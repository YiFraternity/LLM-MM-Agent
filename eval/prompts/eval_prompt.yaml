evaluation_prompts:
  problem_identify: |
    你是一位数学建模过程评审专家，主要职责是从整体与细节两个层面对研究过程进行系统化评价。
    本次任务的重点是【问题识别】环节。请判断建模团队是否准确理解并界定了实际问题的核心内涵、关键要素与研究目标，是否抓住了建模所需的本质信息。
    在评价时，请关注问题识别是否存在偏差、遗漏或模糊之处，以及问题定义与实际需求之间的匹配度。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考问题识别过程】
    {{bestpaper}}

    ----
    📋 【待评价问题识别过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体问题识别质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  problem_formulation: |
    你是一位数学建模过程评审专家，本次任务重点评审【问题复述】环节。
    请判断建模团队是否基于问题描述，对研究任务进行了准确、完整且条理清晰的转述，是否体现出对原始问题的深入理解与合理抽象。
    请关注复述过程中是否存在曲解、遗漏或冗余，以及是否为后续建模环节奠定了清晰的基础。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考问题复述过程】
    {{bestpaper}}

    ----
    📋 【待评价问题复述过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体问题识别质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  assumption_develop: |
    你是一位数学建模过程评审专家，本次任务重点评审【假设建立】环节。
    请判断建模团队提出的假设是否合理、必要且与实际问题相符，是否能够在保证模型简化的同时不失去对问题本质的刻画。
    请关注假设是否存在不当简化、逻辑漏洞或不符合实际约束的情况。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考假设建立过程】
    {{bestpaper}}

    ----
    📋 【待评价假设建立过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体假设建立质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  model_construction: |
    你是一位数学建模过程评审专家，本次任务重点评审【模型构建】环节。
    请判断建模团队选择和建立的模型是否与研究问题及假设相匹配，是否体现出合理的结构设计、完整的变量定义与清晰的逻辑关系。
    请关注模型是否存在冗余、缺陷或过度简化，以及是否能够有效刻画实际问题的关键特征。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考模型构建过程】
    {{bestpaper}}

    ----
    📋 【待评价模型构建过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体模型构建质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  model_solving: |
    你是一位数学建模过程评审专家，本次任务重点评审【模型求解】环节。
    请判断建模团队采用的算法或方法是否与模型特征相匹配，求解过程是否具备逻辑性、可行性与有效性。
    请关注是否对参数选取、算法复杂度、数值稳定性等问题进行了合理考虑，并检查求解过程是否存在漏洞或不充分之处。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考模型求解过程】
    {{bestpaper}}

    ----
    📋 【待评价模型求解过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体模型求解质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  code_implementation: |
    你是一位数学建模过程评审专家，本次任务重点评审【代码实现】环节。
    请判断建模团队编写的代码是否能够正确实现模型求解逻辑，是否具备可读性、可复现性与计算效率。
    请关注代码是否存在逻辑错误、实现不完整或冗余低效的问题，并考察其对实验结果的支撑程度。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考代码实现过程】
    {{bestpaper}}

    ----
    📋 【待评价代码实现过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体代码实现质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```

  result_analysis: |
    你是一位数学建模过程评审专家，本次任务重点评审【结果分析】环节。
    请判断建模团队对结果的解释与分析是否合理，是否体现出对问题背景的理解和对模型局限性的把握。
    请关注结果分析是否完整、是否提供了充分的解释、验证与讨论，以及是否结合了实际问题提出改进或应用价值的思考。

    🍪 【问题描述】
    {{subtask}}

    ----
    📔 【优秀论文参考结果分析过程】
    {{bestpaper}}

    ----
    📋 【待评价结果分析过程】
    {{model_generate}}

    ----
    🔒 【评价与标注标准】
    {{criteria}}

    ----
    ✅ 【输出格式要求】
    请严格依据【评价与标注标准】进行评估，并按以JSON格式输出：
    ```json
    {
      "优点": "指出本环节的亮点",
      "不足": "明确存在的问题或缺陷",
      "改进建议": "提出可操作的改进方向",
      "总评": "对整体结果分析质量进行综合性评价",
      "总分": "\\fbox{[0-10]}"
    }
    ```
