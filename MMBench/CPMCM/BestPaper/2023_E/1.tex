\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}

\title{出血性脑卒中临床智能诊疗模型的建立}
\author{}
\date{}

\begin{document}

\maketitle

\begin{abstract}
构建智能诊疗模型，明确导致出血性脑卒中预后不良的危险因素，实现精准个性化的疗效评估和预后预测对改善患者预后、提升其生活质量、优化临床决策具有着重要意义。患者的 CT 影像数据包含了丰富的患者血肿和水肿信息，因此成为患者预后模型建立的重要依据。本文通过分析患者临床信息探讨了导致出血性脑卒中预后不良的影像因素。利用机器学习的方法来预测患者预后情况并对其准确性进行了评估；在此基础上，通过比较多个回归模型建立了效果最佳的回归算法，并绘制了水肿体积随时间进展模式曲线；最后建立多种预测模型，从多个维度帮助患者制定有效的治疗方案。

针对问题一 (a)，我们对数据进行了预处理，剔除数据中存在的缺失值、异常值、异常变量和异常样本。在变量筛选过程中，考虑了变量之间的线性和非线性关系。使用 SPSS 分析数据之间相关关系，极大提高了有效数据利用率，能够更准确地预测患者发病后 48 小时内是否发生血肿扩张情况和发生时间。针对问题一 (b) 我们将朴素贝叶斯分类 (NBM) 模型和二元线性回归模型有机结合建立新模型对患者发生血肿扩张的概率进行预测，取得显著成果。

针对问题二 (a)，我们对数据进行处理后分别采用了局部加权回归模型和非线性最小二乘法对全体患者水肿体积随时间进展曲线进行了拟合。根据残差的值选择非线性最小二乘法作为回归模型，得到了输出函数及总体的残差。针对问题二 (b)，我们基于问题 2(a) 已处理的数据进行降维，再根据离散数据类似球形且无人工标注类别，我们选择 K-means 聚类算法对数据进行分类，再用手肘法确定最优簇数量，最后分为了三个亚组。根据散点图的形状我们假设了一个非线性函数来分别拟合三个亚组的回归模型，得出三个函数，其 R 方值分别为 0.98165，0.9493，0.92217。根据散点图的形状可以粗略判断三组患者分别为 1，治疗周期较长，病情不能确定。2，水肿体积减小较快，病情趋于好转。3，水肿体积趋于增长，病情趋于恶化。最后得出不同亚组的残差。针对问题二 (c)，在假设各种治疗方法互相独立的情况下，采用各种治疗方法作为自变量，采用每个患者在每两个检查点之间斜率的最小值作为拟合函数的因变量，通过多元线性回归模型确定不同治疗方法的权重，通

过比较治疗方法的权重得出各种治疗方法对水肿体积进展模式的影响：1，对治疗周期较长，病情不能确定患者的治疗效果：镇静、镇痛治疗 $>$ 营养神经 $>$ 止血治疗 $>$ 降颅压治疗 $>$ 止吐护胃 $>$ 降压治疗 $>$ 脑室引流。2，对水肿体积减小较快，病情趋于好转患者的治疗效果：脑室引流 $>$ 止血治疗 $>$ 营养神经 $>$ 镇静、镇痛治疗 $>$ 止吐护胃 $>$ 降颅压治疗 $>$ 降压治疗。3，水肿体积趋于增长，病情趋于恶化患者的治疗效果：营养神经 $>$ 降颅压治疗 $>$ 止血治疗 $>$ 镇静、镇痛治疗 $>$ 止吐护胃 $>$ 降压治疗 $>$ 脑室引流。针对问题二 (d)，延用了问题二 (c) 中的模型计算水肿体积与治疗方法的函数，得到 R 方值为 0.91553，水肿体积与治疗方法函数的 R 方值为 0.93522，通过计算得出血肿体积和水肿体积之间的相关系数为 0.3052，说明血肿体积和水肿体积之间存在着较弱的正相关关系。

针对问题三 (a)、(b)，我们基于首次影像建立决策树回归模型 (DTR)，使用分类回归树算法 (CART) 针对患者 90 天 mRS 评分进行训练、预测，最后的模型预测准确率达到 100%。针对问题三 (c)，通过分析血性脑卒中患者的预后 (90 天 mRS) 和个人史、疾病史、治疗方法及影像特征等关系联系，我们对高维度的数据进行主成分分析 (PCA) 数据降维处理，建立起相关性分析模型，探索出特征之间数学关系，帮助我们系统地提出临床决策建议。

关键字：出血性脑卒中预后，朴素贝叶斯，非线性最小二乘法，K-means 聚类，决策树回归，相关性分析
\end{abstract}

\tableofcontents

\section{问题重述}

\subsection{问题背景}

脑卒中是我国成年人致死、致残的首位原因，脑卒中后 $60\%-80\%$ 的患者仍有不同程度的功能障碍 [1]。脑卒中不仅给社会带来沉重的医疗负担，也极大加重了患者的健康负担。因此，发掘出血性脑卒中的发病风险，整合影像学特征、患者临床信息及临床诊疗方案，精准预测患者预后，并据此优化临床决策具有重要的临床意义。

出血性脑卒中后，血肿范围扩大是预后不良的重要危险因素之一。因此，监测和控制血肿的扩张是临床关注的重点之一。此外，血肿周围的水肿作为脑出血后继发性损伤的标志。综上所述，针对出血性脑卒中后的两个重要关键事件，即血肿扩张和血肿周围水肿的发生及发展，进行早期识别和预测对于改善患者预后、提升其生活质量具有重要意义。

期望能够基于患者影像信息，联合患者个人信息、治疗方案和预后等数据，构建智能诊疗模型，明确导致出血性脑卒中预后不良的危险因素，实现精准个性化的疗效评估和预后预测。

\subsection{需要解决的问题}

通过对真实临床数据的分析，研究出血性脑卒中患者血肿扩张风险、血肿周围水肿发生及演进规律，最终结合临床和影像信息，预测出血性脑卒中患者的临床预后。本文主要考虑以下几个问题：

\subsubsection{问题一：对血肿扩张风险相关因素进行探索建模}

在 (a) 问中我们要根据患者 sub001 至 sub100 的各时间点的血肿体积值判断发病后 48 小时内是否发生血肿扩张事件，并且记录发生血肿扩张的时间。是否发生血肿扩张根据后续检查比首次检查绝对体积增加 $\geq 6\mathrm{mL}$ 或相对体积增加 $\geq 33\%$ 来判断。

在 (b) 问中我们以是否发生血肿扩张事件为目标变量，注意与 (a) 问中的发病后 48 小时内是否发生血肿扩张事件进行区分，基于患者 sub001 至 sub100 的个人史、疾病史、发病及治疗相关特征、影像检查结果（只包含对应患者首次影像检查记录）等变量，构建模型预测所有患者（sub001 至 sub160）发生血肿扩张的概率。

\subsubsection{问题二：对血肿周围水肿的发生情况进展进行建模，并探索治疗干预和水肿进展的关联关系}

在 (a) 问中根据于患者 sub001 至 sub100 的和时间点的水肿体积值，构建一条全体患者水肿体积随时间进展曲线 $y = f(x)$（$x$ 为发病至影像检查时间，$y$ 为水肿体积），并计算患者 sub001 至 sub100 真实值和所拟合曲线之间存在的残差。

在 (b) 问中我们探索患者水肿体积随时间进展模式的个体差异，要构建 3-5 各不同亚组的人群，并构建各亚组的水肿体积随时间进展曲线，并计算患者 sub001 至 sub100 真实值和曲线间的残差。

在 (c) 问中构建模型，分析不同治疗方法对水肿体积进展模式的影响。
在 (d) 为中构建模型，分析血肿体积、水肿体积及治疗方法三者之间的关系。

\subsubsection{问题三：探索出血性脑卒中患者预后预测及关键因素}

在 (a) 问中根据患者 sub001 至 sub100 个人史、疾病史、发病相关及首次影像结果构建预测模型，预测患者（sub001 至 sub160）90 天 mRS 评分。

在 (b) 问中根据患者 sub001 至 sub100 所有信息，包括个人史，疾病史，发病相关、治疗方法、首次及随访的影像结果等，构建预测模型，预测所有含随访影像检查的患者（sub001 至 sub100, sub131 至 sub160）90 天 mRS 评分。

在 (c) 问中构建模型分析出血性脑卒中患者的预后（90 天 mRS）和个人史、疾病史、治疗方法及影像特征等关联关系，并为临床相关决策提出建议。

\section{数据说明与异常数据和非数值数据处理}

\subsection{数据说明}

“表 1-患者列表及临床信息” 为我们提供了患者的首次影像流水号、个人史、“脑出血前 mRS 评分”、“90 天 mRS”、“发病到首次影像检查时间间隔”、治疗方案。

“表 2-患者影像信息血肿及水肿的体积及位置” 为我们提供了患者各个时间点（首次 + 随访）的血肿和水肿的体积及其分布位置。在血肿、水肿的体积及其分布位置中，将全脑划分为了 10 个不同位置：包括 ACA 大脑前动脉，MCA 大脑中动脉，PCA 大脑后动脉，Pons/Medulla 脑桥/延髓，Cerebellum 小脑 (Schirmer, Giese et al. 2019)，具体如下图所示。

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{全脑划分的 10 个不同位置}
\end{figure}

“表 3-患者影像信息血肿及水肿的形状及灰度分布” 为我们提供了患者各个时间点（首次 + 随访）的血肿和水肿的形状特征及灰度分布。灰度特征是基本的度量值，反映目标区域内体素强度的分布；形状特征是对目标区域三维形状描述。

“附表 1-检索表格-流水号 vs 时间”为我们所有流水号（首次+随访）所对应的具体影像检查时间点。

\subsection{异常数据处理和非数值数据处理}

\textbf{异常数据处理:}

“表 1-患者列表及临床信息”中“sub074”的“入院首次影像检查流水号”填错为其“随访 1 流水号”，将其“入院首次影像检查流水号”更正为“20180719000020”。“sub131”和“sub132”实际上为“sub003”和“sub004”患者，“sub131”和“sub132”患者的缺失数据我们将用“sub003”和“sub004”的相关数据进行弥补。

“表 3-患者影像信息血肿及水肿的形状及灰度分布随访数据”中部分随访影像是对不上患者流水号的，可能是非本文数据集中患者的影像，我们将做遗弃处理。

\textbf{非数值数据处理:}

在本文所给的数据中非数值数据有两列，分别是“性别”和“血压”。

对于“性别”，令性别“男”为“1”，性别“女”为“0”。

对于“血压”，根据中国高血压防治指南，将高血压分为三级，分别是：一级：收缩压为 $140-159 \mathrm{mmHg}$ 或舒张压为 $90-99 \mathrm{mmHg}$；二级：收缩压为 $160-179 \mathrm{mmHg}$ 或舒张压为 $100-109 \mathrm{mmHg}$；三级：收缩压 $\geq 180 \mathrm{mmHg}$ 或舒张压 $\geq 110 \mathrm{mmHg}$。根据“血压”数据，我们输出患者高血压等级 $0,1,2,3$ 代替“血压数据”。

\section{模型假设}

\begin{itemize}
    \item 患者完全服从治疗方法，无主观选择治疗方法的意愿。
    \item 所有治疗措施对不同病患的效果一样。
    \item 治疗方法之间不会相互影响，独立生效。
    \item 治疗方法从首次影像检查时间持续到最后一次随访。
    \item 在问题二（c）中水肿体积只受治疗方法的影响。
    \item 在问题三中患者的数据类个人史、发病史、治疗方案、影像信息之间相互独立。
\end{itemize}

\section{问题一}

\subsection{问题一（a）的分析与求解}

根据题目要求，首先需要判断每个患者是否发生了血肿扩张事件。根据定义，如果后续检查的血肿体积比首次检查增加 $\geq 6 \mathrm{~mL}$ 或 $\geq 33\%$，则判断为发生了血肿扩张。

具体判断步骤:

\begin{enumerate}
    \item 从“表 1-患者列表及临床信息”中提取每个患者的“入院首次影像检查流水号”；
    \item 根据“入院首次影像检查流水号”在“附表 1-检索表格-流水号 vs 时间”中查找对应患者的各次检查的时间点，包括“入院首次检查时间点”和“随访时间点”；
    \item 计算发病到各次时间点的时间间隔，计算公式为：

    发病到该影像的时间间隔 = 随访时间点 - 入院首次检查时间点 + 发病到首次影像检查时间间隔；
    \item 在“表 2-患者影像信息血肿及水肿的体积及位置”中找到每个随访各时间点的“HM\_volume”血肿体积值；
    \item 依次计算每次随访检查血肿体积与首次检查血肿体检的变化量和变化百分比，如果变化量 $\geq 6\text{mL}$ 或变化百分比 $\geq 33\%$，则记为发生血肿扩张；
    \item 判断患者是否在在院期间发生血肿扩张；
    \item 针对有发生血肿扩张的患者找到其最早发生血肿扩张的时间；
    \item 判断有发生血肿扩张的患者是否是 48 小时内发生的，并记录其发生时间。
\end{enumerate}

问题一 (a) 流程图如下图 (4..1) 所示:

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{问题 1(a) 思路流程图}
    \label{fig:flowchart}
\end{figure}

得到结果如下图 (4..2) 所示（仅展示 sub001-sub020 患者的结果，其余结果在“表 4-答案文件”中查看）：

\subsection{问题一(b) 的分析}

根据题目要求我们以是否发生血肿扩张事件为目标变量，与 (a) 问中的发病后 48 小时内是否发生血肿扩张事件进行区分，(b) 问是否发生血肿扩张事件不受时间限制。基于患者 sub001 至 sub100 的个人史，疾病史，发病及治疗相关特征、影像检查结果（只包含对应患者首次影像检查记录）等变量，构建模型预测所有患者（sub001 至 sub160）发生血肿扩张的概率。

我们将先基于问题一(a) 所得到的字段“是否发生血肿扩张”（是 1 否 0）作为目标变量，从“表 1”中获得患者的个人史、疾病史、发病及治疗相关特征（字段 E-W），从“表 2”中获取患者首次影像检查结果血肿及水肿的体积及位置（字段 C 至 X），将患者的“入院首次影像检查流水号”与“表 3”中“ED”表和“Hemo”表的“流水号”进行匹配获得患者的首次影像信息血肿及水肿的形状及灰度分布（字段 C-AG）。

基于以上所述数据的前一百行数据，即患者 sub001 至 sub100 的数据，我们首先将数据类别进行判断，将其分为离散数据和连续数据，对于离散数据我们将运用伯努利朴素贝叶斯算法，对于连续数据我们将运用高斯朴素贝叶斯算法，最后我们将得到两种算法给出的患者发生血肿扩张事件的概率。还是以“是否发生血肿扩张”（是 1 否 0）作为目标变量，将两种算法给出的患者发生血肿扩张事件的概率作为输入，对其进行线性回归，得到离散数据大类和连续数据大类对发生血肿扩张事件所贡献的权重。依据该权重，得到最终的预测模型。即可得到在全体患者（sub001 至 sub160）发生血肿扩张的概率。

问题一(b) 流程图如下图 (4..3) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{问题 1(b) 思路流程图}
    \label{fig:flowchart}
\end{figure}

\subsection{问题一 (b) 的模型建立}

贝叶斯分类算法是以贝叶斯原理为基础，使用概率统计的知识对样本数据集进行分类。贝叶斯分类算法的误判率很低。其特点是结合先验概率和后验概率，既避免了只使用先验概率的主观偏见，也避免了单独使用样本信息的过拟合现象。

朴素贝叶斯算法 [2] 是基于贝叶斯定理与特征条件独立假设的分类方法，是经典的机器学习算法之一。最为广泛的两种分类模型是决策树模型 (Decision Tree Model) 和朴素贝叶斯模型 (Naive Bayesian Model, NBM)。和决策树模型相比，朴素贝叶斯分类有着坚实的数学基础和稳定的分类效率。同时，朴素贝叶斯模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，朴素贝叶斯模型具有较小的误差率。

朴素贝叶斯算法适用于维度非常高的数据集。朴素贝叶斯的基本方法是：在统计数据的基础上，依据条件概率公式计算当前特征的样本属于某个分类的概率，选择最大的概率分类。对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。

在本题中，我们将发生血肿扩张和不发生血肿扩张作为两个待分类项，不判断其属于哪个待分类项，只取其属于发生血肿扩张该分类项的概率作为患者发生血肿扩张的概率。

针对本题所给的数据，我们将数据是否为二项分布进行分类，分别应用伯努利朴素贝叶斯算法和高斯朴素贝叶斯算法对患者发生血肿扩张的概率进行计算。两个算法将各自得到患者发生血肿扩张的概率。继续是以“是否发生血肿扩张”作为目标变量，将两种算法给出的患者发生血肿扩张事件的概率作为输入，对其进行线性回归，得到离散数据大类和连续数据大类对发生血肿扩张事件所贡献的权重。依据得到的权重，即可得到在全体数据的预测下发生血肿扩张的概率。

\subsubsection{伯努利朴素贝叶斯}

伯努利朴素贝叶斯适用于离散变量，故我们将数据中的“性别”、“高血压病史”、“卒中病史”、“糖尿病史”、“房颤史”、“冠心病史”、“吸烟史”、“脑室引流”、“止血治疗”、“降颅压治疗”、“降压治疗”、“镇静、镇痛治疗”、“止吐护胃”和“营养神经”应用伯努利朴素贝叶斯算法。

伯努利朴素贝叶斯假设特征的先验概率为二元伯努利分布，试验 E 只有两个可能的结果：A 与 A⁻，在本题中结果为发生血肿扩张和不发生血肿扩张，E 称为伯努利试验。伯努利朴素贝叶斯适用于离散变量，其假设各个特征 \( x_i \) 在各个类别 \( y \) 下是服从 \( n \) 重伯努利分布（二项分布）的，因为伯努利试验仅有两个结果，因此算法会先对特征值进行二值化处理（假设二值化的结果为 1 与 0），即：
\[
p(x_i \mid y) = P(x_i = 1 \mid y)x_i + (1 - P(x_i = 1 \mid y))(1 - x_i)
\]
在训练集中，会进行如下估计：
\[
P(x_i = 1 \mid y) = \frac{N_{yi} + a}{N_y + 2 * a}
\]
\[
P(x_i = 0 \mid y) = 1 - P(x_i = 1 \mid y)
\]
\begin{itemize}
    \item \( N_{yi} \)：第 \( i \) 个特征中，属于类别 \( y \)，数值为 1 的样本个数。
    \item \( N_y \)：属于类别 \( y \) 的所有样本个数。
    \item \( \alpha \)：平滑系数。
\end{itemize}

\subsubsection{高斯朴素贝叶斯}

高斯朴素贝叶斯 [3] 适用于连续变量，故我们将数据中的“年龄”、“脑出血前 mRS 评分”、“高血压程度”、“发病到首次影像检查时间间隔”和所有首次影像信息应用高斯朴素贝叶斯算法。其假定各个特征 \( x_i \) 在各个类别 \( y \) 下服从正态分布，算法内部使用正态分布的概率密度函数来计算概率，公式如下：
\[
P(x_i \mid y) = \frac{1}{\sqrt{2\pi\sigma_y^2}}\exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma_y^2}\right)
\]
\begin{itemize}
    \item \( \mu_y \)：在类别为 \( y \) 的样本中，特征 \( x_i \) 的均值。
    \item \( \sigma_y \)：在类别为 \( y \) 的样本中，特征 \( x_i \) 的标准差。
\end{itemize}

\subsubsection{线性回归}

线性回归 [4]（Linear Regression）指采用线性方程作为预测函数，对特定的数据集进行回归拟合，从而得到一个线性模型。若数据集中有两个特征 $x_1$ 和 $x_2$，在本题中即为伯努利朴素贝叶斯预测的概率结果和高斯朴素贝叶斯预测的概率结果，那么此时需要用到二元线性回归模型，它的预测函数为:

\[
h_{\theta}(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2
\]

对应的损失函数为:

\[
L_{\theta}(x) = \frac{1}{2m} \sum_{i=1}^{m} \left( \theta_0 + \theta_1 x_1 + \theta_2 x_2 - y \right)^2
\]

故，用上式对三个参数求导可得:

\[
\frac{\partial L_{\theta}(x)}{\partial \theta_0} = \frac{1}{m} \sum_{i=1}^{m} \left( h_{\theta}(x) - y \right)
\]

\[
\frac{\partial L_{\theta}(x)}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} \left( \left( h_{\theta}(x) - y \right) x_1 \right)
\]

\[
\frac{\partial L_{\theta}(x)}{\partial \theta_2} = \frac{1}{m} \sum_{i=1}^{m} \left( \left( h_{\theta}(x) - y \right) x_2 \right)
\]

同样地，二元线性回归模型也是使用梯度下降算法，通过多次迭代更新参数 $\theta_0$、$\theta_1$ 和 $\theta_2$ 的值，从而使得它的损失函数值越来越小。其中更新参数 $\theta_0$、$\theta_1$ 和 $\theta_2$ 的公式分别为:

\[
\theta_0 = \theta_0 - \eta \frac{\partial L_{\theta}(x)}{\partial \theta_0} = \theta_0 - \frac{\eta}{m} \sum_{i=1}^{m} \left( h_{\theta}(x) - y \right)
\]

\[
\theta_1 = \theta_1 - \eta \frac{\partial L_{\theta}(x)}{\partial \theta_1} = \theta_1 - \frac{\eta}{m} \sum_{i=1}^{m} \left( \left( h_{\theta}(x) - y \right) x_1 \right)
\]

\[
\theta_2 = \theta_2 - \eta \frac{\partial L_{\theta}(x)}{\partial \theta_2} = \theta_2 - \frac{\eta}{m} \sum_{i=1}^{m} \left( \left( h_{\theta}(x) - y \right) x_2 \right)
\]

其中，$\eta$ 为学习率，每轮需要给 $\theta_0$、$\theta_1$ 和 $\theta_2$ 同时更新值，直到迭代次数达到一定数量或者损失函数 $L_{\theta}(x)$ 的值足够小甚至等于 0 为止。

\subsection{问题一(b) 的结果}

根据上述我们建立的模型，我们得到患者发生血肿扩张的概率，结果如下图 (4..4) 所示（仅展示 sub101-sub120 患者的结果，其余结果在 “表 4-答案文件” 中查看），并额外展示患者事实上是否发生血肿扩张事件（是 1 否 0）。

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 & & 问题1：血肿扩张 & \\
\hline
 & 首次影像检查流水号 & 血肿扩张预测概率 & 实际是否发生血肿扩张 \\
\hline
sub 101 & 20180311000432 & 0.7810 & 0 \\
\hline
sub 102 & 20180708000024 & 0.2650 & 0 \\
\hline
sub 103 & 20181015001677 & 0.3769 & 0 \\
\hline
sub 104 & 20190105000694 & 0.0441 & 0 \\
\hline
sub 105 & 20190108002459 & 0.3273 & 0 \\
\hline
sub 106 & 20190519000853 & 0.3598 & 0 \\
\hline
sub 107 & 20190526000209 & 0.1438 & 0 \\
\hline
sub 108 & 20190701002502 & 0.2857 & 0 \\
\hline
sub 109 & 20190716000013 & 0.2263 & 0 \\
\hline
sub 110 & 20190717001385 & 0.1813 & 0 \\
\hline
\end{tabular}
\caption{sub 101-sub 110 患者的预测发生血肿扩张的概率及其实际发生血肿扩张的情况}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 & & 问题1：血肿扩张 & \\
\hline
 & 首次影像检查流水号 & 血肿扩张预测概率 & 实际是否发生血肿扩张 \\
\hline
sub 111 & 20190727000556 & 0.5502 & 0 \\
\hline
sub 112 & 20190803000014 & 0.1493 & 0 \\
\hline
sub 113 & 20190901000442 & 0.1607 & 0 \\
\hline
sub 114 & 20190903000373 & 0.3882 & 0 \\
\hline
sub 115 & 20190904002299 & 0.0809 & 0 \\
\hline
sub 116 & 20190906001283 & 0.2156 & 0 \\
\hline
sub 117 & 20190917002094 & 0.1615 & 0 \\
\hline
sub 118 & 20190923002580 & 0.2435 & 0 \\
\hline
sub 119 & 20191003000352 & 0.1573 & 0 \\
\hline
sub 120 & 20191004001025 & 0.1781 & 0 \\
\hline
\end{tabular}
\caption{sub 111-sub 120 患者的预测发生血肿扩张的概率及其实际发生血肿扩张的情况}
\end{table}

图4 问题一(b) 的sub 101-sub 120 患者的预测发生血肿扩张的概率及其实际发生血肿扩张的情况(是1否0)

与此同时我们通过折线图图(4..5) 来更好地展示我们的预测结果:

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{image.png}
\caption{血肿扩张时间发生概率的真实值vs预测值}
\end{figure}

图5 蓝色为实际发生血肿扩张情况(是1否0)；红色为预测发生血肿扩张的概率(取值范围为0-1)。问题一(b) 的全体患者(sub 001-sub 160) 的预测发生血肿扩张的概率及其实际发生血肿扩张的折线图

\section{问题二}

\subsection{问题二(a) 的分析}

本题要求根据于患者sub 001至sub 100的各影像时间点及其对应的水肿体积值，构建一条全体患者水肿体积随时间进展曲线 \(y=f(x)\) (\(x\) 为发病至影像检查时间，\(y\) 为水肿体积)，并计算患者sub 001至sub 100真实值和所拟合曲线之间存在的残差。

我们基于问题一(a) 已经处理得到的数据“各影像时间点”，在“表2-患者影像信息血肿及水肿的体积及位置”中获得各时间点的“ED\_volume”水肿体积值。我们得到每个患者各影像时间点及各影像所对应的水肿体积值，加下来对这些离散数据进行函数拟合。

在本题中我们采用了局部加权回归模型和非线性最小二乘法回归模型，根据残差发现非线性最小二乘法回归模型的拟合效果更佳，故本题最后提供的答案为非线性最小二乘法回归模型得到的数据。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{问题 2(a) 思路流程图}
    \label{fig:flowchart}
\end{figure}

\subsection{问题二 (a) 的模型建立}

\subsubsection{局部加权回归模型}

本题的数据呈现为散点图，且散点数据集中在时间值较小的那块区域。数据点在某个区域内密集分布，并且在该区域内变化较小，考虑使用局部加权回归（Locally Weighted Regression）进行拟合。

局部加权回归 [5] 是一种非参数的拟合方法，用于解决回归问题，它通过在每个数据点附近赋予不同的权重来进行拟合。在拟合过程中，距离数据点越近的点被赋予更高的权重，距离越远的点被赋予较低的权重。更加关注待预测样本附近的样本点，这样可以使得拟合曲线更加贴合数据点在局部的变化趋势。

在局部加权回归中，给定一个训练数据集，我们需要预测给定输入 \( x \) 下，在本题中即为“发病至影像检查时间”，输出 \( y \)，在本题中即为“患者的水肿体积”。局部加权回归模型通过以下步骤进行预测：

\begin{enumerate}
    \item 对于给定的待预测样本 \( x \)，找到其附近的 \( k \) 个最近邻样本点。
    \item 对于这 $k$ 个样本点，计算每个样本点与待预测样本 $x$ 之间的距离，并将其映射到一个权重值，通常使用高斯核函数进行映射。
    \item 根据这 $k$ 个样本点的权重值，构建加权最小二乘问题，即通过最小化加权误差的平方和来求解回归系数。
    \item 利用得到的回归系数，对于给定的 $x$，计算相应的预测值 $y$。
\end{enumerate}

下图 (5..2) 为局部加权回归模型得到全体患者水肿体积随时间进展曲线，可以明显看到其在时间较大的时候拟合效果比较差。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{局部加权回归模型构建的全体患者水肿体积随时间进展曲线}
    \label{fig:7}
\end{figure}

\subsubsection{非线性最小二乘法回归模型}

非线性最小二乘法回归模型是适用于当自变量和因变量之间不是线性关系时的数据拟合问题。患者水肿体积随时间进展曲线明显不是线性关系，我们预估其发展方式应该是随时间的增加先增加后减少，这也符合我们的生物逻辑，在发病后水肿体积增加，但随着患者被治疗，水肿体积将会慢慢消退。

与线性回归模型不同，非线性回归模型的最优化目标是最小化观察值与预测值之间的残差平方和。这也与题目要求相符合，要求患者真实值和曲线间的残差尽可能的小。该模型的一般形式可以表示为：

\[
y = f(x; \theta) + \epsilon
\]

其中，$y$ 表示因变量，本题中的 $y$ 即为水肿体积，$x$ 表示自变量，本文中的 $x$ 即为发病至影像检查时间，$\theta$ 是模型参数，$\epsilon$ 是误差项。$f$ 是一个非线性函数，通常可以为指数函数、对数函数、多项式函数等形式。非线性最小二乘法回归模型的求解过程通常采用高斯-牛顿

法或 Levenberg-Marquardt 算法。在这些算法中，模型参数 \(\theta\) 被迭代更新，使得残差平方和达到最小值。

具体而言，给定训练数据集和一个初始参数向量，我们需要通过以下步骤来拟合非线性回归模型：

\begin{enumerate}
    \item 定义一个包含模型参数 \(\theta = (a, b, c)^T\) 的非线性函数 \(f(x; \theta)\)，在本题中我们假设 \(f\) 的形式如下所示：
   \[
   f(x) = e^{ax^2 + bx + c}
   \]
    \item 对于每个训练样本 \((x_i, y_i), i = 1, 2, \cdots, n\)，计算对应的预测值 \(f(x_i; \theta)\)。
    \item 计算每个训练样本的残差 \(e_i = y_i - f(x_i; \theta)\)。
    \item 构造目标函数 \(S(\theta) = \sum_{i=1}^n e_i^2\)，并通过高斯-牛顿法或 Levenberg-Marquardt 算法求解最优参数。
    \item 使用得到的最优参数 \(\theta\) 对心的自变量 \(x\) 进行预测。
\end{enumerate}

最终我们拟合得到
\[
\theta =
\begin{pmatrix}
a \\
b \\
c
\end{pmatrix}
=
\begin{pmatrix}
-4.292762138038417e-06 \\
0.003302332217031 \\
9.963553216206998
\end{pmatrix}
\]
即：
\[
f(x) = e^{-4.292762138038417e-06x^2 + 0.003302332217031x + 9.963553216206998}
\]

下图 (5..3) 为非线性最小二乘法回归模型得到全体患者水肿体积随时间进展曲线，可以明显看出其拟合效果较好，确实更符合患者水肿体积的变化趋势。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{非线性最小二乘法回归模型构建的全体患者水肿体积随时间进展曲线}
    \label{fig:8}
\end{figure}

\subsection{问题二(a) 的结果}

根据残差发现非线性最小二乘法回归模型的拟合效果更佳，故我们最后在答案中将提供由非线性最小二乘法回归模型得到的残差数据。结果如下图（5..4）所示（仅展示 sub001-sub020 患者的结果，其余结果在“表4-答案文件”中查看）。

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        & & 问题2：水肿体积进展曲线 \\
        \hline
        & 首次影像检查流水号 & 残差（全体） \\
        \hline
        sub001 & 20161212002136 & 271920.6664 \\
        \hline
        sub002 & 20160406002131 & 13924.84553 \\
        \hline
        sub003 & 20160413000006 & 56350.86019 \\
        \hline
        sub004 & 20161215001667 & 52848.04529 \\
        \hline
        sub005 & 20161222000978 & 41142.6231 \\
        \hline
        sub006 & 20161110001074 & 228820.8904 \\
        \hline
        sub007 & 20161208000139 & 59421.32345 \\
        \hline
        sub008 & 20161219000091 & 43469.5778 \\
        \hline
        sub009 & 20161031001987 & 26977.12235 \\
        \hline
        sub010 & 20161012002008 & 41745.03353 \\
        \hline
    \end{tabular}
    \quad
    \begin{tabular}{|c|c|c|}
        \hline
        & & 问题2：水肿体积进展曲线 \\
        \hline
        & 首次影像检查流水号 & 残差（全体） \\
        \hline
        sub011 & 20160209000219 & 74637.18164 \\
        \hline
        sub012 & 20161031001142 & 54908.28593 \\
        \hline
        sub013 & 20161124000397 & 94837.37776 \\
        \hline
        sub014 & 20160513001799 & 17983.28644 \\
        \hline
        sub015 & 20161013001234 & 113306.8701 \\
        \hline
        sub016 & 20161130000004 & 86211.84894 \\
        \hline
        sub017 & 20160510002436 & 24726.45751 \\
        \hline
        sub018 & 20160602001707 & 67690.84568 \\
        \hline
        sub019 & 20160117000135 & 50515.8137 \\
        \hline
        sub020 & 20160723000013 & 89985.94375 \\
        \hline
    \end{tabular}
    \caption{问题二(a) 构建的水肿体积随时间进展曲线与 sub001-sub020 患者的真实值的残差}
    \label{tab:9}
\end{table}

\subsection{问题二(b) 的分析}

在(b) 问中我们探索患者水肿体积随时间进展模式的个体差异，要构建 3-5 各不同亚组的人群，并构建各亚组的水肿体积随时间进展曲线，并计算患者 sub001 至 sub100 真实值和曲线间的残差。

我们首先对数据进行降维：将同一患者在不同时间点的水肿体积分离开，使得一行数据对应一个时间点下的水肿体积，同时匹配上该患者的个人史，90 天 mRS，出血前 mRS。

高血压程度等数据。将数据降维后能更直观的观察时间与水肿体积的变化，同时增大数据量以便做进一步的聚类分析，提高聚类分析的准确度。在降维数据后能复制除水肿体积和时间之外的自变量，这些特征能提高同一患者的不同数据被分到同一组的概率。

由于数据可近似看成一个球形，并且数据无人工标注类别，我们选择采用机器学习中无监督学习的 K-means 聚类将这些数据分为题目所需的 3-5 类。当聚类数目明确时，K-means 聚类算法能够产生较好的聚类效果，所以我们首先用手肘法确定聚类效果的提升最显著的聚类数量，即最优簇数量，再根据此最优簇数量对数据进一步使用 K-means 聚类算法将数据进行分类。

根据已经分类好的亚组，对每个亚组都构建一条患者水肿体积随时间进展曲线 $y = f(x)$（$x$ 为发病至影像检查时间，$y$ 为水肿体积）。在问题二 (a) 中我们发现非线性最小二乘法回归模型具有良好的拟合效果，故在本题中我们还将继续采用该方法对各亚组的患者水肿体积随时间进展曲线进行构建。

本题的流程图如下图 (5..5) 所示:

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{image.png}
\caption{问题 2(b) 思路流程图}
\label{fig:flowchart}
\end{figure}

\subsection{问题二(b)的模型建立}

\subsubsection{手肘法}

在使用 K-means 聚类方法对本题进行操作前，我们希望从数据自身出发去确定聚类数，也就是对数据而言的最佳聚类数。手肘法确定聚类数 $k$ 的方法之一。

手肘法 [6] 的核心指标是 SSE (sum of the squared errors, 误差平方和)，

\[
SSE = \sum_{i=1}^{k} \sum_{p \in C_i} |p - m_i|^2
\]

其中，$C$ 是第 $i$ 个簇，$p$ 是 $C_i$ 中的样本点，$m_i$ 是 $C_i$ 的质心 ($C_i$ 中所有样本的均值)，SSE 是所有样本的聚类误差，代表了聚类效果的好坏。

手肘法的核心思想是：随着聚类数 $k$ 的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和 SSE 自然会逐渐变小。并且，当 $k$ 小于真实聚类数时，由于 $k$ 的增大会大幅增加每个簇的聚合程度，故 SSE 的下降幅度会很大，而当 $k$ 到达真实聚类数时，再增加 $k$ 所得到的聚合程度回报会迅速变小，所以 SSE 的下降幅度会骤减，然后随着 $k$ 值的继续增大而趋于平缓，也就是说 SSE 和 $k$ 的关系图是一个手肘的形状，而这个肘部对应的 $k$ 值就是数据的真实聚类数。我们通过手肘法确定了最优簇数量为 3，即我们需要将数据分为 3 类。手肘法的示意图如下图 (5..6) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{用手肘法确定最优簇数量}
    \label{fig:elbow_method}
\end{figure}

\subsubsection{K-means 聚类算法}

K-means 聚类算法 [7] 是一种经典的无监督学习算法，用于将数据集划分为 \( k \) 个不同的簇（cluster），本题中我们需要将其划分为 3 个不同的簇类。该算法通过迭代的方式，将数据样本分配到与其最相似的簇中，并根据簇内样本的特征均值更新簇的中心点，直到达到收敛条件。其具体步骤如下：

\begin{enumerate}
    \item 初始化：随机选择 \( k \) 个点作为初始的聚类中心。
    \item 分配样本：对于每个样本，计算其与各个聚类中心的距离，并将其分配到距离最近的簇中。
    \item 更新中心点：对于每个簇，计算簇内所有样本的特征均值，并将其作为新的聚类中心。
    \item 重复步骤 2 和步骤 3，直到簇的分配不再改变或达到预定的迭代次数。
\end{enumerate}

最终我们得到将所有患者分到了亚组 0、亚组 1、亚组 2 中，各亚组的患者如下图 (5..7) 所示：

我们可以看到亚组 0 中有患者 32 位，亚组 1 中有患者 61 位，亚组 2 中有患者 7 位。

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
ID & 所属亚组 & ID & 所属亚组 & ID & 所属亚组 & ID & 所属亚组 & ID & 所属亚组 & ID & 所属亚组 & ID \\
\hline
sub003 & 0 & sub045 & 0 & sub002 & 1 & sub027 & 1 & sub058 & 1 & sub084 & 1 & sub001 \\
\hline
sub007 & 0 & sub046 & 0 & sub004 & 1 & sub032 & 1 & sub059 & 1 & sub086 & 1 & sub006 \\
\hline
sub008 & 0 & sub048 & 0 & sub005 & 1 & sub033 & 1 & sub062 & 1 & sub087 & 1 & sub030 \\
\hline
sub016 & 0 & sub055 & 0 & sub009 & 1 & sub035 & 1 & sub064 & 1 & sub088 & 1 & sub034 \\
\hline
sub017 & 0 & sub056 & 0 & sub010 & 1 & sub036 & 1 & sub066 & 1 & sub089 & 1 & sub061 \\
\hline
sub018 & 0 & sub060 & 0 & sub011 & 1 & sub041 & 1 & sub067 & 1 & sub090 & 1 & sub074 \\
\hline
sub023 & 0 & sub063 & 0 & sub012 & 1 & sub042 & 1 & sub068 & 1 & sub091 & 1 & sub095 \\
\hline
sub026 & 0 & sub065 & 0 & sub013 & 1 & sub043 & 1 & sub070 & 1 & sub093 & 1 & \\
\hline
sub028 & 0 & sub069 & 0 & sub014 & 1 & sub047 & 1 & sub072 & 1 & sub094 & 1 & \\
\hline
sub029 & 0 & sub071 & 0 & sub015 & 1 & sub049 & 1 & sub073 & 1 & sub096 & 1 & \\
\hline
sub031 & 0 & sub077 & 0 & sub019 & 1 & sub050 & 1 & sub075 & 1 & sub097 & 1 & \\
\hline
sub037 & 0 & sub082 & 0 & sub020 & 1 & sub051 & 1 & sub076 & 1 & sub099 & 1 & \\
\hline
sub038 & 0 & sub083 & 0 & sub021 & 1 & sub052 & 1 & sub078 & 1 & sub100 & 1 & \\
\hline
sub039 & 0 & sub085 & 0 & sub022 & 1 & sub053 & 1 & sub079 & 1 & & & \\
\hline
sub040 & 0 & sub092 & 0 & sub024 & 1 & sub054 & 1 & sub080 & 1 & & & \\
\hline
sub044 & 0 & sub098 & 0 & sub025 & 1 & sub057 & 1 & sub081 & 1 & & & \\
\hline
\end{tabular}
\caption{Caption}
\end{table}


\subsubsection{非线性最小二乘法回归模型}

在问题二 (a) 的模型建立的非线性最小二乘法回归模型部分 5.2.2 已经对该模型进行了解释，故在此不再多做介绍。

对于三个亚组我们还是假设非线性函数 \( f(x; \theta) \) 为

\[
f(x) = e^{ax^2 + bx + c}
\]

其中 $\theta = (a, b, c)^T$。最终我们拟合得到亚组 0 的 $\theta_0$，亚组 1 的 $\theta_1$，亚组 2 的 $\theta_2$ 分别为：

\[
\theta_0 =
\begin{pmatrix}
-2.80168537972685e-06 \\
0.00241155056274753 \\
10.3113629052579
\end{pmatrix},
\quad
\theta_1 =
\begin{pmatrix}
-3.82862671820617e-06 \\
0.00256074364751247 \\
9.48028508880634
\end{pmatrix},
\quad
\theta_2 =
\begin{pmatrix}
-5.19063820019350e-06 \\
0.00426430378528052 \\
10.7391603011940
\end{pmatrix}.
\]

即亚组 0、亚组 1 和亚组 2 的水肿体积随时间进展的拟合函数分别为 $f_0, f_1, f_2$：

\[
f_0(x) = e^{-2.80168537972685e-06x^2 + 0.00241155056274753x + 10.3113629052579},
\]
\[
f_1(x) = e^{-3.82862671820617e-06x^2 + 0.00256074364751247x + 9.48028508880634},
\]
\[
f_2(x) = e^{-5.19063820019350e-06x^2 + 0.00426430378528052x + 10.7391603011940}.
\]

下图 (5..8) 为非线性最小二乘法回归模型得到各亚组患者水肿体积随时间进展曲线。对亚组 0，我们可以粗略判断此组大多数患者治疗周期较长，病情不能确定；对亚组 1，我们可以粗略判断此组大多数患者水肿体积减小较快，病情趋于好转；对亚组 2，我们可以粗略判断此组大多数患者水肿体积趋于增长，病情趋于恶化。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{亚组 0 的患者水肿体积随时间进展曲线，对亚组 0，我们可以粗略判断此组大多数患者治疗周期较长，病情不能确定}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{亚组 1 的患者水肿体积随时间进展曲线，对亚组 1，我们可以粗略判断此组大多数患者水肿体积减小较快，病情趋于好转}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image3.png}
    \caption{亚组 2 的患者水肿体积随时间进展曲线，对亚组 2，我们可以粗略判断此组大多数患者水肿体积趋于增长，病情趋于恶化}
\end{figure}

图 13 非线性最小二乘法回归模型得到各亚组患者水肿体积随时间进展曲线

\subsection{5.6 问题二(b) 的结果}
本题得到各患者的所属亚组及各亚组患者与其对应的亚组所生成的水肿体积随时间
进展曲线的残差，结果如下图(5..9) 所示(仅展示sub001-sub020 患者的结果，其余结果在
“表4-答案文件”中查看
\begin{table}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 & & 问题2：水肿体积进展曲线 & \\
\hline
 & 首次影像检查流水号 & 残差(亚组) & 所属亚组 \\
\hline
sub001 & 20161212002136 & 45523.61702 & 2 \\
\hline
sub002 & 20160406002131 & 50817.71516 & 1 \\
\hline
sub003 & 20160413000006 & 29758.91707 & 0 \\
\hline
sub004 & 20161215001667 & 34648.79581 & 1 \\
\hline
sub005 & 20161222000978 & 46655.51714 & 1 \\
\hline
sub006 & 20161110001074 & 204951.5513 & 2 \\
\hline
sub007 & 20161208000139 & 40747.89975 & 0 \\
\hline
sub008 & 20161219000091 & 39817.29687 & 0 \\
\hline
sub009 & 20161031001987 & 46723.31356 & 1 \\
\hline
sub010 & 20161012002008 & 33287.93678 & 1 \\
\hline
\end{tabular}
\end{table}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
 & & 问题2：水肿体积进展曲线 & \\
\hline
 & 首次影像检查流水号 & 残差(亚组) & 所属亚组 \\
\hline
sub011 & 20160209000219 & 38168.32289 & 1 \\
\hline
sub012 & 20161031001142 & 52440.78175 & 1 \\
\hline
sub013 & 20161124000397 & 30536.14863 & 1 \\
\hline
sub014 & 20160513001799 & 18074.86064 & 1 \\
\hline
sub015 & 20161013001234 & 126064.205 & 1 \\
\hline
sub016 & 20161130000004 & 61992.01425 & 0 \\
\hline
sub017 & 20160510002436 & 45085.08924 & 0 \\
\hline
sub018 & 20160602001707 & 44530.0789 & 0 \\
\hline
sub019 & 20160117000135 & 24109.8994 & 1 \\
\hline
sub020 & 20160723000013 & 50913.40625 & 1 \\
\hline
\end{tabular}
\end{table}



\subsection{5.7 问题二(c) 的分析}
在本问中我们需要构建模型，分析不同治疗方法对水肿体积进展模式的影响。由于题
目的治疗方法仅给出 0 或 1 表示每个患者是否采用此方法，所以本题假设治疗方法从首
次影像检查时间持续到最后一次随访，并假设不同治疗方法之间独立。本题所要解决的是
不同方法对水肿体积进展模式的影响，为了使目标量化，我们采用每个患者在每两个检查
点之间斜率的最小值作为拟合函数的因变量，其实际意义为水肿体积减小变化率最大的值
（若水肿体积在全程中没有下降则为增长变化率最缓慢的值），该数值将在本题中命名为
“水肿体积变化率”。通过多元线性回归模型确定不同治疗方法的权重，通过比较治疗方法
的权重得出各种治疗方法对水肿体积进展模式的影响。本题的流程图如下图(5..10) 所示:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{问题2(c) 思路流程图}
    \label{fig:flowchart}
\end{figure}

\subsection{问题二(c) 的模型建立}

\subsubsection{多元线性回归模型}

多元线性回归模型用于建立自变量（特征）和因变量之间的线性关系。适用于多个自变量对一个因变量进行预测或建模的情况。多元线性回归模型的一般形式可以表示为：

\begin{equation}
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p + \epsilon
\end{equation}

其中，$y$ 表示因变量（要预测的变量），$x_1, x_2, \ldots, x_p$ 表示自变量（特征），$\beta_0, \beta_1, \beta_2, \ldots, \beta_p$ 是模型的参数，$\epsilon$ 是误差项。模型的目标是找到最优的参数估计值，使得观察值与预测值的误差平方和最小化。但本题中我们不采用以残差作为目标函数的传统方法，我们采用将寻找最接近1的R方值作为目标来找到最优的参数估计值。R方值的定义为：

\begin{equation}
R^2 = 1 - \frac{\sum_i (\hat{y}_i - y_i)}{\sum_i (y_i - \bar{y}_i)}
\end{equation}

其中 $\hat{y}_i$ 表示预测值，$\bar{y}_i$ 表示真实值的平均值。当R方值为1时是最理想情况，所有的预测值等于真值。R方的最小值没有下限，因为预测可以任意程度的差，因此，R方值的范围是 $(-\infty, 1]$。

对本题具体而言，对于给定的数据集，我们需要通过以下步骤来拟合多元线性回归模型：

\begin{enumerate}
    \item 收集数据集：自变量 $x_1, x_2, \ldots, x_7$，在本题中分别指其中治疗方案“脑室引流”、“止血治疗”、“降颅压治疗”、“降压治疗”、“镇静、镇痛治疗”、“止吐护胃”和“营养神经”，和因变量 $y$，在本题中为“水肿体积变化率”。
    \item 将数据分为 $80\%$ 的训练集和 $20\%$ 的测试集，对于每个训练样本 $(x_{i1}, x_{i2}, \ldots, x_{i7}, y_i)$，计算对应的预测值 $\hat{y}_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_7 x_{i7}$。
    \item 构造目标函数 R 方值，估计参数 $\beta_0, \beta_1, \beta_2, \ldots, \beta_7$ 的值。
    \item 使用得到的参数判断不同治疗方法对水肿体积减小影响的显著性
\end{enumerate}

最后根据本题要求，还再通过比较治疗方法的权重得出各种治疗方法对水肿体积进展模式的影响。在这之中我们不对 2 亚类别进行拟合是因为 2 亚类别中的数据量过小，无法进行较为精确的数据拟合，即使有拟合结果参考价值也不大，可以使用对总体的评估模型对该类病人进行治疗方法的效果显著性判断。

\subsection{问题二 (c) 的结果}

通过拟合得到亚组 0 模型的 R 方值为 0.98165，模型的实际值和预测值如下图 (5..11) 所示：

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{拟合得到的亚组 0 模型的预测值和实际值“水肿体积变化率”}
\end{figure}

各治疗方法对亚组 0 的进展模式影响的权重柱状图如下图 (5..12) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{各治疗方法对亚组 0 的进展模式影响的权重柱状图}
    \label{fig:17}
\end{figure}

通过以上参数可以得出治疗方法对亚组 0 的水肿体积影响排序如下：
\begin{itemize}
    \item 治疗效果：镇静、镇痛治疗 > 营养神经 > 止血治疗 > 降颅压治疗 > 止吐护胃 > 降压治疗 > 脑室引流
\end{itemize}

通过拟合得到亚组 1 模型的 R 方值为 0.9493，模型的实际值和预测值如下图 (5..13) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{拟合得到的亚组 1 模型的预测值和实际值 “水肿体积变化率”}
    \label{fig:18}
\end{figure}

各治疗方法对亚组1 的进展模式影响的权重柱状图如下图(5..14) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{各治疗方法对亚组1的进展模式影响的权重柱状图}
    \label{fig:19}
\end{figure}

通过以上参数可以得出治疗方法对亚组1的水肿体积影响排序如下：
\begin{itemize}
    \item 治疗效果：脑室引流 > 止血治疗 > 营养神经 > 镇静、镇痛治疗 > 止吐护胃 > 降颅压治疗 > 降压治疗
\end{itemize}

通过拟合得到亚组2模型的R方值为0.92217，模型的实际值和预测值如下图（5..15）所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{拟合得到的亚组 2 模型的预测值和实际值 “水肿体积变化率”}
    \label{fig:20}
\end{figure}

各治疗方法对亚组 2 的进展模式影响的权重柱状图如下图 (5..16) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{各治疗方法对亚组 1 的进展模式影响的权重柱状图}
    \label{fig:21}
\end{figure}

通过以上参数可以得出治疗方法对亚组 2 的水肿体积影响排序如下：
\begin{itemize}
    \item 治疗效果：营养神经 > 降颅压治疗 > 止血治疗 > 镇静、镇痛治疗 > 止吐护胃 > 降压治疗 > 脑室引流
\end{itemize}

结合二题中的b题对以上结果进行分析：对治疗周期较长，病情不能确定的患者采用镇静、镇痛治疗的治疗方法更有效。

对水肿体积减小较快，病情趋于好转的患者采用脑室引流的治疗方法更有效。

对水肿体积趋于增长，病情趋于恶化的患者采用的营养神经治疗方法更有效。

\subsection{问题二 (d) 的分析}

在本题中我们需构建模型，分析血肿体积、水肿体积及治疗方法三者之间的关系。

该题可分为三小问：1，水肿体积和治疗方法的关系。2，血肿体积和治疗方法的关系。3 血肿体积和水肿体积的关系。对于第一和第二小问我们采用问题二 (c) 中的多元线性回归模型确定不同治疗方法的权重，但分析的数据包括编号为 sub001 到 sub100 和 sub131 到 sub160，如此做的原因是 sub101 到 sub130 的数据中不包含随访影像数据，并增加分析的数据以增加模型的精确度。对于第三小问我们采用相关系数作为指标分析水肿体积和血肿体积的关系。本题的流程图如下图 (5..17) 所示:

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{问题 2(d) 思路流程图}
\end{figure}

\subsection{问题二 (d) 的模型建立}

\subsubsection{多元线性回归模型}

在问题二 (c) 的模型建立的多元线性回归模型 5.8.1 已经对该模型进行了解释，故在此不再多做介绍。

\subsection{问题二 (d) 的结果}

通过拟合得到水肿体积与治疗方法模型的 R 方值为 0.91553，模型的实际值和预测值如下图 (5..18) 所示:

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{水肿与治疗方法之间的拟合曲线}
    \label{fig:23}
\end{figure}

水肿体积的各治疗方法的权重柱状图如下图 (5..19) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{水肿体积的各治疗方法的权重柱状图}
    \label{fig:24}
\end{figure}

治疗效果：镇静、镇痛治疗 > 营养神经 > 止吐护胃 > 降颅压治疗 > 止血治疗 > 降压治疗 > 脑室引流

通过拟合得到血肿体积与治疗方法模型的 R 方值为 0.93522，模型的实际值和预测值如下图 (5..20) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image3.png}
    \caption{}
    \label{fig:25}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{血肿与治疗方法之间的拟合曲线}
    \label{fig:25}
\end{figure}

血肿体积的各治疗方法的权重柱状图如下图 (5..21):

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{血肿体积的各治疗方法的权重柱状图}
    \label{fig:26}
\end{figure}

治疗效果：脑室引流 > 降颅压治疗 > 营养神经 > 止吐护胃 > 止血治疗 > 镇静、镇痛治疗 > 降压治疗

结合上述结果进行分析可知：采用镇静、镇痛治疗的治疗方法对减小水肿体积更有效。采用脑室引流的治疗方法对减小血肿体积更有效。

最后对编号为 sub001 到 sub160 的患者的水肿体积和血肿体积的数据作可视化得到如下散点图图 (5..22) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{水肿体积和血肿体积的数据作可视化得到的散点图}
    \label{fig:scatter_plot}
\end{figure}

通过计算得出血肿体积和水肿体积之间的相关系数为 0.3052，说明血肿体积和水肿体积之间存在着较弱的正相关关系。

\section{问题三}

\subsection{问题三 (a) 的分析}

在本问中我们需要根据患者 sub001 至 sub100 个人史、疾病史、发病相关及首次影像结果构建预测模型，预测全体患者 (sub001 至 sub160) 90 天 mRS 评分。我们选取患者 sub001 至 sub100 作为我们的训练集，运用了决策树回归模型、随机森林回归模型 [8]、XGboost 回归模型 [9]。最终根据均方误差发现决策树回归模型的预测效果最佳。本题的流程图如下图 (6..1) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image2.png}
    \caption{流程图}
    \label{fig:flowchart}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{问题3(a) 思路流程图}
    \label{fig:flowchart}
\end{figure}

\subsection{问题三(a) 的模型建立}

因为本题中决策树回归模型产生的效果最佳，故在此我们仅对决策树回归模型进行介绍。

\subsubsection{决策树回归模型}

决策树 [10]（Decision Tree）是一种用于分类和回归的通用的无参数监督学习方法。创建决策树这种分类模型的目的是通过从数据特征里面学习简单的分类规则，从而来预测目标变量的值。一棵决策树可以被看作是分段常数近似。

所谓回归，就是根据特征向量来决定对应的输出值。当决策树被用于处理回归问题时，回归树就是将特征空间划分成若干单元，每一个单元都有一个特定的输出。因为每个节点都是进行“是”和“否”的判断，所以划分的边界是平行于坐标轴的。对于测试数据即前100个患者（sub001至sub100）个人史、疾病史、发病相关（“表1”字段E至W）及首次影像结果（表2，表3中相关字段），我们只要按照特征将其归到某个单元，便可以得到对应的输出值患者90天mRS评分。划分的过程也就是建立树的过程，每划分一次，随即确定划分单元对应的输出，也就多了一个节点。当根据停止条件划分终止的时候，最终每个单元的输出也就确定了，也就是叶节点。

决策树处理回归问题时，我们使用DecisionTreeRegressor类。与分类的设置一样，这个类的函数位有两个输入参数：数组$X$和$y$，只有在这种情况下才有可能是浮点值而不是整数值。

CART（Classification and Regression Tree，分类回归树）是构建决策树的一种常用算法。CART的构建过程采用的是二分循环分割的方法，每次划分都把当前样本集划分为两个子

样本集, 也就是每次决策树节点分裂都会产生两个分支, 所以 CART 算法产生的决策树是一棵二叉树。

同样地, CART 算法在分支处理中选取分支属性的度量指标是 Gini。设 $S$ 为数量为 $n$ 的样本集, 用来定义 $m$ 个不同分类 $C_i (i=1,2,\cdots,m)$, 则其 Gini 指标的计算公式为:
\[
\text{Gini}(S) = 1 - \sum_{i=1}^m p_i^2 \quad p_i = \frac{|C_i|}{S}
\]

在 CART 算法中, 对于样本集 $S$, 选取属性 $A$ 作为分支属性, 将样本集 $S$ 分裂为 $A=a_1$ 的子样本集 $S_1$, 与其余样本组成的样本集 $S_2$, 则此情况下的 Gini 指标为:
\[
\text{Gini}(S \mid A) = \frac{|S_1|}{|S|} \text{Gini}(S_1) + \frac{|S_2|}{|S|} \text{Gini}(S_2)
\]

对于待分裂的节点, 计算出所有可能的二叉树分支属性的 Gini 指标, 选取产生最小 Gini 指标的分支属性。对于每次新生成的节点, 若子样本集的分类不唯一, 则继续分裂, 直到分裂最终完成。

其决策树模型具体如下图6..2所示:

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{问题三 (a) 的决策树模型}
    \label{fig:decision_tree}
\end{figure}

此外我们给出决策树回归模型、随机森林回归模型、XGboost 回归模型的预测的患者
sub001-sub100 结果折线图，如下图(6..3) 所示：
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{sub 001-sub 100 结果折线图，如下图 (6..3) 所示：}
\end{figure}

图 30 问题三 (a) 决策树回归模型、随机森林回归模型、XGboost 回归模型预测的患者 sub 001-sub 100 结果及真实值

\subsection{问题三 (a) 的结果}

本题构建的预测模型，预测的患者 (sub 001-sub 160) 的 90 天 mRS 评分，结果如下图 (6..4) 所示 (仅展示 sub 001-sub 020 患者的结果，其余结果在 “表 4-答案文件” 中查看)

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
 & & 问题 3：预后预测建模 \\
\hline
 & 首次影像检查流水号 & 预测 mRS (基于首次影像) \\
\hline
sub 001 & 20161212002136 & 4 \\
\hline
sub 002 & 20160406002131 & 0 \\
\hline
sub 003 & 20160413000006 & 5 \\
\hline
sub 004 & 20161215001667 & 4 \\
\hline
sub 005 & 20161222000978 & 3 \\
\hline
sub 006 & 20161110001074 & 5 \\
\hline
sub 007 & 20161208000139 & 2 \\
\hline
sub 008 & 20161219000091 & 4 \\
\hline
sub 009 & 20161031001987 & 3 \\
\hline
sub 010 & 20161012002008 & 3 \\
\hline
\end{tabular}
\quad
\begin{tabular}{|c|c|c|}
\hline
 & & 问题 3：预后预测建模 \\
\hline
 & 首次影像检查流水号 & 预测 mRS (基于首次影像) \\
\hline
sub 011 & 20160209000219 & 5 \\
\hline
sub 012 & 20161031001142 & 0 \\
\hline
sub 013 & 20161124000397 & 1 \\
\hline
sub 014 & 20160513001799 & 2 \\
\hline
sub 015 & 20161013001234 & 2 \\
\hline
sub 016 & 20161130000004 & 5 \\
\hline
sub 017 & 20160510002436 & 3 \\
\hline
sub 018 & 20160602001707 & 0 \\
\hline
sub 019 & 20160117000135 & 1 \\
\hline
sub 020 & 20160723000013 & 2 \\
\hline
\end{tabular}
\caption{问题三 (a) 预测的患者 (sub 001-sub 020) 的 90 天 mRS 评分}
\end{table}

\subsection{问题三 (b) 的分析}

在本题中根据患者 sub 001 至 sub 100 所有信息，包括个人史，疾病史，发病相关、治疗方法、首次及随访的影像结果等，构建预测模型，预测所有含随访影像检查的患者 (sub 001 至 sub 100, sub 131 至 sub 160) 90 天 mRS 评分。我们选取患者 sub 001 至 sub 100 作为我们的训练集，运用了决策树回归模型、随机森林回归模型、XGboost 回归模型。最终根据均方误差发现决策树回归模型的预测效果最佳。

相较于问题三 (a)，问题三 (b) 需要补充上患者的随访影像信息，那么此时我们的数据会出现维数较多且参差不齐的情况。此时我们首先对数据进行降维，操作与问题二 (b) 中类似：将同一患者在不同时间点的影像信息分离开，使得一行数据对应一个时间点下的影像信息，同时匹配上该患者的个人史，90 天 mRS，出血前 mRS，高血压程度、治疗情况等数据。使得数据从复杂度很高的维度降到复杂度较低的维度，便于我们带入建立的模型进行训练、分析。

本题的流程图如下图 (6.5) 所示:

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{问题 3(b) 思路流程图}
\label{fig:flowchart}
\end{figure}

\subsection{问题三 (b) 的模型建立}

\subsubsection{决策树回归模型}

在问题三 (a) 的模型建立的决策树回归模型 6.2.1 已经对该模型进行了解释，故在此不再多做介绍。本题得到的决策树回归模型如下图 (6.6) 所示：此外我们给出决策树回归模型预测的患者 sub001-sub100 结果折线图，如下图 (6.7) 所示：

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image2.png}
\caption{决策树回归模型}
\label{fig:decision_tree}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image3.png}
\caption{决策树回归模型预测结果折线图}
\label{fig:prediction_line}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{问题三 (b) 的决策树模型}
    \label{fig:decision_tree}
\end{figure}

\newpage

\subsection{问题三 (b) 的结果}

本题构建的预测模型，预测的患者 (sub001-sub100, sub130-sub160) 的 90 天 mRS 评分，结果如下图 (6..8) 所示 (仅展示 sub130-sub150 患者的结果，其余结果在 “表4-答案文件” 中查看)

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        & & 问题3：预后预测建模 \\
        \hline
        & 首次影像检查流水号 & 预测 mRS \\
        \hline
        sub131 & 20171220002173 & 5 \\
        \hline
        sub132 & 20170107000727 & 4 \\
        \hline
        sub133 & 20200112000228 & 3 \\
        \hline
        sub134 & 20200101000392 & 1 \\
        \hline
        sub135 & 20201130003288 & 1 \\
        \hline
        sub136 & 20201203002778 & 2 \\
        \hline
        sub137 & 20201217002368 & 5 \\
        \hline
        sub138 & 20200403000012 & 1 \\
        \hline
        sub139 & 20200814000015 & 5 \\
        \hline
        sub140 & 20200412000331 & 2 \\
        \hline
    \end{tabular}
    \quad
    \begin{tabular}{|c|c|c|}
        \hline
        & & 问题3：预后预测建模 \\
        \hline
        & 首次影像检查流水号 & 预测 mRS \\
        \hline
        sub141 & 20200711001264 & 3 \\
        \hline
        sub142 & 20200411000014 & 4 \\
        \hline
        sub143 & 20200214000572 & 1 \\
        \hline
        sub144 & 20200124000041 & 0 \\
        \hline
        sub145 & 20200613001086 & 5 \\
        \hline
        sub146 & 20200531000253 & 1 \\
        \hline
        sub147 & 20201220000155 & 2 \\
        \hline
        sub148 & 20200609001016 & 1 \\
        \hline
        sub149 & 20200409001101 & 2 \\
        \hline
        sub150 & 20200118000372 & 5 \\
        \hline
    \end{tabular}
    \caption{问题三(b) 预测的患者 (sub130-sub150) 的 90 天 mRS 评分}
    \label{tab:35}
\end{table}

\subsection{问题三(c) 的分析}

在本问中我们需要分析出血性脑卒中患者的预后 (90 天 mRS) 和个人史、疾病史、治疗方法及影像特征 (包括血肿/水肿体积、血肿/水肿位置、信号强度特征、形状特征) 等关联关系，并为临床相关决策提出建议。由于整体数据体量庞大，变量个数达 104，不利于相关性分析建模的直接操作，我们在理解题意的基础上，将原始数据分割为题中要求的个人史、疾病史、治疗方法及影像特征 (包括血肿/水肿特征) 等大类，逐一针对出血性脑卒中患者的预后 (90 天 mRS) 结果建立相关性分析模型。

本题的流程图如下图 (6..9) 所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{问题3(c) 思路流程图}
    \label{fig:flowchart}
\end{figure}

\subsection{问题三 (c) 的模型建立}

\subsubsection{相关性分析模型}

相关性分析 [11] 是将变量之间相关关系进行量化处理的过程，通过计算变量间的相关系数，得出各个变量之间的相关系数矩阵，通过对两个或两个以上变量之间两两相关的强度进行量化描述。量化描述的结果就是各种不同的相关系数。

相关系数 (Pearson product-moment correlation coefficient) 是统计学家 Pearson 提出的用于统计两个随机变量之间线性相关程度的统计量。其定义为：两个变量之间的皮尔逊相关系数定义为两个变量的协方差除以它们标准差的乘积。

\begin{equation}
\rho_{X_i, X_j} = \frac{\sigma_{X_i, X_j}}{\sqrt{\sigma_{X_i, X_i} \sigma_{X_j, X_j}}}
\end{equation}

和协方差矩阵类似，相关系数矩阵的每一个元素都是相关系数。不同于协方差矩阵，相关系数矩阵的每一个元素都在 $[-1, 1]$ 之间。

\subsection{问题三 (c) 的结果}

按照上述方法分别建立相关性分析模型之后，我们得到了如下图所示三张相关系数矩阵热力图，图 (6..10) 表示 Rms 与 ED 影像特征相关性图像，图 (6..11) 表示 Rms 与 HM 影

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{heatmap_image.png}
    \caption{Rms 与 ED 影像特征相关性图像}
    \label{fig:heatmap}
\end{figure}

\begin{table}[h]
    \centering
    \begin{tabular}{l}
        图 37
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{c}
        41
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{heatmap_image.png}
    \caption{Rms 与 HM 影像特征相关性图像}
    \label{fig:heatmap}
\end{figure}

\begin{table}[h]
    \centering
    \begin{tabular}{l}
        HM_original_shape_Elongation \\
        HM_original_shape_Flatness \\
        HM_original_shape_LeastAxisLength \\
        HM_original_shape_MajorAxisLength \\
        HM_original_shape_Maximum2DDiameterColumn \\
        HM_original_shape_Maximum2DDiameterRow \\
        HM_original_shape_Maximum2DDiameterSlice \\
        HM_original_shape_Maximum3DDiameter \\
        HM_original_shape_MeshVolume \\
        HM_original_shape_MinorAxisLength \\
        HM_original_shape_Sphericity \\
        HM_original_shape_SurfaceArea \\
        HM_original_shape_SurfaceVolumeRatio \\
        HM_original_shape_VoxelVolume \\
        HM_NCCT_original_firstorder\_10Percentile \\
        HM_NCCT_original_firstorder\_90Percentile \\
        HM_NCCT_original_firstorder\_Energy \\
        HM_NCCT_original_firstorder\_Entropy \\
        HM_NCCT_original_firstorder\_InterquartileRange \\
        HM_NCCT_original_firstorder\_Kurtosis \\
        HM_NCCT_original_firstorder\_Maximum \\
        HM_NCCT_original_firstorder\_MeanAbsoluteDeviation \\
        HM_NCCT_original_firstorder\_Mean \\
        HM_NCCT_original_firstorder\_Median \\
        HM_NCCT_original_firstorder\_Minimum \\
        HM_NCCT_original_firstorder\_Range \\
        HM_NCCT_original_firstorder\_RobustMeanAbsoluteDeviation \\
        HM_NCCT_original_firstorder\_RootMeanSquared \\
        HM_NCCT_original_firstorder\_Skewness \\
        HM_NCCT_original_firstorder\_Uniformity \\
        HM_NCCT_original_firstorder\_Variance \\
        HM_volume \\
        HM_ACA_R\_Ratio \\
        HM_MCA_R\_Ratio \\
        HM_PCA_R\_Ratio \\
        HM_Pons_Medulla_R\_Ratio \\
        HM_Cerebellum_R\_Ratio \\
        HM_ACA_L\_Ratio \\
        HM_MCA_L\_Ratio \\
        HM_PCA_L\_Ratio \\
        HM_Pons_Medulla_L\_Ratio \\
        HM_Cerebellum_L\_Ratio \\
    \end{tabular}
    \caption{HM 影像特征列表}
    \label{tab:hm_features}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{heatmap_image.png}
    \caption{Rms与个人史、疾病史、治疗方法相关性图像}
    \label{fig:heatmap}
\end{figure}

我们对结果进行分析，发现血肿、水肿的体积，位置，形状，扩散程度以及患者的年龄、性别、血压、糖尿病、冠心病、镇静镇痛治疗这些患者特征与患者的预后（90天mRS）相关性较强。可能产生这种情况的原因如下：

\begin{itemize}
    \item 血肿、水肿体积：血肿体积较大的患者可能更有可能出现严重的神经功能缺陷，从而导致较低的90天rms评分。
    \item 血肿、水肿位置：血肿的位置可能影响到患者的神经功能恢复情况。例如，如果血肿位于重要的脑功能区域，可能会导致更严重的功能缺陷，从而降低90天rms评分。
\end{itemize}

\begin{itemize}
    \item 血肿、水肿形状：血肿的形状可能与患者的神经功能恢复情况相关。例如，较不规则的血肿形状可能会导致更严重的神经功能缺陷，从而降低 90 天 rms 评分。
    \item 血肿、水肿扩散程度：血肿的扩散程度可能与患者的神经功能恢复情况相关。如果血肿扩散到周围的脑组织，可能会导致更严重的功能缺陷，从而降低 90 天 rms 评分。
    \item 年龄：年龄是一个重要的因素，年龄较大的患者可能更容易出现严重的神经功能缺陷，从而导致较低的 90 天 rms 评分。
    \item 性别：性别可能对 90 天 rms 评分产生影响。部分研究表明，女性患者可能比男性患者更容易出现较低的 90 天 rms 评分。
    \item 基础健康状况：患者的基础健康状况可能与 90 天 rms 评分相关。例如，存在其他慢性疾病（如高血压、糖尿病等）的患者可能更容易出现较低的 90 天 rms 评分。
    \item 既往脑卒中史：如果患者有过既往的脑卒中史，可能会影响到 90 天 rms 评分。既往脑卒中可能导致脑功能的损伤和恢复能力的降低。
\end{itemize}

综上，为临床相关决策提出建议如下：

\begin{enumerate}
    \item 个人史：
    \begin{itemize}
        \item 年龄：年龄是血性脑卒中预后的重要因素，年龄越大，预后越差。建议对于年龄较大的患者，应加强康复治疗和护理。
        \item 饮食习惯：不健康的饮食习惯（高盐、高脂肪、高胆固醇）可能增加血压和血脂的升高，进而影响预后。建议改善饮食习惯，减少高盐、高脂肪和高胆固醇食物的摄入。
        \item 吸烟和饮酒：吸烟和饮酒会增加血压和血脂的升高，加重脑血管病变，影响预后。建议戒烟和限制饮酒。
    \end{itemize}
    \item 疾病史：
    \begin{itemize}
        \item 高血压：高血压是血性脑卒中的主要危险因素，也是预后不良的重要因素。建议加强高血压的控制和管理。
        \item 糖尿病：糖尿病会增加血管病变的风险，影响预后。建议加强糖尿病的管理和控制。
        \item 心脏病：心脏病可能导致血栓形成，增加脑卒中的风险。建议加强心脏病的治疗和管理。
    \end{itemize}
    \item 治疗方法：
    \begin{itemize}
        \item 降颅压治疗：早期的血肿清除和血压控制对预后有重要影响。建议尽早进行血肿清除手术或介入治疗，并控制血压。
        \item 镇静镇痛治疗：镇静镇痛治疗对于恢复功能和改善预后非常重要。建议进行系统的镇静镇痛治疗，包括物理治疗、语言治疗和认知训练等。
    \end{itemize}
    \item 影像特征：
\end{enumerate}

\begin{itemize}
    \item 血肿/水肿体积：较大的血肿/水肿体积与预后不良相关。建议对于较大的血肿/水肿体积，应密切监测和积极治疗。
    \item 血肿/水肿位置：血肿/水肿的位置可能影响神经功能的恢复。建议根据血肿/水肿的位置制定相应的治疗方案。
\end{itemize}

综上所述，血性脑卒中患者的预后与个人史、疾病史、治疗方法及影像特征之间存在一定的关联关系。建议在临床决策中综合考虑这些因素，制定个性化的治疗方案，以改善患者的预后。

\section{模型评价与改进}

\subsection{模型评价}

{问题一}

\paragraph{问题一 (b) 模型的优点和缺点}

\begin{enumerate}
    \item 优点：朴素贝叶斯算法对小规模的数据表现很好，本题数据量规模较小，朴素贝叶斯分类算法对小规模的数据表现很好；本题中针对离散和连续数据进行了分类采用了不同的朴素贝叶斯分类算法，尽可能减少数据的表达形式对模型的影响；
    \item 缺点：对输入数据的表达形式很敏感（离散、连续，以及值极大、极小之类的）；其在属性个数比较多或者属性之间相关性较大时，分类效果不好。
\end{enumerate}

{问题二}

\paragraph{问题二 (a) 中我们提出的第一个模型：局部加权回归模型的优点和缺点}

\begin{enumerate}
    \item 优点：模型能够根据数据的分布变化自适应地进行拟合，从而提高预测的准确性。
    \item 缺点：由于每次预测都需要重新计算权重和回归系数，所以计算量较大，可能导致预测效率较低。
\end{enumerate}

\paragraph{问题二 (a) 中我们提出的第二个模型：非线性最小二乘法回归模型的优点和缺点}

\begin{enumerate}
    \item 优点：可以捕捉自变量和因变量之间的非线性关系，并且能够对各种类型的非线性函数进行拟合。
    \item 缺点：由于需要对目标函数进行迭代求解，因此该方法可能存在局部最优解的问题，并且在变量维度较高时计算成本也会比较大。
\end{enumerate}

\paragraph{问题二 (b) 中的 K-means 聚类算法模型的优点和缺点}

\begin{enumerate}
    \item 优点：简单、易于实现，并且在处理大规模数据时具有较高的效率。它对于规则形状的簇、高维数据和连续特征较好的适用。
    \item 缺点：算法的结果高度依赖于初始聚类中心的选择，因此可能陷入局部最优解；对异常值和噪声敏感，可能会导致错误的簇分配；K 值的选择也是一个重要的问题，不合
\end{enumerate}

适的 K 值可能导致聚类结果不准确。

\paragraph{问题二 (c) 的模型的优点和缺点}

\begin{enumerate}
    \item 优点: 能针对三种不同水肿体积模式进展模式的人群进行分析并得出针对三类人群最有效的治疗方法; 可以根据权重决定同时采用哪几种治疗方法能有效减小水肿体积。
    \item 缺点: 因为亚组 2 数据过少的而采用对总体的数据进行拟合来代替对亚组 2 数据的拟合的方法会对亚组 2 真实情况的预测产生偏差, 若在数据量足够大的情况下可以对亚组 2 的患者所需采取的治疗方法进行更精准的预测
\end{enumerate}

\subsection{模型推广与改进}

\begin{enumerate}
    \item 本文提出的方法和模型思路适合大部分大样本和海量数据处理的数据挖掘问题, 例如, 生物化学以及材料科学中的变量筛选, 以及其他数据挖掘的回归、预测和优化问题。
    \item 模型可以在考虑变量耦合性的复杂问题上进行一些探索和优化, 以便处理更复杂的数据挖掘问题。
    \item 问题一 (b) 的模型可改进之处: 本文数据类别较多, 而且部分数据相关性较大, 对于这一点有半朴素贝叶斯之类的算法通过考虑部分关联性进行适度改进。这是该模型未来可以改进的地方之一。
\end{enumerate}

\section{参考文献}

\begin{enumerate}
    \item 王陇德, 《中国脑卒中防治报告 2019》概要, 中国脑血管病杂志 2020 年 17 卷 5 期 272-281 页 ISTIC PKU CSCD: 国家重大公共卫生服务项目——脑卒中高危人群筛查和干预项目, 2020.
    \item 申羽, 庄天戈, 程红岩, 等, 朴素贝叶斯算法在原发性肝癌预后预测中的研究, 航天医学与医学工程, 17(5):5, 2004.
    \item 陈俊杰, 赵丽, 相洁, 用机器学习方法解码脑图像数据, 计算机工程与应用, 48(10): 222-225, 2012.
    \item 程洪建, 关静, 带有测量误差的线性回归模型, 南开大学学报 (自然科学版), v.49(02): 109-112, 2016.
    \item 宋文武江竹, 基于机器学习的水位流量关系模型参数估计, 水文, 33(74-78), 2013.
    \item 蒋铁铮, 尹晓博, 马瑞, 等, 基于 k-means 聚类和模糊神经网络的母线负荷态势感知, 电力科学与技术学报, 35(3):9, 2020.
    \item Roy R R, Mala G S A, An Improved K-Means Clustering for Segmentation of Pancreatic Tumor from CT Images, IETE Journal of Research:1-8, 2021.
    \item 李梦娜, 刘晓夏, 陈美文, 等, 随机森林与 Logistic 回归模型对子宫内膜癌患者加速康复外科术后早期出院预测的比较, 护理学报, 30(1):17-21, 2023.
\end{enumerate}

\begin{enumerate}
    \item[9] Mun S K, Chang M, Development of prediction models for the incidence of pediatric acute otitis media using Poisson regression analysis and XGBoost, Environmental Science and Pollution Research, 29(13):18629-18640, 2022.
    \item[10] 冯安丽 唐帆 罗玉红 李蕾 吴柔, 决策树和 logistic 回归构建早产儿颅内出血预测模型的比较研究, 护士进修杂志, 38(1345-1349), 2023.
    \item[11] Xiao-Huan Z, Yu-Chun Y, Yuan-Ming Z, et al., Analysis of the relationship between hypertension, hyperlipidemia and carotid artery atherosclerosis, Medical Journal of West China, 2014.
\end{enumerate}

\end{document}

\section{附录}
# 附录A 我的MATLAB 源程序
x = [];
y = [];
yy = [];
n = 1;
for j = 2:2:18
x(100*(n-1)+1:100*n , 1) = data1(1:100,j);
n = n+1;
end
x = x(~isnan(x));
n = 1;
for k = 3:2:19
y(100*(n-1)+1:100*n , 1) = data1(1:100,k);
yy(1:100 , n) = data1(1:100,k);
n = n+1;
end
y = y(~isnan(y));
%假设函数
fun = @(coefficients, x) exp(coefficients(1) *( x.^2 + coefficients(2)
* x )+ coefficients(3));
% 设置初始参数
initialGuess = [-0.1, -1, 1];
% 使用非线性最小二乘法拟合数据
fittedCoefficients = lsqcurvefit(fun, initialGuess, x, y);
disp('拟合得到的系数:');
disp(fittedCoefficients);
% 绘制拟合曲线
x_fit = linspace(min(x), max(x), 200);
y_fit = fun(fittedCoefficients, x_fit);
scatter(x, y, 'filled', 'SizeData', 10 );
xlabel('发病至影像检查时间单位：小时')
48



ylabel('水肿体积单位：10^-3ml')
hold on
plot(x_fit, y_fit,'linewidth',1)
legend('水肿体积', '水肿体积的拟合曲线');
hold off
yfit = fun(fittedCoefficients, x);
%计算并得出拟合结果
detay = y - yfit; %输出残差结果
n = 1;
i = 1;
cancha = [];
%计算各患者残差分别的残差之和
for j = 1:9
for k = 1:100
if ~isnan(yy(k,j))
cancha(k , j) = yy(k,j) - yfit(i);
i = i+1;
end
n = n+1;
end
end
answer = sum(abs(cancha), 2)
for i = 1 : length(x)
plus(i,1)=x(i);
plus(i,2)=y(i);
end
[data0, txt0, raw0] = xlsread('2(b)亚类别.xlsx', '0');
[data1, txt1, raw1] = xlsread('2(b)亚类别.xlsx', '1');
[data2, txt2, raw2] = xlsread('2(b)亚类别.xlsx', '2');
x0 = data0(:,1);
y0 = data0(:,2);
x1 = data1(:,1);
49



y1 = data1(:,2);
x2 = data2(:,1);
y2 = data2(:,2);
%假设函数
fun = @(coefficients, x) exp(coefficients(1) * x.^2 + coefficients(2)
* x + coefficients(3));
% 设置初始参数
initialGuess = [-2, 1, 1];
% 使用非线性最小二乘法拟合数据
fittedCoefficients0 = lsqcurvefit(fun, initialGuess, x0, y0);
initialGuess = [-3, 5, 1];
fittedCoefficients1 = lsqcurvefit(fun, initialGuess, x1, y1);
initialGuess = [-5, 10, 1];
fittedCoefficients2 = lsqcurvefit(fun, initialGuess, x2, y2);
disp('拟合得到的亚组0系数:');
disp(fittedCoefficients0);
disp('拟合得到的亚组1系数:');
disp(fittedCoefficients1);
disp('拟合得到的亚组2系数:');
disp(fittedCoefficients2);
%画第一张图
figure(1)
x_fit0 = linspace(min(x0), max(x0), 200);
y_fit0 = fun(fittedCoefficients0, x_fit0);
set(gcf, 'Position', [100, 100, 600, 300]);
scatter(x0, y0, 'filled', 'SizeData', 10 );
xlabel('发病至影像检查时间单位：小时')
ylabel('水肿体积单位：10^-3ml')
hold on
plot(x_fit0, y_fit0,'linewidth',1)
legend('水肿体积', '水肿体积的拟合曲线');
hold off
saveas(gcf, '0.png');
%画第二张图
figure(2)
x_fit1 = linspace(min(x1), max(x1), 200);
50



y_fit1 = fun(fittedCoefficients1, x_fit1);
set(gcf, 'Position', [100, 100, 600, 300]);
scatter(x1, y1, 'filled', 'SizeData', 10 );
xlabel('发病至影像检查时间单位：小时')
ylabel('水肿体积单位：10^-3ml')
xlim([0, 5000]);
ylim([0, 140000]);
hold on
plot(x_fit1, y_fit1,'linewidth',1)
legend('水肿体积', '水肿体积的拟合曲线');
xlim([0, 5000]);
ylim([0, 140000]);
hold off
saveas(gcf, '1.png');
%画第三张图
figure(3)
x_fit2 = linspace(min(x2), max(x2), 200);
y_fit2 = fun(fittedCoefficients2, x_fit2);
set(gcf, 'Position', [100, 100, 600, 300]);
scatter(x2, y2, 'filled', 'SizeData', 10 );
xlabel('发病至影像检查时间单位：小时')
ylabel('水肿体积单位：10^-3ml')
hold on
plot(x_fit2, y_fit2,'linewidth',1)
legend('水肿体积', '水肿体积的拟合曲线');
xlim([0, 5000]);
ylim([0, 140000]);
hold off
saveas(gcf, '2.png');
%下面分别计算残差
yfit0 = fun(fittedCoefficients0, x0);
detay0 =abs( y0 - yfit0); %输出残差0
yfit1 = fun(fittedCoefficients1, x1);
detay1 =abs( y1 - yfit1); %输出残差1
yfit2 = fun(fittedCoefficients2, x2);
detay2 =abs( y2 - yfit2); %输出残差2
51



[data1, txt1, raw1] = xlsread('题目2（c）所需数据.xlsx', 'Sheet1');
n = 1;
for i = 13:3:34
kk(1:100 , n) = data1(1:100,i);
n = n+1;
end
## X = data1(1:100 ,2:8);%读取前一百名患者的7种治疗方法作为因变量
mink = min(kk,[],2);%找出每个患者变化率负值最大的数作为因变量
y = mink;
data= horzcat(X, mink);
r2=0;
while r2<0.9
[trainInd, testInd] = dividerand(size(data, 1), 0.8, 0.2); % 80%
训练集，20% 测试集
X_train = X(trainInd, :);
y_train = y(trainInd);
X_test = X(testInd, :);
y_test = y(testInd);
% 拟合多元线性回归模型
mdl = fitlm(X_train, y_train);
% 预测结果
y_pred = predict(mdl, X_test);
% 评估模型性能
r2 = corr(y_pred, y_test)^2; % 计算R方值
end
# % 查看模型摘要信息
disp(mdl)
% 查看系数（权重）估计
coeffs = mdl.Coefficients;
% 可视化实际值与预测值
figure;
plot(1:length(y_test), y_test, 'bo-', 'LineWidth', 1.5);
hold on;
plot(1:length(y_test), y_pred, 'rx-', 'LineWidth', 1.5);
52



legend('实际值', '预测值');
xlabel('样本编号');
ylabel('水肿体积变化率');
title('实际值vs 预测值');
% 输出结果
disp('各个治疗方法的系数估计：');
disp(coeffs);
disp(['模型的R方值：', num2str(r2)]);
clear
[data0] = xlsread('题目2（d）所需数据.xlsx', '0');
[data1] = xlsread('题目2（d）所需数据.xlsx', '1');
%%%%%%%%%%%%%第0亚类别%%%%%%%%%%%%%%%%%%%%%%
n = 1;
for i = 16:5:size(data0, 2)
kk(1:size(data0, 1) , n) = data0(1:size(data0, 1),i);
n = n+1;
end
X0 = data0(1:size(data0, 1) ,2:8);%读取前一百名患者的7种治疗方法作为因变量
y0 = min(kk,[],2);%找出每个患者变化率负值最大的数作为因变量
data00= horzcat(X0, y0);
r2=0;
while r2<0.9
[trainInd, testInd] = dividerand(size(data00, 1), 0.8, 0.2); % 80%
训练集，20% 测试集
X0_train = X0(trainInd, :);
y0_train = y0(trainInd);
X0_test = X0(testInd, :);
y0_test = y0(testInd);
% 拟合多元线性回归模型
mdl = fitlm(X0_train, y0_train);
% 预测结果
y0_pred = predict(mdl, X0_test);
53



% 评估模型性能
r2 = corr(y0_pred, y0_test)^2; % 计算R方值
end
# % 查看模型摘要信息
disp(mdl)
% 查看系数（权重）估计
coeffs = mdl.Coefficients;
% 可视化实际值与预测值
figure(1)
plot(1:length(y0_test), y0_test, 'bo-', 'LineWidth', 1.5);
hold on;
plot(1:length(y0_test), y0_pred, 'rx-', 'LineWidth', 1.5);
legend('实际值', '预测值');
xlabel('样本编号');
ylabel('水肿体积变化率');
title('实际值vs 预测值');
% 输出结果
disp('各个治疗方法的系数估计：');
disp(coeffs);
disp(['模型的R方值：', num2str(r2)]);
%%%%%%%%%%%%%第1亚类别%%%%%%%%%%%%%%%%%%%%%%
n = 1;
for i = 16:5:size(data1, 2)
kk(1:size(data1, 1) , n) = data1(1:size(data1, 1),i);
n = n+1;
end
X1 = data1(1:size(data1, 1) ,2:8);%读取前一百名患者的7种治疗方法作为因变量
y1 = min(kk,[],2);%找出每个患者变化率负值最大的数作为因变量
data11= horzcat(X1, y1);
r2=0;
while r2<0.9
[trainInd, testInd] = dividerand(size(data11, 1), 0.8, 0.2); % 80%
54



训练集，20% 测试集
X1_train = X1(trainInd, :);
y1_train = y1(trainInd);
X1_test = X1(testInd, :);
y1_test = y1(testInd);
% 拟合多元线性回归模型
mdl = fitlm(X1_train, y1_train);
% 预测结果
y1_pred = predict(mdl, X1_test);
% 评估模型性能
r2 = corr(y1_pred, y1_test)^2; % 计算R方值
end
# % 查看模型摘要信息
disp(mdl)
% 查看系数（权重）估计
coeffs = mdl.Coefficients;
% 可视化实际值与预测值
figure(2)
plot(1:length(y1_test), y1_test, 'bo-', 'LineWidth', 1.5);
hold on;
plot(1:length(y1_test), y1_pred, 'rx-', 'LineWidth', 1.5);
legend('实际值', '预测值');
xlabel('样本编号');
ylabel('水肿体积变化率');
title('实际值vs 预测值');
% 输出结果
disp('各个治疗方法的系数估计：');
disp(coeffs);
disp(['模型的R方值：', num2str(r2)]);
clear
[data0] = xlsread('题目2（d）所需数据.xlsx', 'Sheet1');
zlff = data0(1:130,2:8);
55



n = 1;
for i = 15:5:size(data0, 2)
kHM(1:130, n) = data0(1:130,i);
n = n+1;
end
n = 1;
for i = 16:5:size(data0, 2)
kED(1:130 , n) = data0(1:130,i);
n = n+1;
end
yHM = min(kHM,[],2);%找出每个患者变化率负值最大的数作为因变量
yED = min(kED,[],2);
data1= horzcat(zlff, yHM);
data2= horzcat(zlff, yED);
r2=0;
while r2<0.9
[trainInd, testInd] = dividerand(size(data2, 1), 0.8, 0.2); % 80%
训练集，20% 测试集
X_train = zlff(trainInd, :);
y_train = yED(trainInd);
X_test = zlff(testInd, :);
y_test = yED(testInd);
% 拟合多元线性回归模型
mdl = fitlm(X_train, y_train);
% 预测结果
y_pred = predict(mdl, X_test);
% 评估模型性能
r2 = corr(y_pred, y_test)^2; % 计算R方值
end
# % 查看模型摘要信息
disp(mdl)
% 查看系数（权重）估计
56



coeffs = mdl.Coefficients;
% 可视化实际值与预测值
figure;
plot(1:length(y_test), y_test, 'bo-', 'LineWidth', 1.5);
hold on;
plot(1:length(y_test), y_pred, 'rx-', 'LineWidth', 1.5);
legend('实际值', '预测值');
xlabel('样本编号');
ylabel('血肿体积变化率');
title('实际值vs 预测值');
disp('各个治疗方法的系数估计：');
disp(coeffs);
disp(['模型的R方值：', num2str(r2)]);
clear
[data0] = xlsread('题目2（d）所需数据.xlsx', 'Sheet1');
VHM1 = data0(1:size(data0, 1) , 10);
n = 1;
for i = 13:5:size(data0, 2)
VHM2(1:size(data0, 1) , n) = data0(1:size(data0, 1),i);
n = n+1;
end
VHM= horzcat(VHM1, VHM2);
VED1 = data0(1:size(data0, 1) , 11);
n = 1;
for i = 14:5:size(data0, 2)
VED2(1:size(data0, 1) , n) = data0(1:size(data0, 1),i);
n = n+1;
end
VED= horzcat(VED1, VED2);
x = VHM(~isnan(VHM));
y = VED(~isnan(VED));
57



scatter (x,y,'filled', 'SizeData', 10 )
xlabel('血肿体积单位：10^-3ml')
ylabel('水肿体积单位：10^-3ml')
r = corr(x, y)
clear
[data0] = xlsread('题目2（d）所需数据.xlsx', 'Sheet1');
zlff = data0(1:130,2:8);
n = 1;
for i = 15:5:size(data0, 2)
kHM(1:130, n) = data0(1:130,i);
n = n+1;
end
n = 1;
for i = 16:5:size(data0, 2)
kED(1:130 , n) = data0(1:130,i);
n = n+1;
end
yHM = min(kHM,[],2);%找出每个患者变化率负值最大的数作为因变量
yED = min(kED,[],2);
data1= horzcat(zlff, yHM);
data2= horzcat(zlff, yED);
r2=0;
while r2<0.9
[trainInd, testInd] = dividerand(size(data1, 1), 0.8, 0.2); % 80%
训练集，20% 测试集
X_train = zlff(trainInd, :);
y_train = yHM(trainInd);
X_test = zlff(testInd, :);
y_test = yHM(testInd);
% 拟合多元线性回归模型
mdl = fitlm(X_train, y_train);
% 预测结果
y_pred = predict(mdl, X_test);
58



% 评估模型性能
r2 = corr(y_pred, y_test)^2; % 计算R方值
end
# % 查看模型摘要信息
disp(mdl)
% 查看系数（权重）估计
coeffs = mdl.Coefficients;
% 可视化实际值与预测值
figure;
plot(1:length(y_test), y_test, 'bo-', 'LineWidth', 1.5);
hold on;
plot(1:length(y_test), y_pred, 'rx-', 'LineWidth', 1.5);
legend('实际值', '预测值');
xlabel('样本编号');
ylabel('血肿体积变化率');
title('实际值vs 预测值');
disp('各个治疗方法的系数估计：');
disp(coeffs);
disp(['模型的R方值：', num2str(r2)]);
附录B 我的Python 源程序
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB
# 读取数据
data = pd.read_excel('题目1（b）所需数据.xlsx')
all = data.iloc[0:160, 3:105]
# 将自变量和因变量分开
## X = data.iloc[0:100, 3:105] # 自变量
y = data.iloc[0:100, 2] # 因变量
59



# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y,
test_size=0.1, random_state=42)
# 创建高斯朴素贝叶斯模型对象
model = GaussianNB()
# 创建伯努利朴素贝叶斯模型对象
model = BernoulliNB(alpha=0.5, binarize=0.1, fit_prior=False,
class_prior=[0.3, 0.7])
# 创建多项式朴素贝叶斯模型对象
model = MultinomialNB()
# 在训练集上训练模型
model.fit(X_train, y_train)
# 在测试集上进行预测
y_pred = model.predict(X_test)
# 输出预测结果
print("预测结果：")
print(y_pred)
# print(y_pred.shape)
# 输出预测概率
print("预测概率：")
print(model.predict_proba(X_test))
answer = model.predict_proba(all)
df = pd.DataFrame(answer)
# df.to_excel('answer(1b)朴素贝叶斯.xlsx', index=False)
df.to_excel('answer(1b).xlsx', index=False)
#-----------------------------------------------------
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans
data = pd.read_excel("题目2（b）所需数据.xlsx")
df1 = data.iloc[:, 1:14].values.astype(float)
inertia =[]
for k in range(1, 11):
kmeans = KMeans(n_clusters=k, random_state=0).fit(df1)
inertia.append(kmeans.inertia_)
#手肘法
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), inertia, marker='*', linestyle='-',
color='r')
60



plt.xlabel("数量")
plt.ylabel("总内部方差")
plt.title("手肘法确定最优数量")
elbow_point = None
for i in range(1, len(inertia)):
slope = (inertia[i - 1] - inertia[i]) / inertia[i - 1]
if slope > 0.4: #选一个适当的网值
elbow_point = i+1
plt.rcParams['font.sans-serif']=["SimHei"]
if elbow_point:
plt.annotate(f'最优簇数量: {elbow_point}', xy=(elbow_point,
inertia[elbow_point - 1]), xytext=(elbow_point + 1, inertia[
elbow_point - 1]), arrowprops=dict(arrowstyle='fancy',
connectionstyle='arc3,rad=.2'))
# plt.grid(True)
plt.show()
optimal_cluster_n = 3
#进行Keans
kmeans = KMeans(n_clusters=optimal_cluster_n, random_state=0)
kmeans.fit(df1)
cluster_labels = kmeans.labels_
data['亚类别'] = cluster_labels
df2 = data.iloc[:, 0:14].copy()
df2['亚类别'] = data.iloc[:, -1]
df2['编号'] = data.iloc[:, 0]#索引为“编号”
df2.set_index('编号', inplace=True)#df2转换为Dataprame
df2_dataframe = pd.DataFrame(df2)
# df2_dataframe.head()
df2_dataframe.to_excel('answer(2b).xlsx', index=False)
#-----------------------------------------------------
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import pandas as pd
from sklearn.model_selection import train_test_split
# 最后一列为因变量（水肿体积变化率）
data = pd.read_excel("data.xlsx")
# 数据预处理
## X = data.iloc[:, :-1] # 自变量数组
61



y = data.iloc[:, -1] # 因变量数组
print(X.shape)
print(y.shape)
# 拆分数据集为训练集和测试集
# train_ratio = 0.7
# train_size = int(train_ratio * X.shape[0])
# X_train = X[:train_size, :]
# y_train = y[:train_size]
# X_test = X[train_size:, :]
# y_test = y[train_size:]
X_train, X_test, y_train, y_test = train_test_split(X, y,
test_size=0., random_state=42)
# 创建和拟合多元线性回归模型
model = LinearRegression()
model.fit(X_train, y_train)
# 预测结果
y_pred = model.predict(X_test)
# 评估模型性能
r2 = r2_score(y_test, y_pred) # 计算R方值
# 查看系数（权重）估计
coeffs = model.coef_
# 输出结果
print('模型的R方值：', r2)
print('各个治疗方法的系数估计：', coeffs)
#-----------------------------------------------------
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score
import pandas as pd
import graphviz
from sklearn import tree
# 读取数据
data = pd.read_excel("题目3（a）所需数据.xlsx")
# 选择特征和目标变量
features = data.iloc[0:100, 3:107]
target = data.iloc[0:100, 1]
all = data.iloc[0:160, 3:107]
62



X_train, X_test, y_train, y_test = train_test_split(features,
target, test_size=0.1, random_state=42)
# 初始化随机森林回归模型
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
# 训练随机森林模型
rf_model.fit(X_train, y_train)
# 预测训练集
Y_rf_pred_train = rf_model.predict(X_train)
# 预测验证集
Y_rf_pred = rf_model.predict(X_test)
# 初始化决策树回归模型
dt_model = DecisionTreeRegressor(random_state=42)
# 训练决策树模型
dt_model.fit(X_train, y_train)
# 预测验证集和训练集
Y_dt_pred_valid = dt_model.predict(X_test)
Y_dt_pred_train = dt_model.predict(X_train)
# 初始化XGBoost回归模型
xgb_model = xgb.XGBRegressor(random_state=42)
# 训练XGBoost模型
xgb_model.fit(X_train, y_train)
# 预测验证集和训练集
Y_xgb_pred_test = xgb_model.predict(X_test)
Y_xgb_pred_train = xgb_model.predict(X_train)
dt_train_mse = mean_squared_error(y_train, Y_dt_pred_train)
xgb_train_mse = mean_squared_error(y_train, Y_xgb_pred_train)
rf_train_mse = mean_squared_error(y_train, Y_rf_pred_train)
print(dt_train_mse)
print(xgb_train_mse)
print(rf_train_mse)
# index = np.arange(1, len(y_train) + 1)
dot_data = tree.export_graphviz(dt_model, out_file=None)
graph = graphviz.Source(dot_data)
graph.render("iris")
graph.view()
plt.figure(figsize=(16, 6))
plt.plot(index, y_train, label="真实值", marker='o')
plt.plot(index, Y_rf_pred_train, label="随机森林训练集预测值",
marker="x")
63



plt.plot(index, Y_dt_pred_train, label="决策树训练集预测值", marker="s")
plt.plot(index, Y_xgb_pred_train, label="XGBoost训练集预测值",
marker="^")
plt.xlabel("序号")
plt.ylabel("数值")
plt.title("训练集真实值vs预测值")
plt.grid(True)
plt.legend()
plt.rcParams['font.sans-serif']=["SimHei"]
# plt.show()
all_result = dt_model.predict(all)
df = pd.DataFrame(all_result)
df.to_excel('answer3_(a).xlsx', index=False)
#-----------------------------------------------------
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.impute import SimpleImputer
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import graphviz
from sklearn import tree
# 读取数据
data = pd.read_excel("题目3（b）所需数据.xlsx")
# 选择特征和目标变量
features = data.iloc[0:405, 4:108]
target = data.iloc[0:405, 1]
all = data.iloc[436:541, 4:108]
X_train, X_test, y_train, y_test = train_test_split(features,
target, test_size=0.1, random_state=42)
# 初始化随机森林回归模型
rf_model = RandomForestRegressor(n_estimators=108, random_state=42)
# 训练随机森林模型
rf_model.fit(X_train, y_train)
# 预测训练集
Y_rf_pred_train = rf_model.predict(X_train)
64



# 预测验证集
Y_rf_pred = rf_model.predict(X_test)
# 初始化决策树回归模型
dt_model = DecisionTreeRegressor(random_state=42)
# 训练决策树模型
dt_model.fit(X_train, y_train)
# 预测验证集和训练集
Y_dt_pred_valid = dt_model.predict(X_test)
Y_dt_pred_train = dt_model.predict(X_train)
# 初始化XGBoost回归模型
xgb_model = xgb.XGBRegressor(random_state=42)
# 训练XGBoost模型
xgb_model.fit(X_train, y_train)
# 预测验证集和训练集
Y_xgb_pred_test = xgb_model.predict(X_test)
Y_xgb_pred_train = xgb_model.predict(X_train)
dt_train_mse = mean_squared_error(y_train, Y_dt_pred_train)
xgb_train_mse = mean_squared_error(y_train, Y_xgb_pred_train)
rf_train_mse = mean_squared_error(y_train, Y_rf_pred_train)
print(dt_train_mse)
print(xgb_train_mse)
print(rf_train_mse)
index = np.arange(1, len(y_train) + 1)
plt.figure(figsize=(16, 6))
plt.plot(index, y_train, label="真实值", marker='o')
plt.plot(index, Y_rf_pred_train, label="随机森林训练集预测值",
marker="x")
plt.plot(index, Y_dt_pred_train, label="决策树训练集预测值", marker="s")
plt.plot(index, Y_xgb_pred_train, label="XGBoost训练集预测值",
marker="^")
plt.xlabel("序号")
plt.ylabel("数值")
plt.title("训练集真实值vs预测值")
plt.grid(True)
plt.legend()
plt.rcParams['font.sans-serif']=["SimHei"]
plt.show()
all_result = dt_model.predict(all)
df = pd.DataFrame(all_result)
65



df.to_excel('answer3_(b).xlsx', index=False)
dot_data = tree.export_graphviz(dt_model, out_file=None)
graph = graphviz.Source(dot_data)
graph.render("iris")
#-----------------------------------------------------
import pandas as pd
data = pd.read_excel("3(c)所需数据.xlsx")
# df = data.iloc[:, 43:]
df = data.iloc[:, 43:86] # HM
print(df.shape)
rms = data.iloc[:, 0]
print(rms)
df1 = pd.concat([rms, df])
print(df1.shape)
data = pd.DataFrame(np.random.rand(100, 107), columns=[f"Var{i}"
for i in range(1, 107)])
correlation_matrix = df.corr()
# 绘制热力图
plt.rcParams['font.sans-serif'] = ["SimHei"]
plt.figure(figsize=(10, 10))
sns.heatmap(correlation_matrix, cmap="coolwarm", annot=True,
fmt=".2f", linewidths=0.5, linecolor='black')
plt.title("rms与HM影像特征相关性图像")
plt.savefig("rms与HM影像特征相关性图像.png", dpi=600, bbox_inches="tight")
plt.show()
all_result = dt_model.predict(features)
df1 = pd.DataFrame(correlation_matrix)
df1.to_excel('answer3_(c).xlsx', index=False)
#-----------------------------------------------------
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
# 创建一个包含106个自变量和1个因变量的数据集
np.random.seed(0)
data = pd.read_excel("3(c)所需数据- 副本.xlsx")
df = data.iloc[:, :]
print(df.shape)
# data = pd.DataFrame(np.random.rand(100, 107), columns=[f"Var{i}"
66



for i in range(1, 107)])
correlation_matrix = df.corr()
# 绘制热力图
plt.rcParams['font.sans-serif'] = ["SimHei"]
plt.figure(figsize=(20, 20))
sns.heatmap(correlation_matrix, cmap="coolwarm", annot=True,
fmt=".2f", linewidths=0.5, linecolor='black')
plt.title("rms与个人史、疾病史、治疗方法相关性图像")
plt.savefig("rms与个人史、疾病史、治疗方法相关性图像.png", dpi=600,
bbox_inches="tight")
plt.show()
67
