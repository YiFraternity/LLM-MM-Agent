\begin{center}
\includegraphics[width=0.2\textwidth]{image1.png} \quad
\includegraphics[width=0.2\textwidth]{image2.png} \quad
\includegraphics[width=0.2\textwidth]{image3.png} \quad
\includegraphics[width=0.2\textwidth]{image4.png} \quad
\includegraphics[width=0.2\textwidth]{image5.png}
\end{center}

\begin{center}
\textbf{中国研究生创新实践系列大赛} \\
\textbf{“华为杯”第二十届中国研究生} \\
\textbf{数学建模竞赛}
\end{center}

\begin{table}[h]
\centering
\begin{tabular}{l l}
学校 & 电子科技大学 \\
\hline
参赛队号 & 23106140164 \\
\hline
队员姓名 & 1. 李紫荆 \\
 & 2. 何诗宇 \\
 & 3. 龙子璇 \\
\end{tabular}
\end{table}

\begin{center}
\textbf{中国研究生创新实践系列大赛}\\
\textbf{“华为杯”第二十届中国研究生}\\
\textbf{数学建模竞赛}
\end{center}

\textbf{题 目：} \underline{DFT 类矩阵的整数分解逼近问题研究}

\section*{摘 要}

随着芯片的发展，DFT 计算的硬件复杂度与其算法复杂度和数据元素取值范围相关，如何降低硬件复杂度至关重要。本文针对 DFT 矩阵分解中的问题，基于稀疏矩阵连乘拟合的思想，以最小化误差和硬件复杂度为目标，建立了 DFT 类矩阵的整数分解逼近模型，并使用蝶形分解算法、遗传算法、Feig-Winograd 算法和优化搜索算法对模型进行求解，同时我们提出了两种新的“混合积分分解—降维寻优”算法来拟合 Kronecker 积矩阵。

问题一的目标是限制乘法器的个数从而降低硬件复杂度。对此，本文采用 Cooley-Tukey 算法，根据蝶形运算的对称性，把 $N$ 阶 DFT 矩阵分解为 $\log_2(N)+1$ 个稀疏子矩阵的乘积。该方法分解效率高，且能达到 $10^{-17}$ 的高精度，复杂度如 3.4 表 2 所示。

问题二的目标是限制分解矩阵中的元素实虚部的取值，对此采用了基于 Feig-Winograd 矩阵映射的算法、遗传算法、序列二次规划算法，评估了三种不同算法的误差和复杂度，三种算法的复杂度都为 0，遗传算法的精度最高，RMSE 最小可达 0.15。

问题三的目标是保证矩阵稀疏性的同时限制元素范围，除了采用遗传算法，还提出了一种新的优化搜索算法保证分解结果的精度和复杂度。两种算法的硬件复杂度都为 0，遗传算法分解的矩阵 RMSE 可达 0.08，优化搜索算法 RMSE 最小可达 0.03。因为优化搜索算法优秀的性能和较短的训练时间，问题五选择采用此方法进行求解。

问题四的目标是分解 DFT 矩阵的 Kronecker 积，并且要同时限制分解矩阵的稀疏性和元素范围。对此，结合 Cooley-Tukey 算法、Kronecker 积的运算性质、矩阵初等行变换、遗传算法这四种基本原理，本文提出两种新的“混合积分分解—降维寻优法”。这两种方法都能达到 RMSE 最小可达 0.05。其中，方法 II 的复杂度为 0，方法 I 的复杂度如 6.4 表 6 所示。

问题五的目标是在 $RMSE \leq 0.1$ 的前提下同时满足问题三的约束条件，改进的优化搜索算法在把元素搜索范围提升到 $P=[0, \pm 1, \pm 2, \pm 4, \pm 8]$ 的情况下，硬件复杂度都为 0，8 阶 DFT 矩阵分解精度 RMSE 可达 0.095。

最后，我们通过衡量最小误差和硬件复杂度，对提出的模型进行全面的评价：本文的模型贴合实际，能合理解决提出的问题，计算得出的 RMSE 较小，能很好地拟合 DFT 矩阵，部分模型复杂度较低，该模型在大规模 DFT 类矩阵的整数分解方面也能使用。

\textbf{关键词：} 稀疏矩阵，蝶形算法，遗传算法，优化搜索，混合积分解—降维寻优

\section*{目录}
\begin{itemize}
    \item[1] 问题重述 \dotfill 4
    \begin{itemize}
        \item[1.1] 问题背景 \dotfill 4
        \item[1.2] 问题提出 \dotfill 5
    \end{itemize}
    \item[2] 符号说明与整体思路 \dotfill 5
    \begin{itemize}
        \item[2.1] 符号说明 \dotfill 5
        \item[2.2] 整体思路 \dotfill 6
    \end{itemize}
    \item[3] 问题一的模型建立与求解 \dotfill 6
    \begin{itemize}
        \item[3.1] 问题分析 \dotfill 6
        \item[3.2] 模型建立 \dotfill 7
        \item[3.3] 基于 Cooley-Tukey 算法的分解方法 \dotfill 7
        \item[3.4] 结果与分析 \dotfill 11
        \item[3.5] 总结与评价 \dotfill 14
        \begin{itemize}
            \item[3.5.1] 模型优点 \dotfill 14
            \item[3.5.2] 模型缺点 \dotfill 14
        \end{itemize}
    \end{itemize}
    \item[4] 问题二的模型建立与求解 \dotfill 14
    \begin{itemize}
        \item[4.1] 问题分析 \dotfill 14
        \item[4.2] 模型建立 \dotfill 15
        \item[4.3] 问题求解 \dotfill 15
        \begin{itemize}
            \item[4.3.1] 基于 FEIG-WINOGRAD 矩阵映射的分解方法 \dotfill 15
            \item[4.3.2] 基于序列二次规划 SQP 的分解方法 \dotfill 21
            \item[4.3.3] 基于遗传算法的分解方法 \dotfill 23
        \end{itemize}
        \item[4.4] 结果与分析 \dotfill 26
        \item[4.5] 总结与评价 \dotfill 26
    \end{itemize}
    \item[5] 问题三的模型建立与求解 \dotfill 26
    \begin{itemize}
        \item[5.1] 问题分析 \dotfill 26
        \item[5.2] 模型建立 \dotfill 26
        \item[5.3] 问题求解 \dotfill 27
        \begin{itemize}
            \item[5.3.1] 基于优化搜索的分解方法 \dotfill 27
            \item[5.3.2] 基于遗传算法的分解方法 \dotfill 29
        \end{itemize}
        \item[5.4] 结果与分析 \dotfill 31
        \item[5.5] 总结与评价 \dotfill 32
    \end{itemize}
    \item[6] 问题四的模型建立与求解 \dotfill 32
    \begin{itemize}
        \item[6.1] 问题分析 \dotfill 32
        \item[6.2] 模型建立 \dotfill 32
        \item[6.3] 问题求解 \dotfill 33
        \begin{itemize}
            \item[6.3.1] 基于“混合积分解—降维寻优”算法 I 的分解方法 \dotfill 33
        \end{itemize}
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item[6.3.2] 基于“混合积分解—降维寻优”算法Ⅱ的分解方法 \dotfill 36
    \item[6.4] 结果与分析 \dotfill 38
    \item[6.5] 总结与评价 \dotfill 38
        \begin{itemize}
            \item[6.5.1] 模型优点 \dotfill 38
            \item[6.5.2] 模型缺点 \dotfill 38
        \end{itemize}
    \item[7] 问题五的模型建立与求解 \dotfill 38
        \begin{itemize}
            \item[7.1] 问题分析 \dotfill 38
            \item[7.2] 模型建立 \dotfill 39
            \item[7.3] 基于优化搜索的分解方法 \dotfill 39
            \item[7.4] 结果与分析 \dotfill 40
            \item[7.5] 总结与评价 \dotfill 41
        \end{itemize}
    \item[8] 总结与展望 \dotfill 41
    \item 参考文献 \dotfill 42
    \item 附录 \dotfill 43
\end{itemize}

\section{问题重述}

\subsection{问题背景}

离散傅里叶变换（Discrete Fourier Transform, DFT）作为一种基本工具广泛应用于工程、科学以及数学领域。例如，通信信号处理中，常用 DFT 实现信号的正交频分复用（Orthogonal Frequency Division Multiplexing, OFDM）系统的时频域变换。另外，在信道估计中，也需要用到逆 DFT（IDFT）和 DFT 以便对信道估计结果进行时域降噪。

在芯片设计中，DFT 计算的硬件复杂度与其算法复杂度和数据元素取值范围相关。算法复杂度越高、数据取值范围越大，则硬件复杂度就越大。目前在实际产品中，一般采用快速傅里叶变换（Fast Fourier Transform, FFT）算法来快速实现 DFT，其利用 DFT 变换的各种性质，可以大幅降低 DFT 的计算复杂度。然而，随着无线通信技术的演进，天线阵面越来越大，通道数越来越多，通信带宽越来越大，对 FFT 的需求也越来越大，从而导致专用芯片上实现 FFT 的硬件开销也越大。为进一步降低芯片资源开销，一种可行的思路是将 DFT 矩阵分解成整数矩阵连乘的形式。

给定 $N$ 点的时域一维复数信号 $x_0, x_1, \ldots, x_{N-1}$，DFT 后得到的复数信号 $X_k$（$k = 0, 1, \ldots, N-1$）由下式给出（其中 $j$ 为虚数单位，下同）：

\[
X_k = \sum_{n=0}^{N-1} x_n \cdot e^{-\frac{j 2 \pi n k}{N}}, \quad k = 0, 1, 2, \ldots, N-1
\]

写成矩阵形式为：

\[
\mathbf{X} = \mathbf{F}_N \mathbf{x}
\]

其中 $\mathbf{x} = [x_0 \ x_1 \ \cdots \ x_{N-1}]^{\mathrm{T}}$ 为时域信号向量，$\mathbf{X} = [X_0 \ X_1 \ \cdots \ X_{N-1}]^{\mathrm{T}}$ 为变换后的频域信号向量，$\mathbf{F}_N$ 为 DFT 矩阵，形式如下：

\[
\mathbf{F}_N = \frac{1}{\sqrt{N}} \begin{bmatrix}
1 & 1 & 1 & \cdots & 1 \\
1 & w & w^2 & \cdots & w^{N-1} \\
1 & w^2 & w^4 & \cdots & w^{2(N-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & w^{N-1} & w^{2(N-1)} & \cdots & w^{(N-1)(N-1)}
\end{bmatrix}, \quad w = e^{-\frac{j 2 \pi}{N}}
\]

由于 DFT 矩阵的特殊结构，存在很多方法加速傅里叶变换的计算，其中，分治的策略以及蝶形计算单元的优化是 DFT 性能的关键。下面分别给出用 FFT 和矩阵连乘拟合近似计算 DFT 的具体思路。

\textbf{FFT 思路：} FFT 采用蝶形运算的思想，以 radix-3 蝶形计算为例，其计算过程可以表示为：

\[
\begin{bmatrix}
X_0 \\
X_1 \\
X_2
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0 \\
1 & -3 & -1 \\
1 & -3 & 1
\end{bmatrix}
\begin{bmatrix}
1 & 1 & 0 \\
0 & 1/2 & 0 \\
0 & 0 & \sqrt{3}j/2
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 1 \\
0 & 1 & -1
\end{bmatrix}
\begin{bmatrix}
x_0 \\
x_1 \\
x_2
\end{bmatrix}
\]

可以看到蝶形的设计相对于直接 DFT 矩阵乘积的形式大幅降低了复数乘法运算的次数。

\textbf{矩阵连乘拟合思路：} DFT 可以用传统的蝶形计算方法精确实现，也可以用一种矩阵乘法拟合近似获得，其核心思想是将 DFT 矩阵近似表达为一连串稀疏的、元素取值有限的矩阵连乘形式。

可以看到在该方案中，分解后的矩阵元素均为整数，从而降低了每个乘法器的复杂度；另外 $\mathbf{A}_1 \sim \mathbf{A}_4$ 的稀疏特性可以减少乘法运算数量。可以看出，这其实是一种精度与硬件复杂度的折中方案，即损失了一定的计算精度，但是大幅降低了硬件复杂度。在对输出信噪比要求不高的情况下可以优先考虑此类方案。

\subsection{问题提出}

问题一：首先通过减少乘法器个数来降低硬件复杂度。由于仅在非零元素相乘时需要使用乘法器，若 $\mathbf{A}_k$ 矩阵中大部分元素均为 0，则可减少乘法器的个数，因此希望 $\mathbf{A}_k$ 为稀疏矩阵。对于 $N=2^t, t=1,2,3,\ldots$ 的 DFT 矩阵 $\mathbf{F}_N$，请在满足约束 1 的条件下，对最优化问题 (6) 中的变量 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$ 进行优化，并计算最小误差（即 (6) 的目标函数，下同）和方案的硬件复杂度 $C$（由于本题中没有限定 $\mathbf{A}_k$ 元素的取值范围，因此在计算硬件复杂度时可默认 $q=16$）。

问题二：讨论通过限制 $\mathbf{A}_k$ 中元素实部和虚部取值范围的方式来减少硬件复杂度的方案。对于 $N=2^t, t=1,2,3,4,5$ 的 DFT 矩阵 $\mathbf{F}_N$，请在满足约束 2 的条件下，对 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$ 进行优化，并计算最小误差和方案的硬件复杂度 $C$。

问题三：同时限制 $\mathbf{A}_k$ 的稀疏性和取值范围。对于 $N=2^t, t=1,2,3,4,5$ 的 DFT 矩阵 $\mathbf{F}_N$，请在同时满足约束 1 和 2 的条件下，对 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$ 进行优化，并计算最小误差和方案的硬件复杂度 $C$。

问题四：进一步研究对其它矩阵的分解方案。考虑矩阵 $\mathbf{F}_N = \mathbf{F}_{N_1} \otimes \mathbf{F}_{N_2}$，其中 $\mathbf{F}_{N_1}$ 和 $\mathbf{F}_{N_2}$ 分别是 $N_1$ 和 $N_2$ 维的 DFT 矩阵，$\otimes$ 表示 Kronecker 积（注意 $\mathbf{F}_N$ 非 DFT 矩阵）。当 $N_1=4, N_2=8$ 时，请在同时满足约束 1 和 2 的条件下，对 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$ 进行优化，并计算最小误差和方案的硬件复杂度。

问题五：在问题 3 的基础上加上精度的限制来研究矩阵分解方案。要求将精度限制在 0.1 以内，即 RMSE $\leqslant 0.1$。对于 $N=2^t, t=1,2,3,4,5$ 的 DFT 矩阵 $\mathbf{F}_N$，请在同时满足约束 1 和 2 的条件下，对 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$，$\mathcal{P}$ 进行优化，并计算方案的硬件复杂度 $C$。

\section{符号说明与整体思路}

\subsection{符号说明}

符号说明如表 1 所示。

\begin{table}[h]
\centering
\caption{符号说明}
\begin{tabular}{c c}
\hline
\textbf{符号} & \textbf{含义} \\
\hline
$\mathcal{A}$ & $\{\mathbf{A}_1, \ldots, \mathbf{A}_K\}$ 为分解的系数矩阵 \\
$K$ & 分解的矩阵个数 \\
$\boldsymbol{\beta}$ & 实值矩阵缩放因子 \\
$\mathbf{F}_N$ & $N$ 阶 DFT 矩阵 \\
$\mathbf{I}_N$ & $N$ 阶单位矩阵 \\
$\mathbf{P}$ & 排列矩阵 \\
$\mathbf{D}$ & 对角矩阵 \\
$C$ & 乘法器的硬件复杂度 \\
$\mathcal{P}$ & $\mathbf{A}_k$ 中元素实部和虚部的取值范围 \\
$L$ & 复数乘法的次数 \\
$B$ & $\boldsymbol{\beta}$ 的量化复杂度 \\
$\mathbf{D}_k$ & 标记 $\mathbf{A}_k$ 中非简单元素位置的二进制矩阵 \\
$\mathbf{P}_k$ & 标记 $\mathbf{A}_k$ 中非零元素位置的二进制矩阵 \\
\hline
\end{tabular}
\end{table}

\subsection{整体思路}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{本文技术路线}
    \label{fig:technical_route}
\end{figure}

\section{问题一的模型建立与求解}

\subsection{问题分析}

问题一是通过减少乘法器的个数来降低硬件复杂度。也就是要求 $\mathbf{A}_k$ 为稀疏矩阵。由于问题一只在约束 1 下完成目标函数的最优求解，不限定 $\mathbf{A}_k$ 元素的取值范围。对此，本文采用 Cooley-Tukey 算法 \cite{ref1, ref2, ref3} 把 DFT 矩阵 $\mathbf{F}_N$ 分解为若干稀疏子矩阵的乘积，如式 (1) 所示

\begin{equation}
    \mathbf{F}_N = \beta \mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}
    \tag{1}
\end{equation}

其中 $\beta$ 是实矩阵缩放因子，并且 $\mathbf{A}_1, \ldots, \mathbf{A}_K$ 和 $\mathbf{P}$ 都是稀疏矩阵。

需要注意的是，$\mathbf{P}$ 是一种排列矩阵，$\mathbf{P}$ 是若干个初等列变换矩阵的乘积。$\mathbf{A}_1 \cdots \mathbf{A}_K$ 右乘以 $\mathbf{P}$ 可以理解为矩阵 $\mathbf{P}$ 仅仅调换 $\mathbf{A}_1 \cdots \mathbf{A}_K$ 列的顺序，这种列顺序变换操作并不会增加乘法复杂度。附录所示的 MATLAB 程序也可以验证 $\mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$ 与 $\mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1$ 的乘法复杂度是相同的。

$\mathbf{A}_1, \ldots, \mathbf{A}_K$ 和 $\mathbf{P}$ 的分解过程具体在 3.3 小节中描述。

\subsection{模型建立}

分解之后的矩阵与误差及硬件复杂度之间的对应关系可以建立模型来表达，前文中已模型中相关符号进行定义，根据问题描述和表 1 内给出的参数变量符号，分解之后的矩阵与误差及硬件复杂度之间的关系可以采用以下数学模型来表示：

\textbf{目标函数:}

问题一的优化目标有三个，分别是变量 $\boldsymbol{A}$，$\boldsymbol{\beta}$ 和乘法器个数 $L$，这是典型的多目标问题，我们对每个目标进行加权，使其变成单目标问题，具体如下:

1) 目标函数最小化
\begin{equation}
F = \min \left\{ RMSE(\boldsymbol{A}, \boldsymbol{\beta}) q_1 + B q_2 + L q_3 \right\}
\tag{2}
\end{equation}
其中: $q$ 为权重，$q_1 = 0.6$，$q_2 = 0.2$，$q_3 = 0.2$。

2) 优化目标一
使计算误差最小，即:
\begin{equation}
RMSE(\boldsymbol{A}, \boldsymbol{\beta}) = \frac{1}{N} \sqrt{\left\| \mathbf{F}_N - \boldsymbol{\beta} \mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \right\|_F^2}
\tag{3}
\end{equation}

3) 优化目标二
要优化 $\boldsymbol{\beta}$，使 $\boldsymbol{\beta}$ 的复杂度也最小，定义 $B$ 的定义与 $P$ 相似，使 $\boldsymbol{\beta}$ 能用更小的位宽表示出来
\begin{equation}
B = \left| \log_2 \boldsymbol{\beta} \right|
\tag{4}
\end{equation}

4) 优化目标三
用 $\mathbf{D}_1, \mathbf{D}_2, \ldots, \mathbf{D}_K$ 矩阵分别表示对应 $\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_K$ 矩阵非简单元素的位置（$0$、$\pm 1$、$\pm j$ 不需要计算复杂度，所以把它们记为简单元素），即非简单元素标记为 $1$，简单元素标记为 $0$，得到 $\mathbf{D}_1, \mathbf{D}_2, \ldots, \mathbf{D}_K$ 矩阵为二进制矩阵。

把 $\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_K$ 矩阵映射到 $\mathbf{D}_1, \mathbf{D}_2, \ldots, \mathbf{D}_K$ 矩阵的操作记为 $dif$，$\mathbf{D}_k = dif(\mathbf{A}_k)$，得到乘法器的个数 $L$ 为
\begin{equation}
L = \sum_{i=1}^N \sum_{j=1}^N \mathbf{D}_K dif(\mathbf{A}_{K-1} \cdots \mathbf{A}_2 \mathbf{A}_1) + \cdots + \sum_{i=1}^N \sum_{j=1}^N \mathbf{D}_3 dif(\mathbf{A}_2 \mathbf{A}_1) + \sum_{i=1}^N \sum_{j=1}^N \mathbf{D}_2 \mathbf{D}_1
\tag{5}
\end{equation}

\textbf{约束条件:}

用 $\mathbf{P}_1, \mathbf{P}_2, \ldots, \mathbf{P}_K$ 矩阵分别表示对应 $\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_K$ 矩阵非零元素的位置，即非零元素标记为 $1$，零元素标记为 $0$，得到 $\mathbf{P}_1, \mathbf{P}_2, \ldots, \mathbf{P}_K$ 矩阵为二进制矩阵。

每个矩阵的每行至多只有 $2$ 个非零元素
\begin{equation}
\sum_{j=1}^N \mathbf{P}_k(i, j) \leq 2
\tag{6}
\end{equation}
其中 $k = 1, 2, \ldots, K$，$i = 1, 2, \ldots, N$，$\mathbf{P}_k(i, j)$ 表示 $\mathbf{P}_k$ 矩阵第 $i$ 行第 $j$ 列的元素。

\subsection{基于 Cooley-Tukey 算法的分解方法}

Cooley-Tukey 的基本思想是把一个合数点数的 $N = N_1 N_2$ 点 DFT 拆分成 $N_1$ 个 $N_2$ 点 DFT。下面 $\mathbf{F}_8$ 矩阵为例，给出 DFT 矩阵的 Cooley-Tukey 分解过程，即为蝶形运算，示意图如图 2 所示。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{butterfly_diagram.png}
    \caption{蝶形算法示意图}
    \label{fig:butterfly}
\end{figure}

已知 8 点的 DFT 可以写成下形式:
\begin{equation}
\begin{bmatrix}
X(0) \\
X(1) \\
X(2) \\
X(3) \\
X(4) \\
X(5) \\
X(6) \\
X(7)
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & W_{8} & W_{8}^{2} & W_{8}^{3} & W_{8}^{4} & W_{8}^{5} & W_{8}^{6} & W_{8}^{7} \\
1 & W_{8}^{2} & W_{8}^{4} & W_{8}^{6} & W_{8}^{8} & W_{8}^{10} & W_{8}^{12} & W_{8}^{14} \\
1 & W_{8}^{3} & W_{8}^{6} & W_{8}^{9} & W_{8}^{12} & W_{8}^{15} & W_{8}^{18} & W_{8}^{21} \\
1 & W_{8}^{4} & W_{8}^{8} & W_{8}^{12} & W_{8}^{16} & W_{8}^{20} & W_{8}^{24} & W_{8}^{28} \\
1 & W_{8}^{5} & W_{8}^{10} & W_{8}^{15} & W_{8}^{20} & W_{8}^{25} & W_{8}^{30} & W_{8}^{35} \\
1 & W_{8}^{6} & W_{8}^{12} & W_{8}^{18} & W_{8}^{24} & W_{8}^{30} & W_{8}^{36} & W_{8}^{42} \\
1 & W_{8}^{7} & W_{8}^{14} & W_{8}^{21} & W_{8}^{28} & W_{8}^{35} & W_{8}^{42} & W_{8}^{49}
\end{bmatrix}
\begin{bmatrix}
x(0) \\
x(1) \\
x(2) \\
x(3) \\
x(4) \\
x(5) \\
x(6) \\
x(7)
\end{bmatrix}
\tag{7}
\end{equation}
其中 $\left[x(0) \cdots x(7)\right]^{T}$ 是时域信号，$\left[X(0) \cdots X(7)\right]^{T}$ 是频域信号。

第一步，对 $\left[x(0) \cdots x(7)\right]^{T}$ 做时域抽取重新排列顺序可得
\begin{equation}
\begin{bmatrix}
x(0) \\
x(4) \\
x(2) \\
x(6) \\
x(1) \\
x(5) \\
x(3) \\
x(7)
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
x(0) \\
x(1) \\
x(2) \\
x(3) \\
x(4) \\
x(5) \\
x(6) \\
x(7)
\end{bmatrix}
\tag{8}
\end{equation}

第二步，把重排后的序列分成 4 组，每组做 2-DFT 变换，例如，对 $\left[x(0) \ x(4)\right]^{T}$ 做 2-DFT 变换，可得
\begin{equation}
\begin{bmatrix}
G_{1}(0) \\
G_{1}(1)
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 \\
1 & -1
\end{bmatrix}
\begin{bmatrix}
x(0) \\
x(4)
\end{bmatrix}
\tag{9}
\end{equation}

那么，做完 4 组 2-DFT 变换可得

\begin{equation}
\begin{bmatrix}
G_{1}(0) \\
G_{1}(1) \\
G_{2}(0) \\
G_{2}(1) \\
G_{3}(0) \\
G_{3}(1) \\
G_{4}(0) \\
G_{4}(1)
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & -1
\end{bmatrix}
\begin{bmatrix}
x(0) \\
x(4) \\
x(2) \\
x(6) \\
x(1) \\
x(5) \\
x(3) \\
x(7)
\end{bmatrix}
\tag{10}
\end{equation}

第三步，由 2-DFT 样点合成 4-DFT 样点，例如，由(10)中的 4 个 2-DFT 样点 $G_{1}(0), G_{1}(1), G_{2}(0), G_{2}(1)$ 合成 4-DFT，如式(11)所示

\begin{equation}
\begin{bmatrix}
F_{1}(0) \\
F_{1}(1) \\
F_{2}(2) \\
F_{2}(3)
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 1 & 0 \\
0 & 1 & 0 & W_{8}^{2} \\
1 & 0 & -1 & 0 \\
0 & 1 & 0 & -W_{8}^{2}
\end{bmatrix}
\begin{bmatrix}
G_{1}(0) \\
G_{1}(1) \\
G_{2}(0) \\
G_{2}(0)
\end{bmatrix}
\tag{11}
\end{equation}

那么，合成后的 4-DFT 样点可以表示为 $\left[F_{1}(0) \cdots F_{2}(1)\right]^{T}$，如式(12)所示

\begin{equation}
\begin{bmatrix}
F_{1}(0) \\
F_{1}(1) \\
F_{1}(2) \\
F_{1}(3) \\
F_{2}(0) \\
F_{2}(1) \\
F_{2}(2) \\
F_{2}(3)
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & W_{8}^{2} & 0 & 0 & 0 & 0 \\
1 & 0 & -1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & -W_{8}^{2} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & W_{8}^{2} \\
0 & 0 & 0 & 0 & 1 & 0 & -1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & -W_{8}^{2}
\end{bmatrix}
\begin{bmatrix}
G_{1}(0) \\
G_{1}(1) \\
G_{2}(0) \\
G_{2}(1) \\
G_{3}(0) \\
G_{3}(1) \\
G_{4}(0) \\
G_{4}(1)
\end{bmatrix}
\tag{12}
\end{equation}

第四步，由 4-DFT 样点 $\left[F_{1}(0) \cdots F_{2}(1)\right]^{T}$ 即可合成所需的 8-DFT 频域信号 $\left[X(0) \cdots X(7)\right]^{T}$，如式(13)所示

\begin{equation}
\begin{bmatrix}
X(0) \\
X(1) \\
X(2) \\
X(3) \\
X(4) \\
X(5) \\
X(6) \\
X(7)
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & W_{s} & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & W_{s}^{2} & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & W_{s}^{3} \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & -W_{s} & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -W_{s}^{2} & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -W_{s}^{3}
\end{bmatrix}
\begin{bmatrix}
F_{1}(0) \\
F_{1}(1) \\
F_{1}(2) \\
F_{1}(3) \\
F_{2}(0) \\
F_{2}(1) \\
F_{2}(2) \\
F_{2}(3)
\end{bmatrix}
\tag{13}
\end{equation}

综上所述，$\mathbf{F}_{8} = \mathbf{A}_{3} \mathbf{A}_{2} \mathbf{A}_{1} \mathbf{P}$，其中，$\mathbf{P}, \mathbf{A}_{1}, \mathbf{A}_{2}, \mathbf{A}_{3}$ 分别如下所示，可见 $\mathbf{P}, \mathbf{A}_{1}, \mathbf{A}_{2}, \mathbf{A}_{3}$ 均是满足约束 1 的稀疏矩阵。

\begin{equation}
\mathbf{P} = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\tag{14}
\end{equation}

\begin{equation}
\mathbf{A}_1 = 
\begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 \\
1 & -1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 0 & 1 & -1
\end{bmatrix}
\tag{15}
\end{equation}

\begin{equation}
\mathbf{A}_2 = 
\begin{bmatrix}
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & W_8^2 & 0 & 0 & 0 \\
1 & 0 & -1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & -W_8^2 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & W_8^2 \\
0 & 0 & 0 & 0 & 1 & 0 & -1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & -W_8^2
\end{bmatrix}
\tag{16}
\end{equation}

\begin{equation}
\mathbf{A}_3 = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & W_s & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & W_s^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & W_s^3 \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & -W_s & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -W_s^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -W_s^3
\end{bmatrix}
\tag{17}
\end{equation}

\subsection{结果与分析}

本文采用 MATLAB 实现上述模型，可以完成对 $N=2^t, t=1, 2, 3, \ldots$ 阶 DFT 矩阵的分解，当 $N=2, 4, 8, 16, 32$ 时，DFT 矩阵 $\mathbf{F}_N$ 分解后的计算复杂度和 RMSE 的值如表 2 所示。

\begin{table}[h]
\centering
\caption{问题一的硬件复杂度}
\begin{tabular}{c c c c c c}
\hline
阶数 $N$ & 2 & 4 & 8 & 16 & 32 \\
\hline
硬件复杂度 $C$ & 0 & 0 & 0 & 512 & 5120 \\
\hline
\end{tabular}
\end{table}

绘制得到图像如下

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{问题一的硬件复杂度}
\end{figure}

如图 3 所示，阶数 $N$ 为 2, 4, 8 时硬件复杂度为 0，$N$ 为 16 时硬件复杂度为 512，$N$ 为 32 时硬件复杂度为 5120，由图像可以看出复杂度随指数型增长，所以在后续问题中需要元素实部和虚部取值范围来减小复杂度。

受文档纸张大小限制，以下展示 $\mathbf{F}_2, \mathbf{F}_4, \mathbf{F}_8, \mathbf{F}_{16}$ 的分解结果：

(1) 当 $N=2$ 时，$\mathbf{F}_2 = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}$，$\mathbf{F}_2$ 的所有元素都是简单元素，满足约束 1；

(2) 当 $N=4$ 时，$\mathbf{F}_4 = \beta \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$，取 $\beta = \frac{1}{2}$，分解后的稀疏矩阵为
\[
\mathbf{P} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}, \quad
\mathbf{A}_1 = \begin{bmatrix} 1 & 1 & 0 & 0 \\ 1 & -1 & 0 & 0 \\ 0 & 0 & 1 & 1 \\ 0 & 0 & 1 & -1 \end{bmatrix}, \quad
\mathbf{A}_2 = \begin{bmatrix} 1 & 0 & 1 & 0 \\ 0 & 1 & 0 & W_4^1 \\ 1 & 0 & -1 & 0 \\ 0 & 1 & 0 & -W_4^1 \end{bmatrix}
\]

(3) 当 $N=8$ 时，$\mathbf{F}_8 = \beta \mathbf{A}_3 \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$，取 $\beta = \frac{1}{\sqrt{8}}$，分解后的稀疏矩阵为

\[
\mathbf{P} = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\quad
\mathbf{A}_1 = 
\begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & -1
\end{bmatrix}
\]

\[
\mathbf{A}_2 = 
\begin{bmatrix}
1 & 0 & 1 & 0 & \cdots & \mathbf{0} \\
0 & 1 & 0 & W_8^2 & \vdots & \vdots \\
1 & 0 & -1 & 0 & \ddots & \vdots \\
0 & 1 & 0 & -W_8^2 & & \vdots \\
\vdots & \ddots & & & 1 & 0 & 1 & 0 \\
\vdots & & & & 0 & 1 & 0 & W_8^2 \\
\mathbf{0} & \cdots & & & 1 & 0 & -1 & 0 \\
& & & & 0 & 1 & 0 & -W_8^2
\end{bmatrix}
\quad
\mathbf{A}_3 = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & W_8 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & W_8^3 \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & -W_8 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -W_8^3
\end{bmatrix}
\]

(4) 当 \( N=16 \) 时，\(\mathbf{F}_{16} = \mathbf{A}_4 \mathbf{A}_3 \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}\)，取 \(\beta = \frac{1}{4}\)，分解后的稀疏矩阵为

\[
\mathbf{P} = \left[ e_0 e_8 e_4 e_{12} e_2 e_{10} e_6 e_{14} e_1 e_9 e_5 e_{13} e_3 e_{11} e_7 e_{15} \right]
\]

\[
\mathbf{A}_1 = 
\begin{bmatrix}
1 & 1 & \cdots & \cdots & \mathbf{0} \\
1 & -1 & & & \\
1 & 1 & & & \\
1 & -1 & & & \\
\vdots & & 1 & 1 & \\
\vdots & & 1 & -1 & \\
\vdots & & 1 & 1 & \\
\vdots & & 1 & -1 & \\
\mathbf{0} & & \cdots & \cdots & 1 & 1 \\
& & & & 1 & -1 \\
& & & & 1 & 1 \\
& & & & 1 & -1 \\
& & & & 1 & 1 \\
& & & & 1 & -1 \\
& & & & 1 & 1 \\
& & & & 1 & -1
\end{bmatrix}
\]

\[
\mathbf{A}_{2} = 
\begin{bmatrix}
1 & 0 & 1 & 0 & & & & \mathbf{O} \\
0 & 1 & 0 & W_{16}^{4} & & & & \\
1 & 0 & -1 & 0 & & & & \\
0 & 1 & 0 & -W_{16}^{4} & & & & \\
& & & & 1 & 0 & 1 & 0 \\
& & & & 0 & 1 & 0 & W_{16}^{4} \\
& & & & 1 & 0 & -1 & 0 \\
& & & & 0 & 1 & 0 & -W_{16}^{4} \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots \\
& & & & & & & \vdots

\[
\mathbf{A}_4 =
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & W_{16}^1 & W_{16}^2 & W_{16}^3 & W_{16}^4 & W_{16}^5 & W_{16}^6 & W_{16}^7 \\
1 & 1 & 1 & 1 & 1 & -W_{16}^1 & -W_{16}^2 & -W_{16}^3 & -W_{16}^4 & -W_{16}^5 & -W_{16}^6 & -W_{16}^7 \\
\end{bmatrix}
\]

\section{总结与评价}

\subsection{模型优点}

(1) 精确拟合。本文采用 Cooley-Tukey 算法把 DFT 矩阵 $\mathbf{F}_N$ 分解为若干稀疏子矩阵的乘积，即 $\mathbf{F}_N = \beta \mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$，RMSE 值是 $10^{-17}$ 量级。

(2) 分解后的矩阵满足稀疏特性。由 4.4 小节的模型求解结果可见，分解后的每个子矩阵每行的非零元素不超过 2 个，满足约束 1。

(3) 分解效率高。已有文献只给出了 8 阶或 16 阶 DFT 矩阵的分解方法，由于阶数小，大多采用遍历轮询的方法求解出各个子矩阵。但随着阶数增大，遍历空间会呈指数级增长，大大增加了分解的难度。本文仅通过 $\log_2(N) + 1$ 次分解就能分别得到 $\log_2(N) + 1$ 个稀疏矩阵 $\mathbf{P}, \mathbf{A}_1, \cdots, \mathbf{A}_{\log_2(N)}$。只要 $N$ 是 2 的整数次幂，采用本文的算法就能快速分解 DFT 矩阵。对应的实现代码详见附录。

\subsection{模型缺点}

尽管得到了稀疏矩阵 $\mathbf{P}, \mathbf{A}_1, \cdots, \mathbf{A}_{\log_2(N)}$，但由于该算法只满足约束 1，分解的矩阵中存在非简单元素，因此复杂度还需进一步降低，这将在问题三中进一步优化。

\section{问题二的模型建立与求解}

\subsection{问题分析}

问题二的主要难点在于需要限制稀疏矩阵元素的实虚部取值范围，如果采用传统的遍历搜索，需要考虑每一个元素可能的取值，这大大增加了分解难度。我们考虑先拟合出一个近似 DFT 的矩阵，然后再拆分成几个稀疏矩阵或对角阵相乘。基于这个想法，我

\section*{4.2 模型建立}

问题二的数学模型与问题一类似，只是目标函数和约束条件都略作修改，具体如下：

\textbf{目标函数：}

问题二的优化目标有两个，分别是变量 $\boldsymbol{\mathcal{A}}$ 和 $\boldsymbol{\beta}$，这是典型的多目标问题，我们对每个目标进行加权，使其变成单目标问题，具体如下：

1) 目标函数最小化
\begin{equation}
F = \min \left\{ RMSE(\mathcal{A}, \beta) q_1 + B q_2 \right\}
\tag{18}
\end{equation}
其中：$q$ 为权重，$q_1 = 0.7$，$q_2 = 0.3$。

2) 优化目标一

使计算误差最小，即：
\begin{equation}
RMSE(\mathcal{A}, \beta) = \frac{1}{N} \sqrt{\left\| \mathbf{F}_N - \beta \mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \right\|_F^2}
\tag{19}
\end{equation}

3) 优化目标二

要优化 $\boldsymbol{\beta}$，使 $\boldsymbol{\beta}$ 的复杂度也最小，即：
\begin{equation}
B = \left| \log_2 \beta \right|
\tag{20}
\end{equation}

\textbf{约束条件：}

限定 $\boldsymbol{\mathcal{A}}$ 每个矩阵 $\mathbf{A}_k$ 满足以下要求：
\begin{equation}
\mathbf{A}_k[l, m] \in \{ x + jy \mid x, y \in \mathcal{P} \}, \mathcal{P} = \{ 0, \pm 1, \pm 2, \ldots, +2^{q-1} \},
\tag{21}
\end{equation}
\begin{equation}
k = 1, 2, \ldots, K; l, m = 1, 2, \ldots, N
\end{equation}
其中，$\mathbf{A}_k[l, m]$ 表示矩阵 $\mathbf{A}_k$ 第 $l$ 行第 $m$ 列的元素。

\section*{4.3 问题求解}

在建立模型的基础上，本文给出了三种分解方法，将其应用到 DFT 类矩阵的整数分解方法中。问题一中，$N = 2, 4$ 的分解结果依然满足问题二的限制条件，所以我们只计算 $N = 8, 16, 32$ 的分解方法。

\subsection*{4.3.1 基于 FEIG-WINOGRAD 矩阵映射的分解方法}

Feig-Winograd 算法是由一个指定元素的向量映射出一个逼近 $\mathbf{F}_N$ 的矩阵，进而有利于分解成多个稀疏矩阵相乘 [1]，具体流程如图 4 所示。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{feig_winograd_flowchart.png}
    \caption{FEIG-WINOGRAD 算法流程图}
    \label{fig:feig_winograd_flowchart}
\end{figure}

N 点 DFT 矩阵 $\mathbf{F}_N$ 中每一个元素可表示为
\begin{equation}
    [\mathbf{F}_N]_{m,n} = \omega_N^{nk}
    \tag{22}
\end{equation}
其中 $\omega_N = \exp(-2\pi j / N)$ 是旋转因子。如果 N 是偶数，则有如下关系
\begin{equation}
    [\mathbf{F}_N]_{m+\frac{N}{2},n} = (-1)^n [\mathbf{F}_N]_{m,n}
    \tag{23}
\end{equation}
其中 $m=0,1,\dots,N/2-1$，$n=0,1,\dots,N$，并且
\begin{equation}
    [\mathbf{F}_N]_{m,n+\frac{N}{2}} = (-1)^m [\mathbf{F}_N]_{m,n}
    \tag{24}
\end{equation}
其中 $m=0,1,\dots,N$，$n=0,1,\dots,N/2-1$。因此，$\mathbf{F}_N$ 可以分为四个子矩阵
\begin{equation}
    \mathbf{F}_N =
    \begin{pmatrix}
        \mathbf{A}_{0,0} & \mathbf{A}_{0,1} \\
        \mathbf{A}_{1,0} & \mathbf{A}_{1,1}
    \end{pmatrix}
    \tag{25}
\end{equation}
每个子矩阵都为 $N/2 \times N/2$ 阶，并且 $\mathbf{A}_{0,1}$，$\mathbf{A}_{1,0}$，$\mathbf{A}_{1,1}$ 中的元素和 $\mathbf{A}_{0,0}$ 是同样的，只是部分元素符号需要根据错误!未找到引用源。和错误!未找到引用源。取反[3]。如果 N 是 4 的整数倍，则 $\mathbf{A}_{0,0}$ 内部还存在对称性，满足如下关系
\begin{equation}
    [\mathbf{A}_{0,0}]_{m+\frac{N}{4},n} = (-j)^n [\mathbf{A}_{0,0}]_{m,n}
    \tag{26}
\end{equation}
其中 $m=0,1,\dots,N/4-1$，$n=0,1,\dots,N$，并且
\begin{equation}
    [\mathbf{A}_{0,0}]_{m,n+\frac{N}{4}} = (-j)^m [\mathbf{A}_{0,0}]_{m,n}
    \tag{27}
\end{equation}
其中 $m=0,1,\dots,N$，$n=0,1,\dots,N/4-1$。因此，子矩阵 $\mathbf{A}_{0,0}$ 内部同样可以和错误!未找到引用源。一样再次分为 4 个子矩阵。

根据上面的分析， $\mathbf{F}_{N}$ 内部子矩阵的对称性意味着分解 $\mathbf{F}_{N}$ 仅需要计算 $N/4$ 个不同的复数。根据 Feig-Winograd 因子分解，向量和矩阵映射关系可表示为：
\begin{equation}
f: \mathbb{C}^{N/4-1} \to \mathbb{C}^{N} \times \mathbb{C}^{N}
\end{equation}
\begin{equation}
\mathbf{a} \mapsto \hat{\mathbf{F}}_{N}
\end{equation}
其中 $\mathbf{a} = [a_{0}, a_{1}, a_{2}, \ldots, a_{N/4-1}]^{T}$ 是一个 $N/4 \times 1$ 维的向量，$a_{0} = 1$，因此 $\hat{\mathbf{F}}_{N}$ 的每个元素由 $\mathbf{a}$ 映射得出
\begin{equation}
[\hat{\mathbf{F}}_{N}]_{m,n} = (-1)^{p}(-j)^{t}a_{mn \bmod N/4}
\end{equation}
其中 $p = m \bmod N/2 + n \bmod N/2$，$t = m \bmod N/4 + n \bmod N/4$。

可以看出估计矩阵 $\hat{\mathbf{F}}_{N}$ 是由 $\mathbf{F}_{N}$ 的对称性归纳得出的，向量 $\mathbf{a}$ 中每个元素的实虚部取值范围可以由约束 2 限制，即 $\mathbf{a} \in \{x + jy | x, y \in \mathcal{P}\}$，$\mathcal{P} = \{0, \pm 1, \pm 2, \ldots, \pm 4\}$。$\mathbf{a}$ 中每个元素的值决定了估计矩阵 $\hat{\mathbf{F}}_{N}$ 逼近 $\mathbf{F}_{N}$ 的程度，即决定了目标函数的精度。因此我们首先采用遍历搜索来确定 $\mathbf{a}$ 的每个元素取值，得出 $\hat{\mathbf{F}}_{N}$ 后，再进行快速分解。以 8 阶 DCT 矩阵为例，通过遍历得出的 $\mathbf{a} = [0, 1-j]$，其映射出的
\begin{equation}
\hat{\mathbf{F}}_{8} = \frac{1}{2}
\begin{pmatrix}
2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
2 & 1-j & -2j & -1-j & -2 & -1+j & 2j & 1+j \\
2 & -2j & -2 & 2j & 2 & -2j & -2 & 2j \\
2 & -1-j & 2j & 1-j & -2 & 1+j & -2j & -1+j \\
2 & -2 & 2 & -2 & 2 & -2 & 2 & -2 \\
2 & -1+j & -2j & 1+j & -2 & 1-j & 2j & -1-j \\
2 & 2j & -2 & -2j & 2 & 2j & -2 & -2j \\
2 & 1+j & 2j & -1+j & -2 & -1-j & -2j & 1-j
\end{pmatrix}
\end{equation}
其分解因子由以下矩阵构成：
\begin{equation}
\hat{\mathbf{F}}_{8} = \mathbf{P} \cdot \mathbf{A}_{4} \cdot \mathbf{D} \cdot \mathbf{A}_{3} \cdot \mathbf{A}_{2} \cdot \mathbf{A}_{1}
\end{equation}
其中
\begin{equation}
\mathbf{A}_{1} =
\begin{pmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -1
\end{pmatrix},
\mathbf{A}_{2} =
\begin{pmatrix}
1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & -1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & -1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}
\end{equation}

\[
\mathbf{A}_{3} = \begin{pmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & -1 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & -1
\end{pmatrix}, \mathbf{A}_{4} = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & -1 & 1 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 1
\end{pmatrix}
\]

\[
\mathbf{D} = \text{diag}([1, 1, 1, j, 1, j, j, 1]), \quad \mathbf{P} \text{ 为初等变换矩阵 } \mathbf{P} = [\mathbf{e}_{0} | \mathbf{e}_{4} | \mathbf{e}_{2} | \mathbf{e}_{5} | \mathbf{e}_{1} | \mathbf{e}_{7} | \mathbf{e}_{3} | \mathbf{e}_{6}]^{T}, \quad \mathbf{e}_{i} (i = 0, 1, \ldots, 7) \text{ 为单位向量[7]。同样地，16阶 DCT 矩阵映射后得到}
\]

\begin{equation}
\hat{\mathbf{F}}_{16} = \frac{1}{2} \begin{pmatrix}
\mathbf{A}_{0,0} & \mathbf{A}_{0,1} \\
\mathbf{A}_{1,0} & \mathbf{A}_{1,1}
\end{pmatrix}
\tag{32}
\end{equation}

其中

\[
\mathbf{A}_{0,0} = \begin{pmatrix}
2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
2 & 2-j & 1-j & 1-2j & -2j & -1-2j & -1-j & -2-j \\
2 & 1-j & -2j & -1-j & -2 & -1+j & 2j & 1+j \\
2 & 1-2j & 1-j & -2+j & 2j & 2+j & 1-j & -1-2j \\
2 & -2j & -2 & 2j & 2 & -2j & -2 & 2j \\
2 & -1-2j & -1+j & 2+j & -2j & -2+j & 1+j & 1-2j \\
2 & -1-j & 2j & 1-j & -2 & 1+j & -2j & -1+j \\
2 & -2-j & 1+j & -1-2j & 2j & 1-2j & -1+j & 2-j
\end{pmatrix},
\]

\[
\mathbf{A}_{0,1} = \begin{pmatrix}
2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
-2 & -2+j & -1+j & -1+2j & 2j & 1+2j & 1+j & 2+j \\
2 & 1-j & -2j & -1-j & -2 & -1+j & 2j & 1+j \\
-2 & -1+2j & 1+j & 2-j & -2j & -2-j & -1+j & 1+2j \\
2 & -2j & -2 & 2j & 2 & -2j & -2 & 2j \\
-2 & 1+2j & 1-j & -2-j & 2j & 2-j & -1-j & -1+2j \\
2 & -1-j & 2j & 1-j & -2 & 1+j & -2j & -1+j \\
-2 & 2+j & -1-j & 1+2j & -2j & -1+2j & 1-j & -2+j
\end{pmatrix},
\]

\[
\mathbf{A}_{1,0} = \begin{pmatrix}
2 & -2 & 2 & -2 & 2 & -2 & 2 & -2 \\
2 & -2+j & 1-j & -1+2j & -2j & 1+2j & -1-j & 2+j \\
2 & -1+j & -2j & 1+j & -2 & 1-j & 2j & -1-j \\
2 & -1+2j & 1-j & 2-j & 2j & -2-j & 1-j & 1+2j \\
2 & 2j & -2 & -2j & 2 & 2j & -2 & -2j \\
2 & 1+2j & -1+j & -2-j & -2j & 2-j & 1+j & -1+2j \\
2 & 1+j & 2j & -1+j & -2 & -1-j & -2j & 1-j \\
2 & 2+j & 1+j & 1+2j & 2j & -1+2j & -1+j & -2+j
\end{pmatrix}.
\]

\[
\mathbf{A}_{1,1} = \begin{pmatrix}
2 & -2 & 2 & -2 & 2 & -2 & 2 & -2 \\
-2 & -2+j & -1+j & -1+2j & 2j & 1+2j & 1+j & 2+j \\
2 & -1+j & -2j & 1+j & -2 & 1-j & 2j & -1-j \\
-2 & 1-2j & 1+j & -2+j & -2j & 2+j & -1+j & -1-2j \\
2 & 2j & -2 & -2j & 2 & 2j & -2 & -2j \\
-2 & -1-2j & 1-j & 2+j & 2j & -2+j & -1-j & 1-2j \\
2 & 1+j & 2j & -1+j & -2 & -1-j & -2j & 1-j \\
-2 & -2-j & -1-j & -1-2j & 2j & 1-2j & 1-j & 2-j
\end{pmatrix},
\]

此时 $\hat{\mathbf{F}}_{16}$ 可以被分解为

\begin{equation}
\hat{\mathbf{F}}_{16} = \mathbf{B}_1 \cdot \mathbf{D} \cdot \mathbf{B}_2 \cdot \mathbf{B}_3 \cdot \mathbf{B}_4 \cdot \mathbf{B}_5
\tag{33}
\end{equation}

其中

\[
\mathbf{B}_5 = \begin{pmatrix}
1 & & & & & & & 1 \\
& 1 & & & & & 1 & \\
& & 1 & & & 1 & & \\
& & & 1 & 1 & & & \\
& & & & & 1 & & 1 \\
& & & 1 & & & 1 & \\
& 1 & & & & & & 1 \\
1 & & & & & & & 
\end{pmatrix},
\]

\[
\mathbf{B}_3 =
\begin{pmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
-1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
-1 & -1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
2 & 2 & 2 & 2 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1
\end{pmatrix},
\]

\[
\mathbf{B}_2 =
\begin{pmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 & -2 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1
\end{pmatrix}.
\]

\[
\mathbf{B}_1 =
\begin{bmatrix}
2 & -1 & 1 & & & & & \\
-1 & 1 & & 1 & & & & \\
-2 & & & & & & & -2 \\
& 1 & & & & & & \\
& & 1 & & & & & \\
& & & 1 & & & & \\
& & & & 1 & & & \\
& & & & & 1 & & \\
& & & & & & 1 & \\
& & & & & & & 2 \\
& & & & & & & & -1 \\
& & & & & & & & -1 \\
& & & & & & & & -1 \\
& & & & & & & & -1 \\
& & & & & & & & -1 \\
& & & & & & & & -1 \\
\end{bmatrix},
\]
\[
\mathbf{D} = 1/2 \text{diag}(1, 1, 1, 1, 1, 1, 1, 1, j, j, j, j, j, j).
\]

由于 Feig-Winograd 算法映射得到的矩阵 $\mathcal{A}$ 元素全部为实数或纯虚数，硬件复杂度较为 0，而代价是最小误差相对较大，如表 3 列出了 $N = 2^t, t = 1, 2, 3, 4, 5$ 时计算 $\mathbf{F}_N$ 的最小误差和硬件复杂度 $C$，具体性能如 4.3.1 表 3 所示。

\begin{table}[h]
\centering
\caption{Feig-Winograd 算法性能表}
\begin{tabular}{c c c c c c}
\hline
阶数 $N$ & 2 & 4 & 8 & 16 & 32 \\
\hline
RMSE & 0 & 0 & 0.07 & 0.25 & 0.21 \\
硬件复杂度 $C$ & 0 & 0 & 0 & 0 & 0 \\
\hline
\end{tabular}
\end{table}

\subsection{4.3.2 基于序列二次规划 SQP 的分解方法}

二次规划 (QP) 是一种特殊的非线性规划，即优化最小化或最大化多个变量的二次函数，并服从于这些变量的线性约束。序列二次规划 SQP 算法是将复杂的非线性优化问题转换为简单的二次规划问题来求解的算法，在每一步迭代中，先使用牛顿法计算一个二次近似函数，然后将其转化为一个二次规划问题。问题二中的约束二是一种非线性约束，故可以采用 SQP 迭代得出目标矩阵。给定一个非线性约束的最优问题：
\begin{equation}
\begin{aligned}
\min f(x) \\
s.t. g_u(x) \leq 0 (u = 1, 2, \dots, p) \\
h_v(x) \leq 0 (v = 1, 2, \dots, m)
\end{aligned}
\tag{34}
\end{equation}

利用泰勒展开把上式子的非线性约束问题的目标函数在迭代点 $x^k$ 简化成二次函数，把非线性约束函数简化成线性函数后得到如下二次规划问题：

\begin{equation}
\begin{aligned}
\min f(\mathbf{X}) &= \frac{1}{2}[\mathbf{X} - \mathbf{X}^k]^T \nabla^2 f(\mathbf{X}^k)[\mathbf{X} - \mathbf{X}^k] + \nabla f(\mathbf{X}^k)^T[\mathbf{X} - \mathbf{X}^k] \\
\text{s.t. } \nabla g_u(\mathbf{X}^k)^T[\mathbf{X} - \mathbf{X}^k] + g_u(\mathbf{X}^k) &\leq 0 (u = 1, 2, \dots, p) \\
\nabla h_v(\mathbf{X}^k)^T[\mathbf{X} - \mathbf{X}^k] + h_v(\mathbf{X}^k) &= 0 (v = 1, 2, \dots, m)
\end{aligned}
\tag{35}
\end{equation}

此问题为原来约束最优问题的近似问题，令：
\begin{equation}
\mathbf{S} = \mathbf{X} - \mathbf{X}^k
\tag{36}
\end{equation}

将上述二次规划问题变成关于变量 $\mathbf{S}$ 的问题，即：
\begin{equation}
\begin{aligned}
\min f(\mathbf{X}) &= \frac{1}{2} \mathbf{S}^T \nabla^2 f(\mathbf{X}^k) \mathbf{S} + \nabla f(\mathbf{X}^k)^T \mathbf{S} \\
\text{s.t. } \nabla g_u(\mathbf{X}^k)^T \mathbf{S} + g_u(\mathbf{X}^k) &\leq 0 (u = 1, 2, \dots, p) \\
\nabla h_v(\mathbf{X}^k)^T \mathbf{S} + h_v(\mathbf{X}^k) &= 0 (v = 1, 2, \dots, m)
\end{aligned}
\tag{37}
\end{equation}

令：
\begin{equation}
\begin{aligned}
\mathbf{H} &= \nabla^2 f(\mathbf{X}^k) \\
\mathbf{C} &= \nabla f(\mathbf{X}^k) \\
\mathbf{A}_{eq} &= [\nabla h_1(\mathbf{X}^k), \nabla h_2(\mathbf{X}^k), \dots, \nabla h_m(\mathbf{X}^k)]^T \\
\mathbf{A} &= [\nabla g_1(\mathbf{X}^k), \nabla g_2(\mathbf{X}^k), \dots, \nabla g_p(\mathbf{X}^k)]^T \\
\mathbf{B}_{eq} &= [h_1(\mathbf{X}^k), h_2(\mathbf{X}^k), \dots, h_m(\mathbf{X}^k)]^T \\
\mathbf{B} &= [g_1(\mathbf{X}^k), g_2(\mathbf{X}^k), \dots, g_p(\mathbf{X}^k)]^T
\end{aligned}
\tag{38}
\end{equation}

写成一般形式为：
\begin{equation}
\begin{aligned}
\min \frac{1}{2} \mathbf{S}^T \mathbf{H} \mathbf{S} + \mathbf{C}^T \mathbf{S} \\
\text{s.t. } \mathbf{A} \mathbf{S} &= -\mathbf{B} \\
\mathbf{A}_{eq} \mathbf{S} &= -\mathbf{B}_{eq}
\end{aligned}
\tag{39}
\end{equation}

求解此二次规划问题，将其最优解 $\mathbf{S}^*$ 作为原问题的下一个搜索方向 $\mathbf{S}^k$，并在该方向上进行原约束问题目标函数的约束一维搜索，这样就可以得到原约束问题的一个近似解 $\mathbf{X}^{k+1}$。反复这一过程，就可以得到原问题的最优解。采用 SQP 方法，取 $\beta = \sqrt{N}$ 优化 RMSE 目标函数，例如以 4 阶 DFT 矩阵为参考，迭代出的矩阵 $\hat{\mathbf{F}}_4$ 最小误差为 0.3953，以 8 阶 DFT 矩阵为参考，迭代出的 $\hat{\mathbf{F}}_8$ 最小误差为 0.4336，以下展示了用 SQP 估计的 $\hat{\mathbf{F}}_4$ 和 $\hat{\mathbf{F}}_8$。

\begin{equation}
\hat{\mathbf{F}}_4 = \begin{pmatrix}
1 & 0 & 1 & 1 \\
1 & 1 & 0 & 0 \\
1 & 0 & 1 & 0 \\
1 & 0 & 0 & 0
\end{pmatrix},
\end{equation}

\[
\hat{\mathbf{F}}_{8}=\left(\begin{array}{cccccccc}
0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 \\
1 & 0 & 0 & 1 & 1 & 1 & 1 & 1 \\
0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 1 & 1 & 0 & 1 & 1 & 0 & 1 \\
0 & 0 & 1 & 0 & 0 & 1 & 1 & 1 \\
0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 \\
1 & 1 & 0 & 1 & 0 & 1 & 1 & 0
\end{array}\right)
\]

SQP 能找出的结果与其他算法相比误差最大，优点是硬件复杂度 \(C\) 基本为 0。下表列出了 \(N=2^{t}, t=1,2,3,4,5\) 时计算 \(\mathbf{F}_{N}\) 的最小误差和硬件复杂度 \(C\)，具体性能如 4.3.2 表 4 表 3 所示。

\begin{table}[h]
\centering
\caption{二次规划 SQP 算法性能表}
\begin{tabular}{c c c c c c}
\hline \hline
N & 2 & 4 & 8 & 16 & 32 \\
\hline
RMSE & - & 0.39 & 0.43 & 0.30 & 0.20 \\
硬件复杂度 \(C\) & - & 0 & 0 & 0 & 0 \\
\hline \hline
\end{tabular}
\end{table}

使用 SQP 算法存在的缺点很明显，对初始点的依赖性强，并且求解时需要较长的计算时间。如果初始点不同，计算的最小误差也会有区别，可能是因为陷入了局部最优解，这就是为什么目标函数的最小误差相比其他算法最大，不过 SQP 算法能够处理非线性约束和非光滑函数，在求解器的选择上，具有灵活性，因为可以根据具体问题的特点选择适合的求解器。

\subsection*{4.3.3 基于遗传算法的分解方法}

遗传算法 (GA) 是数学中最常用来解决最优化问题的算法，Grenfenstette 提出的遗传算法从代表问题可能潜在解集的一个种群开始，对种群反复进行复制、交叉已经变异操作，直接对结构对象进行操作，估计各个体的适应值，采用概率化的方式进行全局最优解的搜寻，根据“适者生存、优胜劣汰”的进化规则，使得群体越来越向最优解的方向进化 [8] [9] [10]。

算法的基本运算流程包括染色体编码、初始化种群设置、建立适应度函数对个体进行评价、执行遗传操作、算法的终止规则、染色体解码，具体的算法流程图如图 5 所示。得到的分解矩阵 \(\mathcal{A}=\{\mathbf{A}_{1}, \mathbf{A}_{2}, \ldots, \mathbf{A}_{k}\}\) 可以被简便地编码为染色体，只要给出适应度函数的定义，遗传算法就能直接对不同的分解序列进行筛选，每轮迭代都在原本的种群上更新得到表现更好的种群，基本遗传算法的时间复杂度为 \(O(n^{2})\)，能够在较短的运算时间内给出较为优质的可行解。

在运行步骤当中，合理的种群规模大小很关键，会对遗传算法的性能产生影响 [11]，较大数量的种群可以遍历所有可行解，较小数量的种群计算量小，算法可以以很快的速度收敛，但可能结果是局部最优解，所以一个合适的种群规模变得尤为重要，最优的种群规模应当是决策变量数量的 4 倍到 6 倍，一般在 20~100 之间 [12]；其次是交叉概率，来衡量种群个体是否进行交叉操作的可能性大小，从种群中随机选出部分个体做交叉操作产生子代新个体，交叉概率一般的取值范围为 0.4~0.99；变异概率是个体是否进行变异操作的评价标准，变异概率太大可能会产生不可行解，太小则不易跳出局部最优而重复迭代，变异概率的取值一般为 0.0001~0.5；最大迭代次数是遗传算法预先设定的

一种运行终止规则[13]，若当前已达到最大迭代次数，则退出循环终止操作，得到最优解。

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{genetic_algorithm_flowchart.png}
\caption{遗传算法流程图}
\end{figure}

\section*{Step1：最优分解方法的获取}

通过遗传算法解决 DFT 类矩阵的整数分解的过程如下：

1) 令迭代次数 \( i=0 \)，随机生成初始种群，内含有 \( N \) 条染色体，每条染色体代表问题的一个解。

2) 将随机产生的符合约束条件的矩阵作为初始染色体，产生初始种群，种群中的染色体是由初始染色体中的基因点随机交换生成，计算种群内每条染色体的适应度值 \( \text{Fit} \)，判断算法是否满足设定的终止条件，如果不满足则更新迭代次数 \( i \)，令 \( i=i+1 \)，生成复制种群 \( \text{Select}(i+1) \)。

3) 进行复制操作，首先将当前代中适应度最高的两个个体保留到下一代种群中，再按照轮盘赌选择方式生成新一代种群。

4) 进行交叉操作，采用双点交叉，随机选取两个染色体，随机选定交叉点，两层基因链同时进行交叉操作，生成交叉种群 \( \text{Pc}(i+1) \)。

5) 进行变异操作，在一条染色体上随机选择两个基因点，交换两个基因点的值，两层基因链同时进行变异，生成变异种群 \( \text{Pm}(i+1) \)。

6) 在新一代种群的基础上，返回步骤 3。

7) 输出适应度最高的染色体，解码得到最优出车序列，算法结束。

\section*{Step2：\( \beta \) 调整方案及得分}

在获取最优分解方法的同时，不断调制 \( \beta \) 的取值，最终找到使之最小的误差值 \( \text{RMSE}(A, \beta) \)。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image1.png}
    \caption{16阶和32阶DFT分解矩阵的误差}
    \label{fig:6}
\end{figure}

如图 \ref{fig:6} 所示，分别是16阶和32阶DFT分解矩阵的误差，
1) N=16时，在$\beta=0.08$达到最小误差0.2221；
2) N=32时，在$\beta=0.088$达到最小误差0.1505；

性能是要好于Feig-Winograd算法的。在基于遗传算法时，本文中我们并未对矩阵进行分解，而是直接进行拟合，所以复杂度都为0，得到拟合的部分16阶DFT矩阵（拟合的完整16阶DFT矩阵和32阶DFT矩阵见附录）为：
\[
\hat{\mathbf{F}}_{16} = 
\begin{bmatrix}
-0.5+0.5j & -0.5-j & -1+4j & \cdots & 0.5-j & -0.25-0.25j & -1-4j \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
-0.5+2j & -2-j & 1-0.5j & \cdots & 0.5+j & 0.25+j & 1+j
\end{bmatrix}
\]

然后我们将找到的最优的$\beta$取值带入遗传算法，进行200次迭代，得到适应度进化曲线。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image2.png}
    \caption{16阶和32阶拟合矩阵适应度进化曲线}
    \label{fig:7}
\end{figure}

如图 \ref{fig:7} 所示，分别是16阶和32阶拟合矩阵适应度进化曲线，分别第105代和第221代完成了收敛，且性能由于需要分解的Feig-Winograd算法。

\subsection{结果与分析}

对比三种方法的性能如下图所示:

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{placeholder.png}
    \caption{三种算法的 RMSE 对比图}
    \label{fig:rmse_comparison}
\end{figure}

如图 \ref{fig:rmse_comparison} 所示, 对比三种算法的 RMSE 可知, 由于三种算法的复杂度都为 0, 遗传算法的 RMSE 最小, 可知遗传算法的性能最优。

\subsection{总结与评价}

问题二共使用了三种算法, 各有优缺点。其中基于序列二次规划 SQP 的分解算法精度最差, 遗传算法精度最高, FEIG-WINOGRAD 矩阵映射算法精度介于两者之间。但是序列二次规划 SQP 代码实现简单, 遗传算法的编程实现则比较复杂, 训练时间也比其他两种算法长。FW 矩阵映射算法训练时间最短, 但是在矩阵分解部分依赖特定公式, 适用性不高

\section{问题三的模型建立与求解}

\subsection{问题分析}

本节中, 我们承接问题二中算法选型相关分析, 增加限制稀疏矩阵的每行元素个数这个限制条件, 对遗传算法进行改善。增加优化搜索算法, 即使用对角阵分解, 并使每个对角阵的非零元素取值为整数集 $\mathbb{P}$ 中的值。最后对比几类算法的估计结果。

\subsection{模型建立}

问题三的数学模型页与问题二类似, 只是多加了 $A_k$ 必须为稀疏矩阵的约束条件, 修改后的目标函数和约束条件具体如下:

\subsubsection{目标函数}

1) 目标函数最小化

\begin{equation}
F = \min \left\{ RMSE(A, \beta) q_1 + B q_2 \right\}
\tag{40}
\end{equation}

其中：$q$ 为权重，$q_{1}=0.7$，$q_{2}=0.3$。

2) 优化目标一

使计算误差最小，即：
\begin{equation}
RMSE(\mathcal{A},\beta)=\frac{1}{N}\sqrt{\left\|\mathbf{F}_{N}-\beta\mathbf{A}_{K}\cdots\mathbf{A}_{2}\mathbf{A}_{1}\right\|_{F}^{2}}
\tag{41}
\end{equation}

3) 优化目标二

要优化 $\beta$，使 $\beta$ 的复杂度也最小，即：
\begin{equation}
B=\left|\log_{2}\beta\right|
\tag{42}
\end{equation}

约束条件：

限定 $\mathcal{A}$ 每个矩阵 $\mathbf{A}_{k}$ 满足以下要求：
\begin{equation}
\mathbf{A}_{k}[l,m]\in\{x+jy|x,y\in\mathcal{P}\},\mathcal{P}=\{0,\pm1,\pm2,\ldots,+2^{q-1}\},
\tag{43}
\end{equation}
\begin{equation}
k=1,2,\ldots,K;l,m=1,2,\ldots,N
\end{equation}
其中，$\mathbf{A}_{k}[l,m]$ 表示矩阵 $\mathbf{A}_{k}$ 第 $l$ 行第 $m$ 列的元素。

约束条件：

1) 每个矩阵的每行至多只有 2 个非零元素

用 $\mathbf{P}_{1},\mathbf{P}_{2},\cdots,\mathbf{P}_{K}$ 矩阵分别表示对应 $\mathbf{A}_{1},\mathbf{A}_{2},\cdots,\mathbf{A}_{K}$ 矩阵非零元素的位置
\begin{equation}
\sum_{j=1}^{N}\mathbf{P}_{k}(i,j)\leq2
\tag{44}
\end{equation}
其中 $k=1,2,\ldots,K$，$i=1,2,\ldots,N$，$\mathbf{P}_{k}(i,j)$ 表示 $\mathbf{P}_{k}$ 矩阵第 $i$ 行第 $j$ 列的元素。

2) 限定 $\mathcal{A}$ 每个矩阵 $\mathbf{A}_{k}$ 满足以下要求：
\begin{equation}
\mathbf{A}_{k}[l,m]\in\{x+jy|x,y\in\mathcal{P}\},\mathcal{P}=\{0,\pm1,\pm2,\ldots,+2^{q-1}\},
\tag{45}
\end{equation}
\begin{equation}
k=1,2,\ldots,K;l,m=1,2,\ldots,N
\end{equation}
其中，$\mathbf{A}_{k}[l,m]$ 表示矩阵 $\mathbf{A}_{k}$ 第 $l$ 行第 $m$ 列的元素。

\subsection{5.3 问题求解}

问题一中，$N=2,4$ 的分解结果依然满足问题三的限制条件，所以我们只计算 $N=8,16,32$ 的分解方法。

\subsubsection{5.3.1 基于优化搜索的分解方法}

由于稀疏矩阵的元素个数有限制，在一定程度上削减了遍历规模，可以考虑用一种优化搜索方式找出目标矩阵。该方法基于问题一中的 Cooley-Tukey 算法分解，得到初步分解结果后再对每一个稀疏矩阵进行元素范围约束，遍历所有可能的复数，寻找逼近 DFT 矩阵误差最小的最优方案，具体流程如图 9 所示。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image.png}
    \caption{优化搜索算法流程图}
    \label{fig:flowchart}
\end{figure}

在搜索过程中，固定 $\beta = \sqrt{N}$，以 8 阶 DFT 矩阵为例，分解后的 RMS 误差为 0.125，复杂度 $C$ 为 0，分解矩阵 $\hat{\mathbf{F}}_8 = \mathbf{A}_3 \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$ 如下：

\begin{equation}
\hat{\mathbf{F}}_8 =
\begin{pmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 0 & -j & 0 & -1 & 0 & j & 0 \\
1 & -j & -1 & j & 1 & -j & -1 & j \\
1 & 0 & j & 0 & -1 & 0 & -j & 0 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & 0 & -j & 0 & -1 & 0 & j & 0 \\
1 & j & -1 & -j & 1 & j & -1 & -j \\
1 & 0 & j & 0 & -1 & 0 & -j & 0
\end{pmatrix},
\mathbf{A}_1 =
\begin{pmatrix}
1 & 1 & & & & & & \\
1 & -1 & & & & & & \\
 & & 1 & 1 & & & & \\
 & & 1 & -1 & & & & \\
 & & & & 1 & 1 & & \\
 & & & & 1 & -1 & & \\
 & & & & & & 1 & 1 \\
 & & & & & & 1 & -1
\end{pmatrix},
\end{equation}

\begin{equation}
\mathbf{A}_2 =
\begin{pmatrix}
1 & 1 & & & & & & \\
 & & 1 & 1 & & & & \\
1 & & & & 1 & 1 & & \\
 & & & & & & 1 & 1 \\
 & 1 & -j & & & & & \\
 & & & 1 & -j & & & \\
 & & & & & 1 & -j & \\
 & & & & & & & j
\end{pmatrix},
\mathbf{A}_3 =
\begin{pmatrix}
1 & 1 & & & & & & \\
 & & 1 & 1 & & & & \\
 & & & & 1 & 1 & & \\
 & & & & & & 1 & 1 \\
 & & & & & & & -j \\
 & & & & & & & j \\
 & & & & & & & \\
 & & & & & & & 
\end{pmatrix}.
\end{equation}

\begin{table}[h]
\centering
\caption{优化搜索算法性能表}
\begin{tabular}{c c c c c c}
\hline \hline
N & 2 & 4 & 8 & 16 & 32 \\
\hline
RMSE & - & - & 0.125 & 0.062 & 0.031 \\
硬件复杂度 C & - & - & 0 & 0 & 0 \\
\hline \hline
\end{tabular}
\end{table}

\subsection{基于遗传算法的分解方法}

\subsubsection{阶数 N=8 时}

基于问题一求得的分解结果，N=8 时，得到的分解结果只有 $\mathbf{A}_3$ 的第 6 列和第 8 列不满足本题的约束条件，引用 3.4 节中的 $\mathbf{A}_3$ 如下

\[
\mathbf{A}_3 =
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & \textcolor{red}{W_8} & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & \textcolor{red}{W_8^3} \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & \textcolor{red}{-W_8} & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & \textcolor{red}{-W_8^3}
\end{bmatrix}
\]

我们采用遗传算法对 $\mathbf{A}_3$ 进行优化，为了简化优化思路，提高搜索效率，我们上式圈出的不满足约束条件的元素进行优化，得到拟合出的结果 $\hat{\mathbf{A}}_3$ 为

\[
\hat{\mathbf{A}}_3 =
\begin{bmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & -0.25-j & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 1+0.25j \\
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1-j & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & -W_8^2 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -0.5-j
\end{bmatrix}
\]

同时得到 $\beta=0.9$ 达到最小误差 0.0645，并等得到了适应度进化曲线如下。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{N=8 时的搜索结果}
    \label{fig:search_results_N8}
\end{figure}

如图 \ref{fig:search_results_N8} 所示，当 $\beta=0.9$ 时，最终的 RMSE=0.064，并在第 101 代完成了收敛。

\subsubsection{阶数 N=16 时}

基于问题一求得的分解结果，N=16 时，$\mathbf{A}_3$ 和 $\mathbf{A}_4$ 都需要进行优化，我们现在 $\mathbf{A}_3$ 不满足约束条件的情况下，用遗传算法先优化 $\mathbf{A}_4$，得到最优的 $\hat{\mathbf{A}}_4$ 和 $\beta_1$，然后再将 $\hat{\mathbf{A}}_4$ 带入，求得最优的 $\hat{\mathbf{A}}_3$ 和 $\beta_2$。$\hat{\mathbf{A}}_3$ 和 $\hat{\mathbf{A}}_4$ 即为拟合出的最优解，而 $\beta$ 的最优拟合值即为 $\beta_2$。

\subsubsection{Step1：优化 $\hat{\mathbf{A}}_4$}

采用遗传算法，得到拟合出来的 $\hat{\mathbf{A}}_4$ 为，此时的 RMSE=0.0751。

\begin{equation}
\hat{\mathbf{A}}_4 =
\begin{bmatrix}
1 & 1 & -0.25-2j & 1+2j & 1+1j & W_{16}^4 & 0.5-4j & -0.5-2j & -1-0.5j \\
1 & 1 & 1 & 1 & 1 & 1 & -1 & -2+j & 1+2j \\
1 & 1 & 1 & 1 & 1 & 1 & -1-2j & -W_{16}^4 & 0.25-0.5j \\
1 & 1 & 1 & 1 & 1 & 1 & -2+0.5j & -2+j
\end{bmatrix}
\end{equation}

\subsubsection{Step2：优化 $\hat{\mathbf{A}}_3$ 和 $\beta$}

将拟合得出的最优 $\hat{\mathbf{A}}_4$ 代替 $\mathbf{A}_4$，继续采用遗传算法求得 $\hat{\mathbf{A}}_3$ 为

\[
\hat{\mathbf{A}}_{3} = 
\begin{bmatrix}
1 & 1 & 0.25-4j & W_{16}^{4} & -2+j & 0 \\
1 & 1 & -1 & -2-0.5j & -W_{16}^{4} & -0.25+2j \\
1 & 1 & 0 & 1 & 1 & 2-2j \\
0 & 1 & 1 & W_{16}^{4} & -2-j & 1 \\
1 & -1 & 1 & 2-4j & -W_{16}^{4} & -1+2j \\
\end{bmatrix}
\]

并绘制两次迭代的适应度曲线如下：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{image1.png}
    \caption{适应度进化曲线}
    \label{fig:curve1}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{image2.png}
    \caption{适应度进化曲线}
    \label{fig:curve2}
\end{figure}

图11 N=16 两次迭代结果

如图11所示，在对矩阵 $\mathbf{A}_{4}$ 和 $\mathbf{A}_{3}$ 进行优化时，分别在第95代和第65代完成了收敛，且每次优化 RMSE 都有所增加，当 $\beta=0.4$ 时，最终的 RMSE=0.2008。

3) 阶数 N=32 时

方法同 N=16 时，当 $\beta=0.26$ 时，最终的 RMSE=0.3465。

\subsection{结果与分析}

对比两种方法的性能如下图所示：

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{image3.png}
    \caption{性能对比图}
    \label{fig:performance}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{两种算法的 RMSE 对比图}
    \label{fig:rmse_comparison}
\end{figure}

如图 \ref{fig:rmse_comparison} 所示，对比两种算法的 RMSE 可知，优化算法的 RMSE 在 $N=16$ 和 $N=32$ 时更低，在 $N=8$ 时略高，且优化算法的复杂度都为 0，而遗传算法的复杂度与问题一致，在 $N=32$ 为 5120，故优化算法更好。

\subsection{总结与评价}

问题三共使用两种算法对矩阵进行约束，可以看出优化搜索算法性能优秀，在误差较小的情况下能使计算复杂度降为 0。遗传算法同时对稀疏矩阵和 $\beta$ 进行了优化，而优化搜索算法固定了 $\beta = \sqrt{N}$，故遗传算法精度更高，但是复杂度同时也提升了。

\section{问题四的模型建立与求解}

\subsection{问题分析}

问题四要求把矩阵 $\mathbf{F} = \mathbf{F}_4 \otimes \mathbf{F}_8$ 分解为若干个稀疏矩阵相乘，并且分解后的稀疏矩阵同时满足约束 1 和约束 2。求解问题四的基本思路是“由大化小，分而治之”。对此，本文提出一种“混合积分分解—降维寻优法”，其中的混合积分分解方法是结合 Cooley-Tukey 算法、Kronecker 积的运算性质、矩阵初等行变换这三种基本原理 [4] [5] [6] 推导出的。具体求解过程将在 6.3 小节中详细描述。

\subsection{模型建立}

分解之后的矩阵与误差及硬件复杂度之间的对应关系可以建立模型来表达，前文中已模型中相关符号进行定义，根据问题描述和表 1 内给出的参数变量符号，分解之后的矩阵与误差及硬件复杂度之间的关系可以采用以下数学模型来表示：

\subsubsection{目标函数}

问题三的优化目标有三个，分别是变量 $\mathcal{A}$，$\beta$ 和乘法器个数 $L$，这是典型的多目标问题，我们对每个目标进行加权，使其变成单目标问题，具体如下：

1) 目标函数最小化
\begin{equation}
F = \min \left\{ RMSE(\mathcal{A}, \beta) q_1 + B q_2 + L q_3 \right\}
\tag{46}
\end{equation}

其中：$q$ 为权重，$q_{1}=0.6$，$q_{2}=0.2$，$q_{3}=0.2$。

2) 优化目标一

使计算误差最小，即：
\begin{equation}
RMSE(A,\beta)=\frac{1}{N} \sqrt{\left\|\mathbf{F}_{N}-\beta \mathbf{A}_{K} \cdots \mathbf{A}_{2} \mathbf{A}_{1}\right\|_{F}^{2}}
\tag{47}
\end{equation}
需要注意的是，这里的 $\mathbf{F}_{N}$ 不是 DFT 矩阵，而是两个 DFT 矩阵的混积

3) 优化目标二

要优化 $\beta$，使 $\beta$ 的复杂度也最小，定义 B 的定义与 P 相似，使 $\beta$ 能用更小的位宽表示出来
\begin{equation}
B=\left|\log _{2} \beta\right|
\tag{48}
\end{equation}

4) 优化目标三

用 $\mathbf{D}_{1}, \mathbf{D}_{2}, \ldots, \mathbf{D}_{K}$ 矩阵分别表示对应 $\mathbf{A}_{1}, \mathbf{A}_{2}, \ldots, \mathbf{A}_{K}$ 矩阵非简单元素的位置（0、$\pm 1$、$\pm j$ 不需要计算复杂度，所以把它们记为简单元素），即非简单元素标记为 1，简单元素标记为 0，得到 $\mathbf{D}_{1}, \mathbf{D}_{2}, \ldots, \mathbf{D}_{K}$ 矩阵为二进制矩阵。

把 $\mathbf{A}_{1}, \mathbf{A}_{2}, \ldots, \mathbf{A}_{K}$ 矩阵映射到 $\mathbf{D}_{1}, \mathbf{D}_{2}, \ldots, \mathbf{D}_{K}$ 矩阵的操作记为 $dif$，$\mathbf{D}_{k}=dif\left(\mathbf{A}_{k}\right)$，得到乘法器的个数 $L$ 为
\begin{equation}
L=\sum_{i=1}^{N} \sum_{j=1}^{N} \mathbf{D}_{K} dif\left(\mathbf{A}_{K-1} \cdots \mathbf{A}_{2} \mathbf{A}_{1}\right)+\cdots+\sum_{i=1}^{N} \sum_{j=1}^{N} \mathbf{D}_{3} dif\left(\mathbf{A}_{2} \mathbf{A}_{1}\right)+\sum_{i=1}^{N} \sum_{j=1}^{N} \mathbf{D}_{2} \mathbf{D}_{1}
\tag{49}
\end{equation}

约束条件：

用 $\mathbf{P}_{1}, \mathbf{P}_{2}, \ldots, \mathbf{P}_{K}$ 矩阵分别表示对应 $\mathbf{A}_{1}, \mathbf{A}_{2}, \ldots, \mathbf{A}_{K}$ 矩阵非零元素的位置，即非零元素标记为 1，零元素标记为 0，得到 $\mathbf{P}_{1}, \mathbf{P}_{2}, \ldots, \mathbf{P}_{K}$ 矩阵为二进制矩阵。

每个矩阵的每行至多只有 2 个非零元素
\begin{equation}
\sum_{j=1}^{N} \mathbf{P}_{k}(i, j) \leq 2
\tag{50}
\end{equation}
其中 $k=1,2, \ldots, K$，$i=1,2, \ldots, N$，$\mathbf{P}_{k}(i, j)$ 表示 $\mathbf{P}_{k}$ 矩阵第 $i$ 行第 $j$ 列的元素。

\subsection*{6.3 问题求解}

\subsubsection{6.3.1 基于 “混合积分解—降维寻优” 算法 I 的分解方法}

根据 6.1 小节的问题分析，“混合积分解—降维寻优法” 简单描述为以下四步：

第一步，分别对 $\mathbf{F}_{4}$ 和 $\mathbf{F}_{8}$ 做高精度分解。采用问题一的 Cooley-Tukey 算法，易得
\begin{equation}
\mathbf{F}_{4} \otimes \mathbf{F}_{8}=\beta\left(\mathbf{B}_{2} \mathbf{B}_{1} \mathbf{P}_{N 4}\right) \otimes\left(\mathbf{C}_{3} \mathbf{C}_{2} \mathbf{C}_{1} \mathbf{P}_{N 8}\right)
\tag{51}
\end{equation}

第二步，分离乘积项。把 $\mathbf{F}_{4} \otimes \mathbf{F}_{8}$ 分解为若干个乘积项。根据混积性质，可得式 (52) 所示的表达式
\begin{equation}
\mathbf{F}_{4} \otimes \mathbf{F}_{8}=\beta\left(\mathbf{I}_{4} \otimes \mathbf{C}_{3}\right)\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)\left(\mathbf{B}_{1} \otimes \mathbf{C}_{1}\right)\left(\mathbf{P}_{N 4} \otimes \mathbf{P}_{N 8}\right)
\tag{52}
\end{equation}

第三步，分解成稀疏矩阵，使其满足约束 1。把式 (52) 等式右端的每一个乘积项都分解为稀疏矩阵。分析问题一中 $\mathbf{F}_{4}$ 和 $\mathbf{F}_{8}$ 稀疏子矩阵的特点，可得
\begin{equation}
\mathbf{F}_{4} \otimes \mathbf{F}_{8}=\beta\left(\mathbf{C}_{3}\right)\left(\mathbf{P}_{2} \Lambda_{2}\right)\left(\mathbf{P}_{1} \Lambda_{1}\right)\left(\mathbf{P}_{0}\right)
\tag{53}
\end{equation}

第四步，对 $\mathbf{C}_{3}$ 做寻优，使其满足约束 2。由于 $\mathbf{P}_{3}, \Lambda_{3}, \mathbf{P}_{2}, \Lambda_{2}, \mathbf{P}_{1}$ 这 5 个子矩阵都是同时满足约束 1 和约束 2 的稀疏矩阵，并且 $\left(\mathbf{P}_{2} \Lambda_{2}\right),\left(\mathbf{P}_{1} \Lambda_{1}\right),\left(\mathbf{P}_{0}\right)$ 三项分别是

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{flowchart.png}
    \caption{混合积分分解-降维寻优算法 I 流程图}
    \label{fig:flowchart}
\end{figure}

下面详细描述第三步和第四步的公式推导过程。

第三步，把式 (52) 再次书写如下：
\begin{equation}
    \mathbf{F}_{4} \otimes \mathbf{F}_{8} = \beta \left( \mathbf{I}_{4} \otimes \mathbf{C}_{3} \right) \left( \mathbf{B}_{2} \otimes \mathbf{C}_{2} \right) \left( \mathbf{B}_{1} \otimes \mathbf{C}_{1} \right) \left( \mathbf{P}_{\mathrm{N4}} \otimes \mathbf{P}_{\mathrm{N8}} \right)
    \tag{54}
\end{equation}

我们发现分解后的稀疏矩阵 $\mathbf{B}_{2}, \mathbf{B}_{1}, \mathbf{C}_{3}, \mathbf{C}_{2}, \mathbf{C}_{1}$ 具有某种特定的规律，这种规律可以把 $\left( \mathbf{B}_{2} \otimes \mathbf{C}_{2} \right)$ 和 $\left( \mathbf{B}_{1} \otimes \mathbf{C}_{1} \right)$ 这两项分别分解为一个稀疏矩阵与一个对角矩阵（或满足约束 1 的分块对角阵）相乘的形式。下面对该式中的每一个乘积项单独分析。

(1) 计算第一项 $\left( \mathbf{P}_{\mathrm{N4}} \otimes \mathbf{P}_{\mathrm{N8}} \right)$

$\mathbf{P}_{\mathrm{N4}}$ 和 $\mathbf{P}_{\mathrm{N8}}$ 分别是 $\mathbf{F}_{4}$ 和 $\mathbf{F}_{8}$ 的列变换矩阵，每行仅有一个非零元，且所有非零元素均为 1，因此 $\left( \mathbf{P}_{\mathrm{N4}} \otimes \mathbf{P}_{\mathrm{N8}} \right)$ 是满足约束 1 和约束 2 的稀疏矩阵，记
\begin{equation}
    \mathbf{A}_{1} = \left( \mathbf{P}_{\mathrm{N4}} \otimes \mathbf{P}_{\mathrm{N8}} \right)
    \tag{55}
\end{equation}

(2) 计算第二项 $(\mathbf{B}_1 \otimes \mathbf{C}_1)$

根据 4.4 小节，$\mathbf{B}_1$ 和 $\mathbf{C}_1$ 的值分别如下，
\begin{equation}
\mathbf{B}_1 = \begin{bmatrix}
1 & 1 & 0 & 0 \\
1 & -1 & 0 & 0 \\
0 & 0 & 1 & 1 \\
0 & 0 & 1 & -1
\end{bmatrix}, \mathbf{C}_1 = \begin{bmatrix}
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & -1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & -1
\end{bmatrix}
\tag{56}
\end{equation}

观察发现 $\mathbf{B}_1$ 和 $\mathbf{C}_1$ 是分块对角矩阵，且每个子块都相同，为了简化表达，记这个子块为
\begin{equation}
\mathbf{R} = \begin{bmatrix}
1 & 1 \\
1 & -1
\end{bmatrix}
\tag{57}
\end{equation}

则，$\mathbf{B}_1$ 和 $\mathbf{C}_1$ 可记为
\begin{equation}
\mathbf{B}_1 = \mathbf{I}_2 \otimes \mathbf{R}, \mathbf{C}_1 = \mathbf{I}_4 \otimes \mathbf{R}
\tag{58}
\end{equation}

写成分块矩阵的形式更直观
\begin{equation}
\mathbf{B}_1 = \begin{bmatrix}
\mathbf{R} & \mathbf{R} \\
\mathbf{R} & \mathbf{R}
\end{bmatrix}, \mathbf{C}_1 = \begin{bmatrix}
\mathbf{R} & \mathbf{R} & \mathbf{R} & \mathbf{R} \\
\mathbf{R} & \mathbf{R} & \mathbf{R} & \mathbf{R} \\
\mathbf{R} & \mathbf{R} & \mathbf{R} & \mathbf{R} \\
\mathbf{R} & \mathbf{R} & \mathbf{R} & \mathbf{R}
\end{bmatrix}
\tag{59}
\end{equation}

由于初等变换矩阵和对角矩阵必然是稀疏矩阵，所以把 $\mathbf{R}$ 可分解为 2 个初等行变换矩阵和 1 个对角矩阵的乘积
\begin{equation}
\mathbf{R} = \mathbf{P}_{R_2} \mathbf{P}_{R_1} \mathbf{R}_{diag}
\tag{60}
\end{equation}

由于上式均是二阶矩阵，因此很容易求解出等式右端的矩阵 $\mathbf{P}_{R_2}, \mathbf{P}_{R_1}, \mathbf{R}_{diag}$，如下式所示，
\begin{equation}
\mathbf{P}_{R_2} = \begin{bmatrix}
1 & 0 \\
1 & 1
\end{bmatrix}, \mathbf{P}_{R_1} = \begin{bmatrix}
1 & -1/2 \\
0 & 1
\end{bmatrix}, \mathbf{R}_{diag} = \begin{bmatrix}
1 & 0 \\
0 & -2
\end{bmatrix}
\tag{61}
\end{equation}

把 2 个初等行变换矩阵合成 1 个变换矩阵，记为
\begin{equation}
\mathbf{P}_R = \mathbf{P}_{R_2} \mathbf{P}_{R_1}
\tag{62}
\end{equation}

那么 $\mathbf{B}_1$ 可进一步表示为
\begin{equation}
\begin{aligned}
\mathbf{B}_1 &= \left( \mathbf{I}_2 \right) \otimes \left( \mathbf{P}_R \mathbf{R}_{diag} \right) = \left( \mathbf{I}_2 \mathbf{I}_2 \right) \otimes \left( \mathbf{P}_R \mathbf{R}_{diag} \right) \\
&= \left( \mathbf{I}_2 \otimes \mathbf{P}_R \right) \left( \mathbf{I}_2 \otimes \mathbf{R}_{diag} \right)
\end{aligned}
\tag{63}
\end{equation}

则 $(\mathbf{B}_1 \otimes \mathbf{C}_1)$ 可进一步表示为
\begin{equation}
\begin{aligned}
(\mathbf{B}_1 \otimes \mathbf{C}_1) &= \left( \mathbf{I}_2 \otimes \mathbf{P}_R \right) \left( \mathbf{I}_2 \otimes \mathbf{R}_{diag} \right) \otimes \mathbf{C}_1 \\
&= \left[ \left( \mathbf{I}_2 \otimes \mathbf{P}_R \right) \left( \mathbf{I}_2 \otimes \mathbf{R}_{diag} \right) \right] \otimes \left[ \mathbf{C}_1 \mathbf{I}_8 \right] \\
&= \left[ \left( \mathbf{I}_2 \otimes \mathbf{P}_R \right) \otimes \left( \mathbf{C}_1 \right) \right] \cdot \left[ \left( \mathbf{I}_2 \otimes \mathbf{R}_{diag} \right) \otimes \mathbf{I}_8 \right]
\end{aligned}
\tag{64}
\end{equation}

根据 $\mathbf{P}_{\mathbf{R}}$ 和 $\mathbf{R}_{diag}$ 本身的特性，可得 $\left(\mathbf{I}_{2} \otimes \mathbf{P}_{\mathbf{R}}\right)$ 和 $\left(\mathbf{I}_{2} \otimes \mathbf{R}_{diag}\right)$ 每行仅有 1 个非零元素，而 $\mathbf{C}_{1}$ 每行有 2 个非零元素，所以 $\left(\mathbf{I}_{2} \otimes \mathbf{P}_{\mathbf{R}}\right) \otimes \mathbf{C}_{1}$ 和每行仅有 2 个非零元素， $\left(\mathbf{I}_{2} \otimes \mathbf{R}_{diag}\right) \otimes \mathbf{I}_{8}$ 为对角矩阵，记式(64)中等号右端第三行的 2 个乘积项分别为
\begin{equation}
\mathbf{P}_{2}=\left(\mathbf{I}_{2} \otimes \mathbf{P}_{\mathbf{R}}\right) \otimes\left(\mathbf{C}_{1}\right) \quad \mathbf{\Lambda}_{2}=\left(\mathbf{I}_{2} \otimes \mathbf{R}_{diag}\right) \otimes \mathbf{I}_{8}
\tag{65}
\end{equation}
则第二项 $\left(\mathbf{B}_{1} \otimes \mathbf{C}_{1}\right)$ 的分解结果如下
\begin{equation}
\left(\mathbf{B}_{1} \otimes \mathbf{C}_{1}\right)=\mathbf{P}_{1} \mathbf{\Lambda}_{1}
\tag{66}
\end{equation}
(3) 计算第三项 $\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)$

与 (2) 同理，可得分解结果
\begin{equation}
\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)=\mathbf{P}_{2} \mathbf{\Lambda}_{2}
\tag{67}
\end{equation}
需要注意的是，第三项 $\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)$ 无法写成类似于式(59)的分块对角矩阵形式，但可以把整个 $\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)$ 写成如下的分块矩阵形式
\begin{equation}
\left(\mathbf{B}_{2} \otimes \mathbf{C}_{2}\right)=\left[\begin{array}{ccc}
\mathbf{F}_{8 \times 8} & \mathbf{F}_{8 \times 8} & \mathbf{F}_{8 \times 8} \\
\mathbf{F}_{8 \times 8} & \mathbf{F}_{8 \times 8} & -j \cdot \mathbf{F}_{8 \times 8} \\
\mathbf{F}_{8 \times 8} & -\mathbf{F}_{8 \times 8} & j \cdot \mathbf{F}_{8 \times 8}
\end{array}\right]_{32 \times 32}
\tag{68}
\end{equation}
基于式(68)，可以先对矩阵进行分块行变换，可分解出分块对角矩阵
\begin{equation}
\mathbf{\Lambda}_{2}=\left[\begin{array}{ccc}
\mathbf{F}_{8 \times 8} & \mathbf{F}_{8 \times 8} & \\
& \mathbf{F}_{8 \times 8} & -2 \mathbf{F}_{8 \times 8} \\
& & -2 j \cdot \mathbf{F}_{8 \times 8}
\end{array}\right]
\tag{69}
\end{equation}
由于子块 $\mathbf{F}_{8 \times 8}$ 每行仅有 2 个非零元素，满足约束 1 。且经过计算得到分块行变换 $\mathbf{P}_{2}$ 也是满足约束 1 的稀疏矩阵

(4) 计算第四项 $\left(\mathbf{I}_{4} \otimes \mathbf{C}_{3}\right)$

由问题一的求解结果知 $\mathbf{C}_{3}$ 是满足约束 1 的稀疏矩阵，则 $\left(\mathbf{I}_{4} \otimes \mathbf{C}_{3}\right)$ 必然也是满足约束 1 的稀疏矩阵。

第四步，经过上述分解过程容易得到，式(53)中的稀疏子矩阵里，只有 $\mathbf{C}_{3}$ 不满足约束 2 ，因此可以采用问题三种的寻优算法求解 $\mathbf{C}_{3}$ 的最优值。

本文采用 MATLAB 实现上述算法，由于 $\mathbf{F}=\mathbf{F}_{4} \otimes \mathbf{F}_{8}$ 分解后的子矩阵都是 32 阶的，收纸张大小限制无法显示，因此 $\mathbf{F}=\beta\left(\mathbf{C}_{3}\right)\left(\mathbf{P}_{2} \mathbf{\Lambda}_{2}\right)\left(\mathbf{P}_{1} \mathbf{\Lambda}_{1}\right)\left(\mathbf{P}_{0}\right)$ 的分解结果详见附件，得到 RMSE 的值为 0.04。

\subsection*{6.3.2 基于 “混合积分解—降维寻优” 算法 II 的分解方法}

该方法根据 Kronecker 积的结合律和混合积性质把 $\mathbf{F}_{N_{1}}$ 和 $\mathbf{F}_{N_{2}}$ 拆分成稀疏矩阵相乘，再进行变换最终得到稀疏矩阵的积。具体过程如下，首先将 $\mathbf{F}_{4}$ 和 $\mathbf{F}_{8}$ 根据问题一中的 Cooley-Tukey 算法拆分为
\begin{equation}
\begin{aligned}
\mathbf{F}_{4} & =\mathbf{A}_{42} \mathbf{A}_{41} \mathbf{P}_{4} \\
\mathbf{F}_{8} & =\mathbf{A}_{83} \mathbf{A}_{82} \mathbf{A}_{81} \mathbf{P}_{8}
\end{aligned}
\tag{70}
\end{equation}

可以看出 $\mathbf{A}_{41}$ 和 $\mathbf{A}_{81}$ 可进一步准确的拆解为
\begin{equation}
\begin{aligned}
\mathbf{A}_{41} &= \mathbf{B} \otimes \mathbf{I}_2 \\
\mathbf{A}_{81} &= \mathbf{B} \otimes \mathbf{I}_4
\end{aligned}
\tag{71}
\end{equation}
其中
\[
\mathbf{B} = \begin{pmatrix}
1 & 1 \\
1 & -1
\end{pmatrix},
\]
$\mathbf{I}_2$、$\mathbf{I}_4$ 分别为 2 阶、4 阶单位阵。

而 $\mathbf{A}_{42}$、$\mathbf{A}_{82}$、$\mathbf{A}_{83}$ 无法精准的分为两个简单元素矩阵的 Kronecker 积，故采用近似的矩阵 $\hat{\mathbf{A}}_{42}$、$\hat{\mathbf{A}}_{82}$、$\hat{\mathbf{A}}_{83}$ 来代替：
\begin{align}
\hat{\mathbf{A}}_{42} &= \mathbf{B} \otimes \mathbf{R}_{42} \tag{72} \\
\hat{\mathbf{A}}_{82} &= \mathbf{B} \otimes \mathbf{R}_{42} \otimes \mathbf{I}_2 \tag{73} \\
\hat{\mathbf{A}}_{83} &= \mathbf{B} \otimes \mathbf{R}_{83} \tag{74}
\end{align}
其中
\begin{align*}
\mathbf{R}_{42} &= \begin{pmatrix}
1 & 0 \\
0 & -j
\end{pmatrix}, \\
\mathbf{R}_{83} &= \begin{pmatrix}
1 & & & \\
& 0.707 - 0.707j & & \\
& & -j & \\
& & & -0.707 - 0.707j
\end{pmatrix}.
\end{align*}

故 $\mathbf{F}_{32} = \mathbf{F}_4 \otimes \mathbf{F}_8$ 可近似地表达为
\begin{equation}
\hat{\mathbf{F}} = \hat{\mathbf{F}}_4 \otimes \hat{\mathbf{F}}_8
\tag{75}
\end{equation}

接下来对 Kronecker 积进行组合与分解
\begin{equation}
\begin{aligned}
\hat{\mathbf{F}} &= \hat{\mathbf{A}}_{42} \mathbf{A}_{41} \mathbf{P}_4 \otimes \hat{\mathbf{A}}_{83} \hat{\mathbf{A}}_{82} \mathbf{A}_{81} \mathbf{P}_8 \\
&= \mathbf{I}_4 \hat{\mathbf{A}}_{42} \mathbf{A}_{41} \mathbf{P}_4 \otimes \hat{\mathbf{A}}_{83} \hat{\mathbf{A}}_{82} \mathbf{A}_{81} \mathbf{P}_8 \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})(\hat{\mathbf{A}}_{42} \otimes \hat{\mathbf{A}}_{82})(\mathbf{A}_{41} \otimes \mathbf{A}_{81})(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})(\mathbf{B} \otimes \mathbf{R}_{42} \otimes \mathbf{B} \otimes \mathbf{R}_{42} \otimes \mathbf{I}_2)(\mathbf{B} \otimes \mathbf{I}_2 \otimes \mathbf{B} \otimes \mathbf{I}_4)(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})((\mathbf{B} \mathbf{B}) \otimes (\mathbf{R}_{42} \otimes \mathbf{B} \otimes \mathbf{R}_{42} \otimes \mathbf{I}_2)(\mathbf{I}_2 \otimes \mathbf{B} \otimes \mathbf{I}_4))(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})((\mathbf{B} \mathbf{B}) \otimes (\mathbf{R}_{42} \mathbf{I}_2) \otimes (\mathbf{B} \mathbf{R}_{42} \otimes \mathbf{I}_2)(\mathbf{B} \otimes \mathbf{I}_4))(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})((\mathbf{B} \mathbf{B}) \otimes \mathbf{R}_{42} \otimes (\mathbf{B} \mathbf{B}) \otimes (\mathbf{R}_{42} \otimes \mathbf{I}_2) \mathbf{I}_4)(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= (\mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83})((\mathbf{B} \mathbf{B}) \otimes \mathbf{R}_{42} \otimes (\mathbf{B} \mathbf{B}) \otimes \mathbf{R}_{42} \otimes \mathbf{I}_2)(\mathbf{P}_4 \otimes \mathbf{P}_8) \\
&= \mathbf{C}_1 \mathbf{C}_2 \mathbf{C}_3
\end{aligned}
\tag{76}
\end{equation}
其中
\begin{align*}
\mathbf{C}_1 &= \mathbf{I}_4 \otimes \hat{\mathbf{A}}_{83}, \\
\mathbf{C}_2 &= (\mathbf{B} \mathbf{B}) \otimes \mathbf{R}_{42} \otimes (\mathbf{B} \mathbf{B}) \otimes \mathbf{R}_{42} \otimes \mathbf{I}_2, \\
\mathbf{C}_3 &= \mathbf{P}_4 \otimes \mathbf{P}_8.
\end{align*}

在分解过程中利用了稀疏矩阵与对角阵的 Kronecker 积还是稀疏矩阵这一性质，以及
\[
\mathbf{B} \cdot \mathbf{B} = \begin{pmatrix}
2 & 0 \\
0 & 2
\end{pmatrix}
\]

这一特点，最终化解成立三个稀疏矩阵 $\mathbf{C}_1$、$\mathbf{C}_2$、$\mathbf{C}_3$ 相乘，为确保满足约束 2，还需要对它们进行元素控制，基于问题三中的优化搜索算法，将 $\mathbf{C}_1$、$\mathbf{C}_2$、$\mathbf{C}_3$ 的元素全部限制在取值范围 $P$ 内，此时计算 RMSE 只有 0.0589，硬件复杂度为 0。最终分解结果见附件中的变量 Opti_C1、Opti_C2、Opti_C3。

\subsection{结果与分析}

得到两种方法的性能对比如 6.4 表 6 所示：

\begin{table}[h]
\centering
\caption{混合积分解—降维寻优法性能对比}
\begin{tabular}{c c c}
\hline \hline
 & 方法 1 & 方法 2 \\
\hline
RMSE & 0.0323 & 0.0589 \\
硬件复杂度 $C$ & 640 & 0 \\
\hline \hline
\end{tabular}
\end{table}

如上表所示，两种方法都可以得到低于 0.1 的 RMSE 值。相对而言，方法 1 具有更高的拟合精度，但复杂度也随之增大。方法 2 牺牲了一定的拟合精度，但大大降低了复杂度。两种方法应根据实际工程的指标要求进行选择。

\subsection{总结与评价}

\subsubsection{模型优点}

(1) 矩阵降维处理。利用 Kronecker 积的性质，把高维矩阵分解转化为低维矩阵分解，同时在寻优的时候不必对 32 阶矩阵寻优，只需对 8 阶矩阵寻优，和问题三相比，问题四只是目标函数有所变化，寻优空间并未增大；

(2) 稀疏度高。由于初等变换矩阵和对角矩阵一定是稀疏矩阵，所以从初等变换的角度出发，把矩阵逐一分解，在满足约束 1 的条件下适当地把一些初等矩阵合并相乘从而减少子矩阵的个数；

(3) 较理想的寻优起点。先采用精确分解法得到满足约束 1 的子矩阵，再使用寻优算法求出同时满足约束 1 和约束 2 的最优解，这样会容易得到更理想的最优解；

(4) 较完整的数学理论支撑。本文提出的“混积分解法”是根据 DFT 矩阵的特征和混积的性质进行有限步骤的矩阵分解。该分解过程有很强的规律性，论文简要总结了这些规律，并给出较详细的公式推导。该理论依据对于更高阶的 DFT 混积矩阵分解有重要的参考价值。

\subsubsection{模型缺点}

随着矩阵阶数的增大，DFT 矩阵经过 Cooley-Tukey 算法分解后的稀疏子矩阵的规律性可能会越复杂，DFT 混积矩阵分解后的数学表达式可能也会越复杂。因此，DFT 混积矩阵分解的数学表达式还有优化的空间。

\section{问题五的模型建立与求解}

\subsection{问题分析}

问题五在问题三的基础上增加了 RMSE 限制，主要实现难点是如何调整稀疏矩阵元素的取值范围来满足 $RMSE \leq 0.1$，并权衡硬件复杂度 $C$。该问题的解决思路基于问题三的实现算法，对取值范围 $P$ 进行递增搜索，使 RMSE 最小。

\subsection{7.2 模型建立}

问题五的数学模型页与问题三类似，只是加上了精度的限制，将精度从目标函数变为了限制条件，然后对 $\mathcal{P}$ 也进行优化，修改后的目标函数和约束条件具体如下：

\textbf{目标函数:}

1) 目标函数得分最小化
\begin{equation}
F = \min \left\{ RMSE(\mathcal{A}, \beta) q_1 + P q_2 + B q_3 \right\}
\tag{77}
\end{equation}
其中: $q$ 为权重，$q_1 = 0.6$，$q_2 = 0.2$，$q_3 = 0.2$。

2) 优化目标一得分
\begin{equation}
RMSE(\mathcal{A}, \beta) = \frac{1}{N} \sqrt{\left\| \mathbf{F}_N - \beta \mathbf{A}_K \cdots \mathbf{A}_2 \mathbf{A}_1 \right\|_F^2}
\tag{78}
\end{equation}

3) 优化目标二得分
限定每个元素的取值范围来减小复杂度，使 $\mathcal{P}$ 集合中的元素对 2 取对数，然后取绝对值最大的数，使其最小
\begin{equation}
P = \max \left\{ \left| \log_2 \mathcal{P} \right| \right\}
\tag{79}
\end{equation}

4) 优化目标三得分
要优化 $\beta$，使 $\beta$ 的复杂度也最小
\begin{equation}
B = \left| \log_2 \beta \right|
\tag{80}
\end{equation}

\textbf{约束条件:}

1) 每个矩阵的每行至多只有 2 个非零元素
用 $\mathbf{P}_1, \mathbf{P}_2, \ldots, \mathbf{P}_K$ 矩阵分别表示对应 $\mathbf{A}_1, \mathbf{A}_2, \ldots, \mathbf{A}_K$ 矩阵非零元素的位置，即非零元素标记为 1，零元素标记为 0，得到 $\mathbf{P}_1, \mathbf{P}_2, \ldots, \mathbf{P}_K$ 矩阵为二进制矩阵。
\begin{equation}
\sum_{j=1}^N \mathbf{P}_k(i, j) \leq 2
\tag{81}
\end{equation}
其中 $k = 1, 2, \ldots, K$，$i = 1, 2, \ldots, N$，$\mathbf{P}_k(i, j)$ 表示 $\mathbf{P}_k$ 矩阵第 $i$ 行第 $j$ 列的元素。

2) 限定 $\mathcal{A}$ 每个矩阵 $\mathbf{A}_k$ 满足以下要求:
\begin{equation}
\mathbf{A}_k[l, m] \in \{ x + jy \mid x, y \in \mathcal{P} \}, \mathcal{P} = \{ 0, \pm 1, \pm 2, \ldots, \pm 2^{q-1} \},
\tag{82}
\end{equation}
\begin{equation}
k = 1, 2, \ldots, K; l, m = 1, 2, \ldots, N
\end{equation}
其中，$\mathbf{A}_k[l, m]$ 表示矩阵 $\mathbf{A}_k$ 第 $l$ 行第 $m$ 列的元素。

3) 限定研究矩阵的精度
\begin{equation}
RMSE(\mathcal{A}, \beta) \leq 0.1
\tag{83}
\end{equation}

\subsection{7.3 基于优化搜索的分解方法}

不难看出问题三的分解方法在 16 阶和 32 阶的矩阵分解下已经达到了要求，故重点在于 8 阶矩阵的优化，通过调整取值范围使 $P = [0, \pm 1, \pm 2, \pm 4, \pm 8]$，该优化搜索算法能使 RMSE 达到 0.095，复杂度 $C$ 为 0，$\hat{\mathbf{F}}_8 = \mathbf{A}_3 \mathbf{A}_2 \mathbf{A}_1 \mathbf{P}$ 具体分解情况如下:

\begin{equation}
\hat{\mathbf{F}}_{8}=\left[\begin{array}{cccccccc}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & -j & -j & -1 & -1 & j & j & 1 \\
1 & -j & -1 & j & 1 & -j & -1 & j \\
1 & -j & j & 1 & -1 & j & -j & -1 \\
1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\
1 & j & -j & 1 & -1 & -j & j & -1 \\
1 & j & -1 & -j & 1 & j & -1 & -j \\
1 & j & j & -1 & -1 & -j & -j & 1
\end{array}\right], \quad
\mathbf{A}_{1}=\left[\begin{array}{cccccccc}
1 & 1 & & & & & & \\
1 & -1 & & & & & & \\
& & 1 & 1 & & & & \\
& & 1 & -1 & & & & \\
& & & & 1 & 1 & & \\
& & & & 1 & -1 & & \\
& & & & & & 1 & 1 \\
& & & & & & 1 & -1
\end{array}\right],
\end{equation}

\begin{equation}
\mathbf{A}_{2}=\left[\begin{array}{cccccccc}
1 & 1 & & & & & & \\
& & 1 & -j & & & & \\
& & 1 & -1 & & & & \\
& & 1 & j & & & & \\
& & & & 1 & 1 & & \\
& & & & 1 & 1 & -j & \\
& & & & & & 1 & -1 \\
& & & & & & 1 & j
\end{array}\right], \quad
\mathbf{A}_{3}=\left[\begin{array}{cccc}
1 & 1 & 8j & -j \\
1 & 1 & 1 & 8j \\
1 & -1 & -j & \\
1 & 1 & -2j & j \\
& & 1 & -2j
\end{array}\right],
\end{equation}

\begin{equation}
\mathbf{P}=\left(\mathbf{e}_{1} \mid \mathbf{e}_{5} \mid \mathbf{e}_{3} \mid \mathbf{e}_{7} \mid \mathbf{e}_{2} \mid \mathbf{e}_{6} \mid \mathbf{e}_{4} \mid \mathbf{e}_{8}\right).
\end{equation}

\subsection{结果与分析}

该算法依旧固定 $\beta=\frac{1}{\sqrt{N}}$，以下是精度、复杂度和取值范围 $\mathbf{P}$ 的对比，如表 6 所示：

\begin{table}[h]
\centering
\caption{优化搜索算法仿真结果}
\begin{tabular}{c c c c}
\hline \hline
N & 8 & 16 & 32 \\
\hline
RMSE & 0.095 & 0.062 & 0.031 \\
硬件复杂度 C & 0 & 0 & 0 \\
取值范围 P & $P=[0, \pm 1, \pm 2, \pm 4, \pm 8]$ & $P=[0, \pm 1, \pm 2]$ & $P=[0, \pm 1, \pm 2]$ \\
\hline \hline
\end{tabular}
\end{table}

基于优化搜索算法的性能如下图所示：

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{image.png}
\caption{性能图}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{image.png}
    \caption{基于优化搜索算法的 RMSE 对比图}
    \label{fig:rmse_comparison}
\end{figure}

如图 \ref{fig:rmse_comparison} 所示，基于优化搜索算法得到的 RMSE 符合问题五给出的限制条件，且复杂度非常低，为 0。同时，5.3.2 中 N=8 的情况也可以作为本题的解，RMSE=0.064，且复杂度也为 0。

\section{总结与评价}

从测试性能表来看优化搜索算法在保证 $RMSE \leq 1$ 的同时也使硬件复杂度降到最低，并且优化了稀疏矩阵元素的取值范围 P。优化搜索代码的缺点是需要遍历可能的复数取值，取值范围 P 越大需要迭代的次数就越多，训练时间相应增加很多。不过综合来看优化搜索方法是一个不错的选择。

\section{总结与展望}

经过建模与分析，本文较好地解决了 DFT 矩阵分解的问题，有效降低了硬件计算复杂度，对信号的波束成形具有重大意义。针对各种约束提出了不同的算法，不过拟合精度还有提高的空间，可以优化代码继续改进。本文针对 DFT 矩阵分解作出的贡献主要包括以下几方面：

1. 针对问题一给出了基于 Cooley-Tukey 算法的分解方法，具有极高的准确性。
2. 针对问题二采用了基于 Feig-Winograd 矩阵映射的算法、遗传算法、序列二次规划算法进行分解，分析了各自的优劣势。
3. 针对问题三采用了遗传算法，并提出了一种新的优化搜索法，在极低的复杂度下也能分解出满足题目约束的稀疏矩阵。
4. 针对问题四提出了两种新的基于混合积分解-降维寻优的算法，分解出的矩阵完全符合题目条件，RMSE 都达到了 0.05。
5. 针对问题五继续改进了优化搜索算法，在 N=2、4、8、16、32 的情况下全部满足了 $RMSE \leq 0.1$ 的要求，求出的稀疏矩阵复杂度都为 0，极大地降低了硬件计算难度。

DFT 矩阵分解应用广泛，难点在于保证低复杂度的情况下还要求较高的拟合精度，目前的分解方法仍比较有限，需要进一步对分解方法进行研究，改进搜索算法。

\section*{参考文献}

[1] Viduneth A, Arjuna M, Xinyao T, et al. Analog Approximate-FFT 8/16-Beam Algorithms, Architectures and CMOS Circuits for 5G Beamforming MIMO Transceivers[J]. IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 2018, 8(3).

[2] Blahut R E. Fast algorithms for signal processing[M]. Cambridge University Press, 2010.

[3] Du J, Chen K, Yin P, et al. Design of an approximate FFT processor based on approximate complex multipliers[C]//2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). IEEE, 2021: 308-313.

[4] Bouguezel S, Ahmad M O, Swamy M N S. A note on "Split vector-radix-2/8 2-D Fast Fourier Transform"[J]. IEEE signal processing letters, 2005, 12(3): 185.

[5] Suzuki T, Ikehara M. Integer DCT based on direct-lifting of DCT-IDCT for lossless-to-lossy image coding[J]. IEEE Transactions on image processing, 2010, 19(11): 2958-2965.

[6] Alexey P, Olga P. Methods and Algorithms for Vertical Sliding Spatial-Frequency Fourier Processing of Two-Dimensional Discrete Finite Signals[C]//2023 25th International Conference on Digital Signal Processing and its Applications (DSPA). IEEE, 2023: 1-6.

[7] Du J, Chen K, Yin P, et al. Design of an approximate FFT processor based on approximate complex multipliers[C]//2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). IEEE, 2021: 308-313.

[8] Goldberg D E. Genetic Algorithm in search[J]. Optimization and Machine Learning, 1989 (11): 3-26.

[9] Holland J.H. Adaptation in Natural and Artificial Systems [M]. Massachusetts: MIT Press. 1975.

[10] 马永杰, 云文霞. 遗传算法研究进展[J]. 计算机应用研究, 2012, 29(04): 1201-1206+1210.

[11] 孙宝凤, 申琇秀, 龙书玲, 卢昭宇. 混流装配线的双目标投产排序决策模型[J]. 计算机集成制造系统, 2017, 23(07): 1481-1491. DOI: 10.13196/j.cims.2017.07.013.

[12] 刘晓霞. 种群规模对遗传算法性能影响的研究[D]. 华北电力大学（河北）, 2010.

[13] 刘佳楠. 基于遗传算法的混流装配线平衡与排产问题研究 [D]. 青岛理工大学, 2020. DOI: 10.27263/d.cnki.gqudc.2020.000160.