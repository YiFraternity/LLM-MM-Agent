{
  "tasks": [],
  "problem_str": "问题背景：\n能见度是气象、公路行车、飞机飞行中常见指标，单位通常是米。影响能见度的因素主要是雾和霾。众所周知，能见度对高速公路行车安全非常重要，当能见度很低时，为了行车安全，高速公路管理者通常的做法是封路。而在航空领域，习惯用跑道能见度反映机场附近雾和霾的大小，其定义为在跑道的一端沿跑道方向能辨认出跑道或接近跑道的目标物（夜间为跑道边灯）的最大距离。一般情况下，当机场能见度只有400米左右时，会禁止航班起降。当机场能见度只有600-800米左右时航班虽然可以正常起降。但出于安全考虑，机场会采取临时控制航班流量的措施，拉大航班起飞间隔，容易造成航班延误。因此，能见度预测是高速公路管理部门和航空公司十分关注的问题。\n\n激光能见度仪是常用的检测能见度的仪器。目前，我国高速路网已逐步形成，若大量使用激光能见度仪对全国高速路网进行全覆盖将耗资巨大，同时激光能见度仪还存在对团雾检测精度不高，探测的范围很小，维护成本高等不足。近年来，基于视频的路况（跑道）能见度检测方法受到人们的关注，它某种程度上克服了激光能见度仪的不足。视频能见度检测方法是将大气光学分析与图像处理及人工智能技术结合，通过对视频图像的分析处理，建立视频图像与真实场景之间的关系，再根据图像特征的变化，间接计算出能见度数值。但现有的基于视频图像的能见度检测方法，由于是间接计算，很难准确地估算能见度。特别地，这些方法中大多数只选取少量视频、截取图像中的某些固有特征【1, 2】，基于Koschmieder定律【3, 4】进行估计，并没有充分利用视频的连续信息，所以估计的精度不高，有较大的改进空间。\n\n由于一般情况下，能见度究竟是2000米还是3000米对公路行车、飞机飞行几乎都没有影响，只是在恶劣天气，尤其是大雾情况下需要准确估计当前、特别是预测未来的能见度。所以本项目只关注大雾的演化规律。\n\n事实上，大雾的形成和消散有其自身的规律，通常与近地层的气象因素有关。而视频资料包含了丰富的信息，特别是涵盖了大雾的变化过程信息。充分利用这些信息，不仅可以提高能见度估计精度，也可以对大雾的消散进行预测。\n\n问题要求：\n为了估计不同大雾情况下对应的能见度以及预测大雾的消散，请回答以下问题：\n\n1. 众所周知，雾与近地面的气象因素有关。建立模型描述能见度与地面气象观测（温度、湿度和风速等）之间的关系，并针对题目所提供的数据（机场 AMOS 观测.zip）导出具体的关系式；\n2. 根据题目提供的某机场视频数据（机场视频.zip）和能见度数据（机场 AMOS 观测.zip），建立基于视频数据的能见度估计深度学习模型，并对估计的能见度进行精度评估；\n3. 高速公路某路段只有监控视频数据，建立不依赖能见度仪观测数据的能见度估计算法（提示：事实上，在有雾的情形可以估计视频中物体的景深【1】。反过来，理论上也可以利用视频中不同景深的物体，在不同能见度下的亮度差异估计能见度），讨论相关算法实现过程，并针对题目提供的一段视频（高速公路视频截图.zip）绘制该时间段这段高速公路能见度随时间变化曲线；\n4. 利用问题三得到的能见度随时间变化规律，建立数学模型预测大雾变化趋势（加重或减弱）、何时散去（达到指定的能见度，比如 MOR=150m）？\nAddendum: \n相关名词解释\n\n1. 能见度，是指视力正常的人能将目标物从背景中识别出来的最大距离。所谓“能见”，在白天是指能看到和辨认出目标物的轮廓和形体，在夜间是指能清楚看到目标灯的发光点。\n2. 雾：在水汽充足、微风及大气稳定的情况下，相对湿度达到 100\\% 时，空气中的水汽便会凝结成细微的水滴悬浮于空中，使地面水平的能见度下降，这种天气现象称为雾。\n3. 团雾：是受局部地区微气候环境的影响，在大雾中数十米到上百米的局部范围内，出现的更“浓”、能见度更低的雾。团雾外视线良好，团雾内一片朦胧。\n4. 目标物和背景的亮度对比。在大气中目标物能见与否，取决于本身亮度，又与它同背景的亮度差异有关。比如，亮度暗的目标物在亮的背景衬托下，清晰可见。或者亮的目标物在暗的背景下，同样清晰可见。表示这种差异的指标是亮度的对比值 $K$。设 $B_0$ 为目标物的固有亮度，$B_0'$ 为背景的固有亮度，则亮度的对比值定义为：\n\\[\nK = \\frac{|B_0' - B_0|}{B_0'}, \\text{ if } B_0' \\geq B_0; \\quad K = \\frac{|B_0' - B_0|}{B_0}, \\text{ if } B_0' < B_0.\n\\]\n\n5. 能见度测量基本方程：\n\\[\nF = F_0 e^{-\\sigma z}\n\\]\n这里 $F$ 和 $F_0$ 分别表示观测和入射的光照强度，参数 $\\sigma$ 称为衰减系数，与雾的厚度有关：$\\sigma$ 越大表明雾越浓。气象光学视程 (MOR)\n\\[\n\\text{MOR} = \\frac{\\log(F/F_0)}{-\\sigma} = \\frac{\\log(0.05)}{-\\sigma}\n\\]\n\n6. 跑道视程 (RVR)：是指在跑道中线上的航空器上的飞行员能看到跑道面上的标志或跑道边界灯或中线灯的距离。\n\n参考文献\n\n1. S. K. Nayar, S. G. Narasimhan, Vision in bad weather, ICCV'99\n2. R. T. Tan, Visibility in bad weather from a single image, CVPR, 2008\n3. N. Hautiere, J-P Tarel, J Lavenant D. Aubert, Automatic fog detection and estimation of visibility distance through use of onboard camera, Machine Vision and Application, 2006, 17 (1): 8-20\n4. C. Sakaridis, D. Dai, L. V. Gool, Semantic foggy scene understanding with synthetic data, International J. Computer Vision, 2018, 3\nDataset Path:\n['AMOS20191216', 'AMOS20200313', '机场视频参见百度云网盘.md', '能见度估计与预测.docx', '能见度估计与预测.pdf', '附件-资料格式（与赛题有关信息）说明.docx', '高速公路视频截图']\n\nData Description:\n该数据集由若干与能见度研究和视频监控相关的子集构成，主要包括两个时段的观测子文件夹（如 AMOS20191216 和 AMOS20200313，每个含 WIND、VIS、PTU 类 .his 数据文件夹）以及用于能见度估计与预测的说明文档、附件格式说明、机场视频下载信息和高速公路视频截图等辅助资料；气象观测项包括气压（PAINS/HPA、QFE、QNH）、温度（TEMP）、相对湿度（RH）、露点（DEWPOINT）、风速/风向与垂直风速（如 WS2A、WD2A、CW2A，2 分钟平均、单位 m/s 或度）、跑道视程与最小能见度（RVR_1A、MOR_1A，1 分钟平均、单位米）、灯光数据（LIGHT_S）、记录创建时间与本地时间（CREATEDATE、LOCALDATE，世界时/北京时间）及观测站点标识（SITE）等，字段普遍带有明确单位（hPa、℃、%、m、m/s、°）；提供的图像资料包括以 original_frameXXX.bmp 命名的高速公路视频帧和机场跑道监控视频（下载链接与提取密码在“机场视频参见百度云网盘.md”中），相关文档详细说明了数据来源、采样频率与使用场景。总体上，该数据集适合用于研究能见度与地面气象因子（温度、湿度、气压、风速/风向等）之间的关系、雾的形成与消散规律分析，以及基于视频图像与同步气象观测数据构建和验证能见度估计或短期预报模型，用于交通安全监测、机场运行保障和智能视频感知等应用。",
  "problem": {
    "background": "能见度是气象、公路行车、飞机飞行中常见指标，单位通常是米。影响能见度的因素主要是雾和霾。众所周知，能见度对高速公路行车安全非常重要，当能见度很低时，为了行车安全，高速公路管理者通常的做法是封路。而在航空领域，习惯用跑道能见度反映机场附近雾和霾的大小，其定义为在跑道的一端沿跑道方向能辨认出跑道或接近跑道的目标物（夜间为跑道边灯）的最大距离。一般情况下，当机场能见度只有400米左右时，会禁止航班起降。当机场能见度只有600-800米左右时航班虽然可以正常起降。但出于安全考虑，机场会采取临时控制航班流量的措施，拉大航班起飞间隔，容易造成航班延误。因此，能见度预测是高速公路管理部门和航空公司十分关注的问题。\n\n激光能见度仪是常用的检测能见度的仪器。目前，我国高速路网已逐步形成，若大量使用激光能见度仪对全国高速路网进行全覆盖将耗资巨大，同时激光能见度仪还存在对团雾检测精度不高，探测的范围很小，维护成本高等不足。近年来，基于视频的路况（跑道）能见度检测方法受到人们的关注，它某种程度上克服了激光能见度仪的不足。视频能见度检测方法是将大气光学分析与图像处理及人工智能技术结合，通过对视频图像的分析处理，建立视频图像与真实场景之间的关系，再根据图像特征的变化，间接计算出能见度数值。但现有的基于视频图像的能见度检测方法，由于是间接计算，很难准确地估算能见度。特别地，这些方法中大多数只选取少量视频、截取图像中的某些固有特征【1, 2】，基于Koschmieder定律【3, 4】进行估计，并没有充分利用视频的连续信息，所以估计的精度不高，有较大的改进空间。\n\n由于一般情况下，能见度究竟是2000米还是3000米对公路行车、飞机飞行几乎都没有影响，只是在恶劣天气，尤其是大雾情况下需要准确估计当前、特别是预测未来的能见度。所以本项目只关注大雾的演化规律。\n\n事实上，大雾的形成和消散有其自身的规律，通常与近地层的气象因素有关。而视频资料包含了丰富的信息，特别是涵盖了大雾的变化过程信息。充分利用这些信息，不仅可以提高能见度估计精度，也可以对大雾的消散进行预测。",
    "problem_requirement": "为了估计不同大雾情况下对应的能见度以及预测大雾的消散，请回答以下问题：\n\n1. 众所周知，雾与近地面的气象因素有关。建立模型描述能见度与地面气象观测（温度、湿度和风速等）之间的关系，并针对题目所提供的数据（机场 AMOS 观测.zip）导出具体的关系式；\n2. 根据题目提供的某机场视频数据（机场视频.zip）和能见度数据（机场 AMOS 观测.zip），建立基于视频数据的能见度估计深度学习模型，并对估计的能见度进行精度评估；\n3. 高速公路某路段只有监控视频数据，建立不依赖能见度仪观测数据的能见度估计算法（提示：事实上，在有雾的情形可以估计视频中物体的景深【1】。反过来，理论上也可以利用视频中不同景深的物体，在不同能见度下的亮度差异估计能见度），讨论相关算法实现过程，并针对题目提供的一段视频（高速公路视频截图.zip）绘制该时间段这段高速公路能见度随时间变化曲线；\n4. 利用问题三得到的能见度随时间变化规律，建立数学模型预测大雾变化趋势（加重或减弱）、何时散去（达到指定的能见度，比如 MOR=150m）？",
    "dataset_path": [
      "AMOS20191216",
      "AMOS20200313",
      "机场视频参见百度云网盘.md",
      "能见度估计与预测.docx",
      "能见度估计与预测.pdf",
      "附件-资料格式（与赛题有关信息）说明.docx",
      "高速公路视频截图"
    ],
    "dataset_description": {
      "AMOS20191216": "该文件夹包含三个子文件夹：WIND_R06_15.his, VIS_R06_15.his, PTU_R06_15.his。WIND_R06_15.his 文件夹可能包含与风速相关的数据，VIS_R06_15.his 文件夹可能包含能见度数据，PTU_R06_15.his 文件夹可能包含温度、湿度等气象观测数据。这些数据可用于研究能见度与地面气象因素之间的关系，以及建立基于视频数据的能见度估计模型。",
      "AMOS20200313": "该文件夹包含三个子文件夹：WIND_R06_12.his, VIS_R06_12.his, PTU_R06_12.his。WIND_R06_12.his 文件夹包含风速数据，VIS_R06_12.his 文件夹包含能见度数据，PTU_R06_12.his 文件夹包含温度和湿度数据。这些数据可用于研究能见度与地面气象因素之间的关系，以及建立基于视频数据的能见度估计模型。",
      "机场视频参见百度云网盘": "该文件提供了2020年E题机场视频的下载链接和密码。文件名为机场视频参见百度云网盘.md，内容包括视频的百度云盘下载链接和提取密码。",
      "能见度估计与预测": "该文件提供了关于能见度估计与预测的研究背景、问题描述、相关名词解释、参考文献以及数据说明。具体内容包括高速公路视频图像、某机场跑道监控视频、某机场对应时间段的能见度仪观测数据、地面温度、湿度、气压和风速等。",
      "附件-资料格式（与赛题有关信息）说明": "该文件包含了机场气象观测数据，包括温度、湿度、风速等气象因素以及能见度数据，用于研究雾的形成和消散规律。",
      "高速公路视频截图": "该文件夹包含一系列高速公路视频截图，文件名为original_frameXXX.bmp，其中XXX为三位数字序号。这些图片用于研究在不同能见度条件下高速公路的视觉变化，以建立不依赖能见度仪观测数据的能见度估计算法。"
    },
    "variable_description": [
      {},
      {},
      {},
      {},
      {},
      {
        "PAINS（HPA）": "本站气压，单位：百帕",
        "QFE 06": "飞机着陆地区最高点气压，单位：百帕",
        "QNH": "修正海平面气压，单位：百帕",
        "TEMP": "温度，单位：摄氏度",
        "RH": "相对湿度，单位：百分比",
        "DEWPOINT": "露点温度，单位：摄氏度",
        "RVR_1A": "1分钟平均跑道视程，单位：米",
        "MOR_1A": "1分钟平均最小能见度，单位：米",
        "LIGHT_S": "灯光数据",
        "WS2A": "2分钟平均风速，单位：米/秒",
        "WD2A": "2分钟平均风向，单位：度",
        "CW2A": "2分钟平均垂直风速，单位：米/秒",
        "CREATEDATE": "观测记录创建时间，世界时",
        "LOCALDATE": "对应的北京时",
        "SITE": "观测点名称"
      },
      {}
    ],
    "addendum": "相关名词解释\n\n1. 能见度，是指视力正常的人能将目标物从背景中识别出来的最大距离。所谓“能见”，在白天是指能看到和辨认出目标物的轮廓和形体，在夜间是指能清楚看到目标灯的发光点。\n2. 雾：在水汽充足、微风及大气稳定的情况下，相对湿度达到 100\\% 时，空气中的水汽便会凝结成细微的水滴悬浮于空中，使地面水平的能见度下降，这种天气现象称为雾。\n3. 团雾：是受局部地区微气候环境的影响，在大雾中数十米到上百米的局部范围内，出现的更“浓”、能见度更低的雾。团雾外视线良好，团雾内一片朦胧。\n4. 目标物和背景的亮度对比。在大气中目标物能见与否，取决于本身亮度，又与它同背景的亮度差异有关。比如，亮度暗的目标物在亮的背景衬托下，清晰可见。或者亮的目标物在暗的背景下，同样清晰可见。表示这种差异的指标是亮度的对比值 $K$。设 $B_0$ 为目标物的固有亮度，$B_0'$ 为背景的固有亮度，则亮度的对比值定义为：\n\\[\nK = \\frac{|B_0' - B_0|}{B_0'}, \\text{ if } B_0' \\geq B_0; \\quad K = \\frac{|B_0' - B_0|}{B_0}, \\text{ if } B_0' < B_0.\n\\]\n\n5. 能见度测量基本方程：\n\\[\nF = F_0 e^{-\\sigma z}\n\\]\n这里 $F$ 和 $F_0$ 分别表示观测和入射的光照强度，参数 $\\sigma$ 称为衰减系数，与雾的厚度有关：$\\sigma$ 越大表明雾越浓。气象光学视程 (MOR)\n\\[\n\\text{MOR} = \\frac{\\log(F/F_0)}{-\\sigma} = \\frac{\\log(0.05)}{-\\sigma}\n\\]\n\n6. 跑道视程 (RVR)：是指在跑道中线上的航空器上的飞行员能看到跑道面上的标志或跑道边界灯或中线灯的距离。\n\n参考文献\n\n1. S. K. Nayar, S. G. Narasimhan, Vision in bad weather, ICCV'99\n2. R. T. Tan, Visibility in bad weather from a single image, CVPR, 2008\n3. N. Hautiere, J-P Tarel, J Lavenant D. Aubert, Automatic fog detection and estimation of visibility distance through use of onboard camera, Machine Vision and Application, 2006, 17 (1): 8-20\n4. C. Sakaridis, D. Dai, L. V. Gool, Semantic foggy scene understanding with synthetic data, International J. Computer Vision, 2018, 3",
    "data_summary": "Dataset Path:\n['AMOS20191216', 'AMOS20200313', '机场视频参见百度云网盘.md', '能见度估计与预测.docx', '能见度估计与预测.pdf', '附件-资料格式（与赛题有关信息）说明.docx', '高速公路视频截图']\n\nData Description:\n该数据集由若干与能见度研究和视频监控相关的子集构成，主要包括两个时段的观测子文件夹（如 AMOS20191216 和 AMOS20200313，每个含 WIND、VIS、PTU 类 .his 数据文件夹）以及用于能见度估计与预测的说明文档、附件格式说明、机场视频下载信息和高速公路视频截图等辅助资料；气象观测项包括气压（PAINS/HPA、QFE、QNH）、温度（TEMP）、相对湿度（RH）、露点（DEWPOINT）、风速/风向与垂直风速（如 WS2A、WD2A、CW2A，2 分钟平均、单位 m/s 或度）、跑道视程与最小能见度（RVR_1A、MOR_1A，1 分钟平均、单位米）、灯光数据（LIGHT_S）、记录创建时间与本地时间（CREATEDATE、LOCALDATE，世界时/北京时间）及观测站点标识（SITE）等，字段普遍带有明确单位（hPa、℃、%、m、m/s、°）；提供的图像资料包括以 original_frameXXX.bmp 命名的高速公路视频帧和机场跑道监控视频（下载链接与提取密码在“机场视频参见百度云网盘.md”中），相关文档详细说明了数据来源、采样频率与使用场景。总体上，该数据集适合用于研究能见度与地面气象因子（温度、湿度、气压、风速/风向等）之间的关系、雾的形成与消散规律分析，以及基于视频图像与同步气象观测数据构建和验证能见度估计或短期预报模型，用于交通安全监测、机场运行保障和智能视频感知等应用。",
    "data_description": {
      "AMOS20191216": "该文件夹包含三个子文件夹：WIND_R06_15.his, VIS_R06_15.his, PTU_R06_15.his。WIND_R06_15.his 文件夹可能包含与风速相关的数据，VIS_R06_15.his 文件夹可能包含能见度数据，PTU_R06_15.his 文件夹可能包含温度、湿度等气象观测数据。这些数据可用于研究能见度与地面气象因素之间的关系，以及建立基于视频数据的能见度估计模型。",
      "AMOS20200313": "该文件夹包含三个子文件夹：WIND_R06_12.his, VIS_R06_12.his, PTU_R06_12.his。WIND_R06_12.his 文件夹包含风速数据，VIS_R06_12.his 文件夹包含能见度数据，PTU_R06_12.his 文件夹包含温度和湿度数据。这些数据可用于研究能见度与地面气象因素之间的关系，以及建立基于视频数据的能见度估计模型。",
      "机场视频参见百度云网盘": "该文件提供了2020年E题机场视频的下载链接和密码。文件名为机场视频参见百度云网盘.md，内容包括视频的百度云盘下载链接和提取密码。",
      "能见度估计与预测": "该文件提供了关于能见度估计与预测的研究背景、问题描述、相关名词解释、参考文献以及数据说明。具体内容包括高速公路视频图像、某机场跑道监控视频、某机场对应时间段的能见度仪观测数据、地面温度、湿度、气压和风速等。",
      "附件-资料格式（与赛题有关信息）说明": "该文件包含了机场气象观测数据，包括温度、湿度、风速等气象因素以及能见度数据，用于研究雾的形成和消散规律。",
      "高速公路视频截图": "该文件夹包含一系列高速公路视频截图，文件名为original_frameXXX.bmp，其中XXX为三位数字序号。这些图片用于研究在不同能见度条件下高速公路的视觉变化，以建立不依赖能见度仪观测数据的能见度估计算法。"
    },
    "problem_str": "问题背景：\n能见度是气象、公路行车、飞机飞行中常见指标，单位通常是米。影响能见度的因素主要是雾和霾。众所周知，能见度对高速公路行车安全非常重要，当能见度很低时，为了行车安全，高速公路管理者通常的做法是封路。而在航空领域，习惯用跑道能见度反映机场附近雾和霾的大小，其定义为在跑道的一端沿跑道方向能辨认出跑道或接近跑道的目标物（夜间为跑道边灯）的最大距离。一般情况下，当机场能见度只有400米左右时，会禁止航班起降。当机场能见度只有600-800米左右时航班虽然可以正常起降。但出于安全考虑，机场会采取临时控制航班流量的措施，拉大航班起飞间隔，容易造成航班延误。因此，能见度预测是高速公路管理部门和航空公司十分关注的问题。\n\n激光能见度仪是常用的检测能见度的仪器。目前，我国高速路网已逐步形成，若大量使用激光能见度仪对全国高速路网进行全覆盖将耗资巨大，同时激光能见度仪还存在对团雾检测精度不高，探测的范围很小，维护成本高等不足。近年来，基于视频的路况（跑道）能见度检测方法受到人们的关注，它某种程度上克服了激光能见度仪的不足。视频能见度检测方法是将大气光学分析与图像处理及人工智能技术结合，通过对视频图像的分析处理，建立视频图像与真实场景之间的关系，再根据图像特征的变化，间接计算出能见度数值。但现有的基于视频图像的能见度检测方法，由于是间接计算，很难准确地估算能见度。特别地，这些方法中大多数只选取少量视频、截取图像中的某些固有特征【1, 2】，基于Koschmieder定律【3, 4】进行估计，并没有充分利用视频的连续信息，所以估计的精度不高，有较大的改进空间。\n\n由于一般情况下，能见度究竟是2000米还是3000米对公路行车、飞机飞行几乎都没有影响，只是在恶劣天气，尤其是大雾情况下需要准确估计当前、特别是预测未来的能见度。所以本项目只关注大雾的演化规律。\n\n事实上，大雾的形成和消散有其自身的规律，通常与近地层的气象因素有关。而视频资料包含了丰富的信息，特别是涵盖了大雾的变化过程信息。充分利用这些信息，不仅可以提高能见度估计精度，也可以对大雾的消散进行预测。\n\n问题要求：\n为了估计不同大雾情况下对应的能见度以及预测大雾的消散，请回答以下问题：\n\n1. 众所周知，雾与近地面的气象因素有关。建立模型描述能见度与地面气象观测（温度、湿度和风速等）之间的关系，并针对题目所提供的数据（机场 AMOS 观测.zip）导出具体的关系式；\n2. 根据题目提供的某机场视频数据（机场视频.zip）和能见度数据（机场 AMOS 观测.zip），建立基于视频数据的能见度估计深度学习模型，并对估计的能见度进行精度评估；\n3. 高速公路某路段只有监控视频数据，建立不依赖能见度仪观测数据的能见度估计算法（提示：事实上，在有雾的情形可以估计视频中物体的景深【1】。反过来，理论上也可以利用视频中不同景深的物体，在不同能见度下的亮度差异估计能见度），讨论相关算法实现过程，并针对题目提供的一段视频（高速公路视频截图.zip）绘制该时间段这段高速公路能见度随时间变化曲线；\n4. 利用问题三得到的能见度随时间变化规律，建立数学模型预测大雾变化趋势（加重或减弱）、何时散去（达到指定的能见度，比如 MOR=150m）？\nAddendum: \n相关名词解释\n\n1. 能见度，是指视力正常的人能将目标物从背景中识别出来的最大距离。所谓“能见”，在白天是指能看到和辨认出目标物的轮廓和形体，在夜间是指能清楚看到目标灯的发光点。\n2. 雾：在水汽充足、微风及大气稳定的情况下，相对湿度达到 100\\% 时，空气中的水汽便会凝结成细微的水滴悬浮于空中，使地面水平的能见度下降，这种天气现象称为雾。\n3. 团雾：是受局部地区微气候环境的影响，在大雾中数十米到上百米的局部范围内，出现的更“浓”、能见度更低的雾。团雾外视线良好，团雾内一片朦胧。\n4. 目标物和背景的亮度对比。在大气中目标物能见与否，取决于本身亮度，又与它同背景的亮度差异有关。比如，亮度暗的目标物在亮的背景衬托下，清晰可见。或者亮的目标物在暗的背景下，同样清晰可见。表示这种差异的指标是亮度的对比值 $K$。设 $B_0$ 为目标物的固有亮度，$B_0'$ 为背景的固有亮度，则亮度的对比值定义为：\n\\[\nK = \\frac{|B_0' - B_0|}{B_0'}, \\text{ if } B_0' \\geq B_0; \\quad K = \\frac{|B_0' - B_0|}{B_0}, \\text{ if } B_0' < B_0.\n\\]\n\n5. 能见度测量基本方程：\n\\[\nF = F_0 e^{-\\sigma z}\n\\]\n这里 $F$ 和 $F_0$ 分别表示观测和入射的光照强度，参数 $\\sigma$ 称为衰减系数，与雾的厚度有关：$\\sigma$ 越大表明雾越浓。气象光学视程 (MOR)\n\\[\n\\text{MOR} = \\frac{\\log(F/F_0)}{-\\sigma} = \\frac{\\log(0.05)}{-\\sigma}\n\\]\n\n6. 跑道视程 (RVR)：是指在跑道中线上的航空器上的飞行员能看到跑道面上的标志或跑道边界灯或中线灯的距离。\n\n参考文献\n\n1. S. K. Nayar, S. G. Narasimhan, Vision in bad weather, ICCV'99\n2. R. T. Tan, Visibility in bad weather from a single image, CVPR, 2008\n3. N. Hautiere, J-P Tarel, J Lavenant D. Aubert, Automatic fog detection and estimation of visibility distance through use of onboard camera, Machine Vision and Application, 2006, 17 (1): 8-20\n4. C. Sakaridis, D. Dai, L. V. Gool, Semantic foggy scene understanding with synthetic data, International J. Computer Vision, 2018, 3\nDataset Path:\n['AMOS20191216', 'AMOS20200313', '机场视频参见百度云网盘.md', '能见度估计与预测.docx', '能见度估计与预测.pdf', '附件-资料格式（与赛题有关信息）说明.docx', '高速公路视频截图']\n\nData Description:\n该数据集由若干与能见度研究和视频监控相关的子集构成，主要包括两个时段的观测子文件夹（如 AMOS20191216 和 AMOS20200313，每个含 WIND、VIS、PTU 类 .his 数据文件夹）以及用于能见度估计与预测的说明文档、附件格式说明、机场视频下载信息和高速公路视频截图等辅助资料；气象观测项包括气压（PAINS/HPA、QFE、QNH）、温度（TEMP）、相对湿度（RH）、露点（DEWPOINT）、风速/风向与垂直风速（如 WS2A、WD2A、CW2A，2 分钟平均、单位 m/s 或度）、跑道视程与最小能见度（RVR_1A、MOR_1A，1 分钟平均、单位米）、灯光数据（LIGHT_S）、记录创建时间与本地时间（CREATEDATE、LOCALDATE，世界时/北京时间）及观测站点标识（SITE）等，字段普遍带有明确单位（hPa、℃、%、m、m/s、°）；提供的图像资料包括以 original_frameXXX.bmp 命名的高速公路视频帧和机场跑道监控视频（下载链接与提取密码在“机场视频参见百度云网盘.md”中），相关文档详细说明了数据来源、采样频率与使用场景。总体上，该数据集适合用于研究能见度与地面气象因子（温度、湿度、气压、风速/风向等）之间的关系、雾的形成与消散规律分析，以及基于视频图像与同步气象观测数据构建和验证能见度估计或短期预报模型，用于交通安全监测、机场运行保障和智能视频感知等应用。"
  },
  "problem_background": "能见度是气象、公路行车、飞机飞行中常见指标，单位通常是米。影响能见度的因素主要是雾和霾。众所周知，能见度对高速公路行车安全非常重要，当能见度很低时，为了行车安全，高速公路管理者通常的做法是封路。而在航空领域，习惯用跑道能见度反映机场附近雾和霾的大小，其定义为在跑道的一端沿跑道方向能辨认出跑道或接近跑道的目标物（夜间为跑道边灯）的最大距离。一般情况下，当机场能见度只有400米左右时，会禁止航班起降。当机场能见度只有600-800米左右时航班虽然可以正常起降。但出于安全考虑，机场会采取临时控制航班流量的措施，拉大航班起飞间隔，容易造成航班延误。因此，能见度预测是高速公路管理部门和航空公司十分关注的问题。\n\n激光能见度仪是常用的检测能见度的仪器。目前，我国高速路网已逐步形成，若大量使用激光能见度仪对全国高速路网进行全覆盖将耗资巨大，同时激光能见度仪还存在对团雾检测精度不高，探测的范围很小，维护成本高等不足。近年来，基于视频的路况（跑道）能见度检测方法受到人们的关注，它某种程度上克服了激光能见度仪的不足。视频能见度检测方法是将大气光学分析与图像处理及人工智能技术结合，通过对视频图像的分析处理，建立视频图像与真实场景之间的关系，再根据图像特征的变化，间接计算出能见度数值。但现有的基于视频图像的能见度检测方法，由于是间接计算，很难准确地估算能见度。特别地，这些方法中大多数只选取少量视频、截取图像中的某些固有特征【1, 2】，基于Koschmieder定律【3, 4】进行估计，并没有充分利用视频的连续信息，所以估计的精度不高，有较大的改进空间。\n\n由于一般情况下，能见度究竟是2000米还是3000米对公路行车、飞机飞行几乎都没有影响，只是在恶劣天气，尤其是大雾情况下需要准确估计当前、特别是预测未来的能见度。所以本项目只关注大雾的演化规律。\n\n事实上，大雾的形成和消散有其自身的规律，通常与近地层的气象因素有关。而视频资料包含了丰富的信息，特别是涵盖了大雾的变化过程信息。充分利用这些信息，不仅可以提高能见度估计精度，也可以对大雾的消散进行预测。",
  "problem_requirement": "为了估计不同大雾情况下对应的能见度以及预测大雾的消散，请回答以下问题：\n\n1. 众所周知，雾与近地面的气象因素有关。建立模型描述能见度与地面气象观测（温度、湿度和风速等）之间的关系，并针对题目所提供的数据（机场 AMOS 观测.zip）导出具体的关系式；\n2. 根据题目提供的某机场视频数据（机场视频.zip）和能见度数据（机场 AMOS 观测.zip），建立基于视频数据的能见度估计深度学习模型，并对估计的能见度进行精度评估；\n3. 高速公路某路段只有监控视频数据，建立不依赖能见度仪观测数据的能见度估计算法（提示：事实上，在有雾的情形可以估计视频中物体的景深【1】。反过来，理论上也可以利用视频中不同景深的物体，在不同能见度下的亮度差异估计能见度），讨论相关算法实现过程，并针对题目提供的一段视频（高速公路视频截图.zip）绘制该时间段这段高速公路能见度随时间变化曲线；\n4. 利用问题三得到的能见度随时间变化规律，建立数学模型预测大雾变化趋势（加重或减弱）、何时散去（达到指定的能见度，比如 MOR=150m）？",
  "problem_analysis": "这是一个典型的多学科、跨尺度的问题，既涉及气象与大气光学的物理机制，也涉及计算机视觉、机器学习与时间序列预测方法的工程实现。把问题放到宏观背景来看，模型的主要目标可以被分为三层：第一层是解释性建模，建立能见度（MOR/RVR）与近地面气象量（温度、相对湿度、露点、风速/风向、气压等）之间的物理/统计关系，以便理解雾的形成条件与消散驱动因子；第二层是观测替代或增强，即基于视频图像建立能见度估计器（使用同步的能见度观测作为标签）以在没有或缺失激光能见度仪时替代或补充观测；第三层是短时序预测，利用气象时间序列与/或从视频连续帧提取的动态信息预测雾的演化趋势和何时达到某阈值（例如 MOR=150m）。这些目标互相影响：第一层的物理理解可用于约束第二层的机器学习模型（物理启发或先验），第二层提供更高时空分辨率的能见度估计，第三层则依赖于前两层输出和气象演变规律做出可靠预报。解决路径因此应是物理—统计—数据驱动的混合策略，既要尊重光学散射与Koschmieder定律等先验知识，又要充分利用视频的时间连续性与深度学习的表征能力来补偿直接测量的不足。\n\n在建模前必须明确并批判性审视显性与隐性的假设，因为这些前提直接决定模型可解释性和推广性。常见的隐含假设包括：大气在观测区域内是横向均匀的（单一衰减系数σ可代表整条视线）；目标与背景亮度为稳定的固有亮度（忽略或可校正相机自动白平衡与增益）；相机与光源位置已知或固定，且相机未被污损；视频帧时间戳与地面气象观测能精确对齐；雾的主要影响是光学衰减（吸收/散射），而非显著改变目标的几何外观或移动行为。现实中这些假设经常被破坏：团雾导致空间非均匀性；白天与夜间光照与自动曝光差异很大；摄像头污点、透镜水珠或变焦会破坏亮度—距离关系；地面气象站的代表性可能不足以代表摄像头前方的微气候。这些偏差会导致基于全局单一σ或简单回归的模型偏差，推广到其它地点或不同季节时性能显著下降。因而模型设计必须包含稳健的预处理（对曝光与白平衡的归一化、雾前场景基线估计、坏帧与遮挡检测）、局地化校准步骤（利用地面标识物如车道线、标志牌、灯塔或灯光作为参考亮度/距离标定），并在不确定性估计上给予充分表述（置信区间或概率预报）。\n\n具体元素之间的关系既有比较直接的物理关联也有高度交叉的统计依赖。气象变量与能见度的关系受微物理过程控制：露点温度接近地温、相对湿度接近100%时最有可能形成雾；温度逆温层与弱风（低摩擦风速）有利于雾的形成与滞留；而随时间升温、太阳辐射增加或风增强、边界层湍动增加会促使雾的消散。因此在第一个任务中，应同时考虑非线性与阈值效应，使用物理启发的特征（露点差 ΔT = 温度 − 露点、夜间/白天二值、风速阈值交互项）并采用灵活的统计模型（广义可加模型 GAM、分段回归、或者包含阈值/门控结构的随机森林/梯度提升机）来捕捉这些关系。由于能见度在大多数晴好时段非常高且不敏感，而在雾事件期间的低值最关键，损失函数或评估指标应对低能见度区间加权以避免被大量高能见度样本主导拟合。数据清洗与时序对齐极为重要：AMOS 文件中的MOR_1A为1分钟平均，需要与视频帧时间戳进行插值/对齐，且要剔除仪器故障或异常值（例如忽然跳变的MOR或灯光记录异常）。\n\n视频驱动的估计（任务二与三）要同时处理光学规律与视觉特征提取问题。Koschmieder定律给出了亮度随距离的指数衰减和背景散射的形式，这可以作为物理层面的约束：若能从图像中识别出某一目标物在无雾条件下的固有亮度 B0（或通过晴好日的图像建库），则可以通过当前观测亮度与背景亮度来估计衰减系数σ并推导MOR。现实中直接获得 B0 很难，因而可采用学习方式：利用同步的地面MOR作为标签训练深度网络，将图像（或其对比、颜色衰减、亮度梯度、边缘锐度、频谱能量、雾边界检测等）映射到能见度。推荐的模型架构是融合空间与时间信息的端到端网络，例如以卷积骨干（ResNet、EfficientNet）提取帧级特征，再通过时序模块（ConvLSTM、Temporal convolution、或Transformer）结合光流/动态信息以利用雾演化的连续性。为提升物理一致性与泛化能力，可采用多任务学习：同时预测能见度、估计场景深度（或相对深度排序）、并重建“去雾”图像；在损失中加入Koschmieder型的物理正则项或亮度一致性约束。训练数据不足时，应使用合成雾（基于晴日图像用已知σ和Koschmieder模型生成雾化图像）和迁移学习（预训练在大规模城市雾数据集）来扩充样本并校正曝光差异。评估时应采用多重指标：MAE/RMSE、偏差（bias）、相对误差在低能见度段（例如MOR<1000m）的表现，以及对判决性阈值（如是否小于400m/600m/150m）的分类性性能（ROC、POD、FAR），并用严格的时间序列交叉验证（按时间段留出而非随机留出）以避免信息泄露。\n\n在第三项“无仪器仅视频”情景下，关键技术点是如何从单目视频中恢复与距离相关的可度量量。若能获得摄像头的内外参和道路几何（如摄像头高度、俯仰角、车道宽度、路标尺寸、远近车位置），则可以通过透视几何把像素位置映射到实际距离，从而把像素级亮度或对比随距变化拟合为衰减曲线并估算σ与MOR。若没有精确标定，可使用深度学习的单目深度估计或利用语义检测（识别车辆、路灯、标志）并假设这些目标的物理尺寸或高度进行距离估计（基于垂直像素位置与透视关系的经验公式）。另一类方法利用场景中已知亮度特征：例如夜间路灯或车灯的点源强度应随着距离按反向平方规律及大气衰减衰减，通过检测特定灯源的光晕或对比来估计σ。Nayar/Narasimhan、Tan 等文献提供了基于单图的能见度推断（亮度对比、颜色衰减模型、暗通道等），这些方法可以与车辆检测、车道投影和图像序列的时间演化联合使用以提高鲁棒性。实现时还要对摄像头自动增益/曝光与光照变化进行补偿，可采用参考区域（天空、路面均值）做归一化，或从图像元数据中读取曝光参数并在物理亮度尺度上校正。\n\n第四项关于预测雾的演化及达到给定能见度阈值的问题本质上是短期时间序列预测与生存分析的组合。简单基线是 persistence 模型（能见度保持现状）、线性/非线性回归与ARIMA、或用LSTM/Transformer直接序列预测能见度曲线；更有力的方法是构建状态空间模型或隐马尔可夫模型，其中隐状态代表边界层稳定/逆温/雾层厚度等特征，观测为能见度与气象变量，状态转移由近地气象驱动并允许风速或辐射突变导致状态改变。在实务中，预测何时能见度降到或升过某阈值可用生存分析或危害函数建模：以历史事件为样本，预测“达到阈值”的时间分布，或计算在给定当前条件下“完全散去”的概率时间分布。物理上有明确驱动变量提供强预测能力：若露点差持续增大、地面辐射迅速上升、风速显著增强，雾散去的概率很大；可以把这些作为协变量进入回归乃至生存模型。为了给出不确定性评估，应采用集合方法（ensemble forecasts）、贝叶斯时间序列或蒙特卡洛仿真，从而给出概率预报与置信区间，而不是单一确定的时间点估计。\n\n在整个建模过程中需注意多重不确定性来源与潜在风险：观测代表性偏差（地面站不在摄像头前方）、标签噪声（RVR/MOR 与视觉定义可能不一致）、相机自适应参数与污染物影响、样本不均衡（晴天样本过多）以及时序相关性导致的过拟合。应采用稳健的训练—验证分割（按时间块留出、不同月份/季节留出）来测试泛化；使用物理约束和先验对模型输出进行校正；并在模型部署时做持续在线校准与性能监控，以便随着新的事件不断更新模型。最后，建模是一个迭代过程：初始模型应以可解释性和稳健性为优先，逐步引入更复杂的深度学习组件与更精细的物理耦合；在每一步都需要回到数据与物理事实检验假设，调整损失函数以重视关键低能见度情形，并为最终的预警系统提供概率化、可解释的输出与不确定性度量，以服务交通与航空安全这一最终应用目标。",
  "modeling_solution": "下面给出一个综合性的、可实施的数学建模方案，融合物理大气光学、统计/回归建模、深度学习的端到端视觉估计方法以及时序动力学预测（确定性与随机）三大模块，并针对题中数据（AMOS 观测与视频帧）给出明确的变量定义、数学关系、估计/训练方案、求解策略与验证流程，兼顾解释性、可实现性与鲁棒性。为便于表达，先列出主要符号与含义（在后文公式中反复使用）： MOR(t) 为气象能见度（meteorological optical range，单位 m）或 RVR（跑道视程）； I(x,t) 为某时刻 t 在图像像素位置 x 的观测亮度（或灰度）； J(x) 为目标物在无雾时的固有亮度分布； A(t) 为大气背景光照（大气光/散射亮度）； t(x,t) 为透射率（transmittance），常写为 t(x,t)=exp(−β(t) d(x))，其中 β(t)≥0 为时变的光学衰减系数（extinction coefficient，单位 m−1），d(x) 为像素 x 对应的物理距离（m）；按照 Koschmieder 模型，图像成像模型为 I(x,t)=J(x) t(x,t)+A(t) (1−t(x,t)). 另外定义若干气象量： T(t) 地面温度（℃）， RH(t) 相对湿度（%）， TD(t) 露点（℃）， ΔT(t)=T(t)−TD(t)（露点差，℃）， WS(t) 风速（m/s）， WD(t) 风向（°或正弦/余弦分量）， P(t) 气压（hPa）， S(t) 表示太阳辐射/时段二值（白天/夜间），以及可能的边界层稳定度指标 SBL(t)。最终目标是估计并预测 MOR(t)（或 β(t)），并给出不确定性和事件（例如 MOR≤150m 或 MOR≤400m）发生时间的概率或时间点估计。\n\n模型基本假设（为保证可估并有现实意义所做的合理简化）\n假设在观测的视域尺度上大气横向均匀、在短时间尺度内（例如几分钟）衰减系数 β(t) 可视为空间上统一但随时间变化（若存在团雾或明显空间非均匀性，则应分段建模或对图像做空间分区）；相机几何位姿（内外参）在同一摄像头序列中为固定或可知（若未知，则通过道路标记或语义物体做近似标定）；相机自动增益/曝光变化可以被检测并通过图像预处理或利用元数据校正；能见度观测（AMOS 中 MOR_1A）为地面站代表该摄像头前方数百米到数公里的平均值，并可作为监督信号进行回归训练（注意标签存在噪声与偏差）；Koschmieder 模型作为图像亮度-距离的基础物理关系是有效的近似，尤其在均匀雾层下；雾的形成与消散主要由近地面气象变量驱动（露点差、风速、辐射/日照、边界层演变），可用统计或动力学方程刻画。\n\n一、能见度与地面气象变量的半物理统计模型（用于解释性分析与基线预测）\n基于物理直觉，能见度（或 β）与露点差 ΔT、风速 WS、日夜状态 S、边界层稳定度 SBL 以及前一时刻能见度存在强关联。构建模型的两个等价表示：（1）直接对 MOR 建模；（2）对光学衰减系数 β 建模并通过 Koschmieder 关系转换为 MOR。采用第二种建模更符合光学物理：β(t)≈−ln(0.05)/MOR(t)。因此我们建立 β(t)=g(X(t))+ε(t)，其中 X(t) 为气象特征向量 [ΔT(t), WS(t), sin(WD(t)), cos(WD(t)), P(t), S(t), past MOR/lags, …]，g(·) 为可解释的半参数函数。建议使用广义可加模型（Generalized Additive Model, GAM）或分段回归与门控结构来捕捉非线性与阈值行为，具体形式为\nβ(t)=α0 + f1(ΔT(t)) + f2(WS(t)) + f3(S(t)) + f4(ΔT(t))·I(WS(t)<w0) + f5(tod(t)) + ε(t),\n其中 fi(·) 为平滑函数（样条），I(·) 为指示函数捕捉风弱条件下的交互项，tod(t) 为时刻角度（捕获昼夜差）。对于模型训练，可先对 β 标签做对数变换以稳定方差，即 y(t)=log β(t)，建模 y(t)=h(X(t))+ε. 为了更好地拟合雾期低能见度情形，应在损失中对低 MOR（高 β）样本加权或直接优化加权 MAE。若观测表明存在两类状态（无雾/有雾），可用混合模型或门控（regime switching）模型：先用一个二元分类器 p_fog(t)=Pr{fog at t}，当 p_fog 小于阈值时使用 persistence/高平稳值预测，否则使用上式深度拟合。\n\n参数估计与模型选择策略：对 AMOS 数据先做严格的数据清洗（剔除缺失、仪器异常、夜间灯光异常的大幅跳变），将 MOR 平滑并对齐到气象采样时间；使用逐步回归、交叉验证（按时间块留出以避免信息泄露）和 AIC/BIC/GCV 选择平滑度与变量集合；检验残差时间序列自相关并考虑加入自回归项 ε(t)=ρ ε(t−1)+η(t) 或用状态空间方法扩展。模型的输出通过 β→MOR 转换：MOR(t)=−ln(0.05)/β(t)。评估指标建议用 MAE、RMSE 以及对关键阈值（例如≤400m、≤800m、≤150m）分类的召回率/误报率等，重点考察低能见度区间性能。\n\n二、基于视频与同步气象观测的端到端深度学习估计模型（利用 AMOS+视频 做监督）\n目标：构建一个能够从视频帧序列直接估计 MOR(t) 的深度网络，利用时序信息提高稳定性并输出不确定度。整体结构采用“空间骨干网络 + 时序聚合器 + 多任务头”的设计：空间骨干可以用 ResNet/EfficientNet（预训练在 ImageNet）或轻量级 MobileNet（若部署受限）提取帧级视觉特征 F(x,t)。时序聚合器可选 ConvLSTM（保留空间信息）或 temporal transformer/TCN（效率高、长程依赖好）。网络同时输出三个任务：预测 β̂(t)（或 MOR̂）、估计场景相对深度 d̂(x,t)（或单通道深度图），以及重建无雾图像 Ĵ(x,t)（用于监督物理一致性）。多任务损失为 L = λ1 Lβ + λ2 Ldepth + λ3 Lrec + λ4 Lphys + λ5 Luncrt，其中 Lβ 为能见度标签回归损失（建议使用对低 MOR 加权的 MAE 或 Huber 损失）； Ldepth 可用监督深度（若有标注）或自监督 (monodepth) 损失； Lrec 为重建（去雾）图像的感知损失（LPIPS/SSIM + L1）； Lphys 是物理一致性损失，将网络推断出的 β̂ 与由 Ĵ、Â、d̂ 通过 Koschmieder 模型生成的 Î 比较：例如 Lphys = E_x || I(x,t) − (Ĵ(x,t) e^{−β̂ d̂(x,t)} − Â(1−e^{−β̂ d̂(x,t)}))||^2（注意符号对应），强制网络输出在物理上自洽。Luncrt 为不确定度估计损失，可通过负对数似然（假设预测带方差）来训练网络同时输出均值与方差。训练策略：先用大量晴天/合成雾数据做预训练：从晴图像用已知 β 合成雾图（按 I=J e^{−β d}+A(1−e^{−β d})）扩充训练集并监督深度估计与去雾重建；然后在真实 AMOS 标注数据上微调。数据对齐：用 AMOS 的时间戳把每分钟 MOR 与对应视频帧（或该分钟帧集的平均/中位）对齐；若 AMOS 记录有一分钟平均而视频帧率高，聚合多帧标签以减少噪声。为提升泛化，应对图像做曝光/增益/白平衡随机化、色温扰动与合成不同类型雾/霾的色散特性。\n\n评估：采用时间序列交叉验证（例如按月份或事件留出），评价 MAE、RMSE、相对误差，并在低能见度段单独评估。此外计算阈值分类指标（<=150、<=400、<=800m）。为了量化模型不确定性，可用 MC Dropout、贝叶斯后验或训练集合模型（ensembles）获得置信区间。最终模型输出 β̂(t) 或 MOR̂(t) 与其置信区间，并可将去雾图像 Ĵ 给出以供人工验证。\n\n三、仅有视频、没有能见度仪观测时的能见度估计算法（适用于高速公路视频）\n核心思路是用图像中不同景深处物体的亮度/对比度随距离的衰减来估计 β。实现分为三步：距离推断、亮度/对比度测量与指数拟合、聚合与置信度校正。距离推断可以采用一种或多种方法：若摄像头内外参已知或可通过道路标记（车道线、路肩、隔离栏、标牌）估算单应或投影参数，则通过几何透视模型将像素行坐标 y 映射为实际距离 d ≈ a / (y − y0) + b（经验透视方程）并通过少量物理尺寸已知的对象（例如车牌高度、路标高度、车道宽）做标定。若无几何信息，则采用单目深度估计网络（MiDaS、DPT 等）得到相对深度排序并把其尺度通过已知对象（车辆或标牌）进行标定。第二步在多个已知或估计距离的区域上计算观察到的亮度或对比度指标 C(d)=|Bbg(d)−Bobj(d)|/max(Bbg,Bobj)（即题中对比度 K 的图像替代）或局部对比、边缘能量（高频能量随距离衰减），并建立指数衰减模型 C(d)=C0(d) e^{−β d} + C∞(1−e^{−β d})（其中 C0(d) 表示无雾下基线对比，C∞ 为远处投射背景对比）。在实际中直接得到 C0(d) 很困难，因此可采用比值法：给定两处不同距离 d1<d2 的同一类对象（如车辆尾灯、路牌），其观测对比比值 R = C(d2)/C(d1) ≈ exp(−β (d2−d1)), 从而 β ≈ −ln R / (d2−d1). 通过对多个对象/时间帧取样并用加权最小二乘拟合 β 得到稳健估计。夜间可使用点光源（车灯/路灯）的亮度或光晕半径随距离的变化做拟合（点光源强度按逆平方和大气指数衰减结合），对 β 的估计更清晰。第三步对时间序列中的 βˆ 做平滑并用物理/统计滤波（卡尔曼或低通滤波）去噪，最终转换为 MORˆ=−ln(0.05)/βˆ。 为了在没有已知对象尺度的情况增强鲁棒性，可以把方法与单目深度网络联合：用网络估计相对深度 d̂(x) 并在时间序列中用同一语义类（车、标志）跨帧比较亮度，消除对象亮度差异的影响。最终输出应包含不确定度（例如拟合标准差）并在输出中标记当场景不满足均匀雾层假设或对象数目太少导致估计不可信时触发“不可用”或低置信度提示。\n\n对题中给定的“高速公路视频截图”实现流程建议：先从第一帧做摄像头标定（检测车道线与透视消失点，估计 y→distance 经验式），使用语义分割（road, vehicle, sign）定位可用于估计的对象，计算各对象或区块的亮度/对比度随时间并拟合 β，生成每帧或每分钟的 MOR 曲线；用滑动窗口平滑并报告置信区间。若需要更准确距离，可通过外部测距标志或人工测量校准第一批帧。\n\n四、雾的时间演化建模与能见度到特定阈值时间的预测\n把雾的演化视为衰减系数 β(t) 的动力学过程，并用受气象驱动的状态空间模型或 SDE 描述。两个互补模型：确定性近似与随机动力学。确定性 ODE 形式可写为 dβ/dt = F(β, M(t)) = −κ1 U(t) β + κ2 H(RH(t), ΔT(t)) − κ3 R(t) + ξ(t)，其中 U(t) 表示混合层湍动或风速对吹散的效应，H(·) 为与湿度和露点差相关的雾生成项（当 ΔT→0 且 RH→100% 时大），R(t) 为太阳辐射/地面升温导致的消散项，κi 为经验参数，ξ(t) 小幅噪声项。更规范的随机性描述为 Ornstein-Uhlenbeck 型 SDE： dβ(t) = −α[β(t) − β_eq(M(t))] dt + σ dW(t), 其中 β_eq(M(t)) 为气象驱动下的平衡衰减系数（可用上文的半物理统计模型估计），α 为回复速率，σ 为扩散项。SDE 的参数可通过最大似然（离散化）或卡尔曼滤波/EM 方法估计。给定当前 β(t0) 与未来气象情景（观测或短期数值预报），可对 β 的未来分布进行蒙特卡洛模拟或解析近似求解，进而得到 MOR(t) 分布并估计达到阈值（例如 MOR≤150m）的时间分布或置信区间。若仅需估计“何时散去（MOR达到某阈值 M*）”可以在确定性近似下解常微分方程或在 SDE 下计算 hitting time 的分布（数值蒙特卡洛最为稳妥）：对若干样本路径模拟 β(t) 并记录首次 t_hit 满足 MOR(t_hit)≥M* 的时间，得到分布与置信区间。若使用状态空间模型，可用扩展/无迹卡尔曼滤波器与在线参数自适应以连续校准模型并输出实时报表。\n\n五、求解策略、参数估计与数值实现细节\n对半物理统计模型（GAM、混合模型）可使用标准回归库（R 的 mgcv、Python 的 pyGAM 或 sklearn 的 GradientBoosting/LightGBM 做近似）完成参数估计；对时间自相关残差加入 AR(1) 或用状态空间（Kalman）求解并用 MLE/EM 估计参数。对深度学习模型需要 GPU（推荐至少一台带 16GB 显存的 GPU，如 NVIDIA V100/A100 或者 2080Ti 若预算受限），训练数据量若在几千到上万帧，通常数小时到数天训练时间（依模型规模）；可用 Adam 优化器、学习率调度、早停和数据增强。物理损失 Lphys 计算需对 d̂(x) 进行尺度标定；若没有深度标签，使用合成雾做预训练并利用单目深度自监督方法。对于视频仅法的 β 拟合，采取加权最小二乘拟合（权重与对象检测置信度、亮度稳定性相关），以及卡尔曼滤波或鲁棒平滑（如 Huber）用于时间序列去噪。SDE 的拟合可用最大似然或贝叶斯 MCMC（若需要置信区间），预测用蒙特卡洛路径采样并并行计算以提高效率。模型复杂度的降维策略包括：在深度网络中用轻量骨干、用 PCA/UMAP 压缩中间时空特征用于时间模型输入、或训练小型代理模型（surrogate）用于实时预测。对于跨地点推广，建议对每台摄像头训练一个小型本地点校准器（线性校正）以补偿摄像头间差异。\n\n六、验证、敏感性分析与不确定度量化\n对所有模型采用按事件/时间分块的交叉验证（避免随机时间切分），并在不同季节、昼夜和不同风速条件下检验模型的稳健性。评估指标建议包括：MAE、RMSE、偏差（Bias）、相对误差分位数、阈值分类的 POD（概率检出率）、FAR（误报率）和 AUC。敏感性分析可用局部灵敏度（对参数小扰动的响应）与全局灵敏度（Sobol 指数）相结合：对半物理模型逐一扰动气象因子（ΔT、WS、S）查看 MOR 变化；对深度模型用特征归因方法（SHAP、Integrated Gradients）评估输入图像或帧序列对输出的贡献。不确定性量化可通过模型集合、贝叶斯后验或蒙特卡洛模拟给出输出分布与置信区间，并在产品中输出置信分数来告知用户。\n\n七、现实问题、风险与补救措施\n摄像头自动曝光/白平衡会强烈影响亮度基线，需优先做曝光补偿或使用原始像素/相机元数据。团雾或空间非均匀雾层会破坏全局单一 β 假设，在这种情况下应分区域估计 β 并输出区域化的 MOR。夜间或强侧光场景需要不同的特征集（点光源亮度、光晕半径、高频能量）与不同的训练集。标签噪声（地面 MOR 与摄像头视域不完全重叠）会降低监督学习性能，可通过对齐校正、用更多站点做一致性检查或采用半监督/弱监督学习减少影响。部署时应实现在线自校准：利用少量人工标注或与邻近站点的相对观测做周期性校准。\n\n八、扩展与改进路径\n长期可将模型扩展为多站点联合学习框架，采用迁移学习与域自适应减少每台摄像头的标注需求；引入云/微物理模型（结合辐射和边界层演变）进一步约束 β 的动力学；把深度学习模型改造成自监督或对比学习框架以利用大量无标签视频数据；在预测层面结合数值天气预报短期预报（0–6小时）输入使得预测更有前瞻性；在输出中加入决策支持（例如对航班或道路是否封闭建议、置信度与成本权衡）帮助实际应用。若需要更严谨的不确定性控制，可用贝叶斯深度学习或概率状态空间模型给出后验分布并驱动风险管理。\n\n九、针对题中数据（AMOS20191216、AMOS20200313 与提供的视频数据）的具体实施步骤\n第一步，数据预处理：解析 .his 文件并将 MOR_1A、RVR、温度、露点、相对湿度、风速/风向、气压等字段按时间排序并去掉异常；将视频帧时间戳与 AMOS 时间对齐，若帧率高可以每分钟内的中位帧作为标签；对图像进行曝光/色温归一化、去除有明显遮挡或雨滴的帧。第二步，建立气象—β GAM 基线：把 MOR 转换为 β 并用 ΔT、WS、WD 分量、日夜指示、历史 β 的滞后项建立 GAM 或 LightGBM，做解释性变量重要性分析并提供基线预测。第三步，训练基于视频的深度模型：用晴天图像合成雾增强数据并预训练空间骨干与深度分支，然后用 AMOS 标签微调整体网络，加入 Lphys 强化物理一致性，采用按时间切分的验证集评估性能。第四步，仅视频估计实现：用图像处理与语义检测获取可测量对象/区域，估计距离-亮度对并拟合 β 曲线，输出 MOR 及置信度，会为高速公路截图段生成能见度随时间变化曲线。第五步，时间演化与预测：对 β 的时间序列用 SDE 或状态空间模型拟合参数，利用未来气象驱动进行蒙特卡洛模拟得到 MOR 的未来分布并推断首次达到阈值时间。第六步，评估与部署：对所有模型进行事件级评估、敏感性分析并输出可解释的诊断（例如当 ΔT 小于阈值且 WS 低则易形成雾），结合实地专家意见调整阈值策略。\n\n总结性陈述：该综合方案在物理律（Koschmieder 成像模型）与数据驱动学习之间寻找平衡，既能用地面气象观测建立解释性且可推广的关系式，也能通过深度网络充分利用视频的时空信息进行高精度估计，并为没有能见度仪的场景提出基于景深与亮度衰减的可行算法。预测模块把 β 的动力学建模为受气象驱动的确定性/随机过程，从而能给出置信的“何时散去”估计。实施时应高度重视数据对齐、曝光/白平衡补偿、空间非均匀性与标签噪声，并采用分层验证和不确定性量化确保模型在关键低能见度场景下的可靠性与可解释性。随着更多站点数据与视频积累，可逐步引入更强的贝叶斯推断、在线自适应与多站点联合建模以提高泛化能力。",
  "task_descriptions": [
    "子任务1的目标是从题目提供的 AMOS 原始观测文件（例如 AMOS20191216、AMOS20200313 中的 .his 文件）中逐步产出可供建模的、具有物理含义的能见度目标变量与一组经过严格工程化的近地面气象特征，并以半物理可解释的统计模型形式给出能见度与地面气象要素的定量关系式；为此需要按下列有序步骤实现：一是数据读取与单位统一——解析所有 .his 字段（MOR_1A、RVR_1A、TEMP、DEWPOINT、RH、WS2A/WD2A、垂直风、气压 PAINS/HPA、LIGHT_S、CREATEDATE/LOCALDATE、SITE 等），将温度/压力/风速等单位统一并转换为数值型时间序列，记录并保留原始元数据；二是时间对齐与重采样——将各变量重采样到统一时间分辨率（建议 1 分钟，与 MOR_1A 的时间尺度一致），处理时区/夏令时与时钟偏差，若存在多站点则明确代表性站点并记录空间偏差；三是质量控制与异常处理——依据物理边界（例如 RH∈[0,100]%、TEMP 在合理区间内、负值或极大突变的 MOR/风速视为异常）、仪器标志（如 LIGHT_S、站点状态）与统计方法（滑动中位数滤波、 MAD 检测、基于局部窗口的突变剔除）剔除或标注坏值，对短期缺失用线性/样条插值或卡尔曼平滑填补、对长缺失段标记为不可用；四是目标变量变换——将观测能见度 MOR 转换为光学衰减系数 β = −ln(0.05)/MOR，并对 β 取对数 y = log(β) 以稳定方差并更好满足回归假设，同时保留原始 MOR 以便阈值分类分析；五是物理启发的特征工程——构造露点差 ΔT = TEMP − DEWPOINT、绝对/相对湿度指标、风速 WS 与风向的正弦/余弦分量、气压 P、日夜/太阳辐射指示（小时/日照因子）、季节/日序特征（day-of-year、hour-of-day 的周期编码）、垂直风/湍动代理与历史滞后项（y 的 1,5,10,30,60 分钟滞后及移动平均、差分和变化率），并构造交互项（如 ΔT·I(WS<w0)）与二元“雾/非雾”指示以支持门控或混合模型；六是平滑与去噪处理——对气象量和目标变量在建模前用低通滤波或局部回归（LOESS）去除高频噪声但保留关键瞬变用于滞后特征；七是基线建模策略与估计——以半物理可解释为主的回归框架，首选对 y = log β 建立广义可加模型（GAM，使用样条平滑函数捕捉非线性效应）并在必要时引入自回归残差项（AR(1)）或状态空间扩展以吸收时间相关性；若需要非参数对比，可并行训练 LightGBM/随机森林作为基线并比较性能；建模时对低能见度（高 β）样本加权（如权重与 1/MOR 或基于分位的权重）以避免晴好样本主导拟合；八是模型选择、正则与验证——用 GCV/AIC/BIC 选取样条平滑度和变量子集，用时间分块交叉验证（按日、按事件或按月份留出，禁止随机时点抽样）评估泛化并用网格或贝叶斯优化调整超参；九是诊断与不确定度估计——检验残差自相关（ACF/PACF）、异方差（Breusch–Pagan）、偏离正态性的影响并在必要时采用稳健回归或方差建模（GARCH/异方差项）；通过残差引导的自助法（bootstrap）、GAM 的置信带或模型集合构造预测区间并输出变量的部分效应曲线、显著性与相对重要性（可用 SHAP 作补充）；十是输出物与可复现性要求——最终产出应包含（1）明确的数学关系式（例如 y = α0 + s1(ΔT) + s2(WS) + s3(hour) + α4·sinWD + ...，并给出各平滑函数的估计曲线与置信区间），或当使用树模型时提供近似解析表达（主导变量规则/分段回归表示）；（2）性能评价指标表（MAE/RMSE 于整体与低能见度子域、分类指标如 POD/FAR 对关键阈值）；（3）数据清洗与特征工程脚本、模型训练脚本与随机种子、以及用到的主要工具建议（Python：pandas、numpy、scipy、statsmodels、pyGAM、scikit-learn、lightgbm；或 R：data.table、mgcv、forecast），并记录模型假设与局限以便后续审查。该子任务的成功判据是可复现地从原始 AMOS 数据得到经物理变换的目标变量、一个经过验证的、可解释的回归关系（含显著自变量和非线性效应）以及可靠的误差/置信区间，以供后续建模或决策使用。",
    "子任务2的目标是在给定机场视频序列与同步地面能见度观测（如 AMOS 数据集中的 MOR_1A/RVR 时间序列）作为监督标签的条件下，设计、训练与验证一个端到端的基于深度学习的能见度估计器，该估计器以视频帧序列为输入、输出时间同步的能见度估计值（MOR 或等价的衰减系数 β）及其不确定度，并可选同时输出场景相对深度图与“去雾”重建图以增强物理一致性；该任务的范围包括（1）输入数据处理：读取并对齐视频帧时间戳与 AMOS 的分钟级能见度标签，剔除或标注曝光失真、雨滴遮挡、夜昼极端光照等坏帧，做相机曝光/白平衡归一化及必要的几何裁剪；（2）模型设计：采用“空间骨干 + 时序聚合 + 多任务头”架构，空间骨干可选预训练的 ResNet/EfficientNet（或移动端 MobileNet）、时序聚合采用 ConvLSTM / Temporal Convolutional Network / Transformer（保留空间信息时优先 ConvLSTM），多任务头包含主回归头预测 β̂ 或 MOR̂、辅助头预测相对深度 d̂(x,t) 与去雾图 Ĵ(x,t)，并包含一个输出预测置信度/方差以量化不确定性；（3）物理与损失函数：主损失为对低能见度加权的回归损失（加权 MAE 或 Huber），辅以深度自监督/监督损失（若用 MiDaS 等外部深度估计做伪标签）、重建/感知损失（L1/SSIM/感知损失）以及物理一致性损失 Lphys，后者基于 Koschmieder 成像模型 I ≈ J e^{−β d} + A(1−e^{−β d}) 强制网络输出在亮度—距离域自洽（A 可由网络估计或通过亮暗远近像素统计初始化）；同时可采用负对数似然或 heteroscedastic loss、MC Dropout 或模型集成来训练/估计不确定度；（4）训练策略与数据增强：先用晴日图像与合成雾（用已知 β 与深度图合成）进行预训练以建立亮度—距离先验，再用真实 AMOS 标签微调，数据增强包含曝光/增益/色温扰动、色彩随机化、仿真不同雾色散与噪声，以提高鲁棒性；（5）数据切分与评估：用按时间块/事件留出的验证与测试集避免时序泄露，评估指标包括 MAE/RMSE、低能见度子域（如 MOR<1000m）的相对误差、阈值分类指标（POD/FAR/AUC 对 150/400/800m）、置信区间覆盖率与校准图；（6）实现细节与算力建议：推荐使用 PyTorch 或 TensorFlow，利用预训练权重、混合精度训练与 Adam 优化器，训练与推理在具备 ≥16GB GPU 的环境上进行，导出可用于实时/近实时推断的轻量化模型（剪枝/量化或用 MobileNet 骨干）与推理流程；（7）对标签噪声与现实偏差的处理：在损失中对 MOR 标签噪声加权或用稳健回归（Huber）、并在训练中引入场景/时段掩码（夜间/日间、灯光异常），记录模型在不同光照、摄像机曝光与镜头污迹条件下的失效警告逻辑。最终交付物为可复现的训练代码与配置、经过时间分块验证的模型权重、按帧或按分钟输出的 MOR̂ 与不确定度置信区间、以及用于人工审查的深度图與去雾图像以便检验物理合理性。",
    "子任务 3 — 仅基于视频的能见度估计算法（独立说明）：目标是设计并实现一个可操作的、仅依赖单目监控视频（无地面能见度仪标签）就能在帧级或分钟级输出道路段能见度（MOR）估计及其置信度的端到端流程；该流程假定摄像头位置固定且视域内雾层在短时间尺度上近似横向均匀，输入为连续视频帧序列与可选的摄像头元数据（内参、曝光/增益/快门时间、时间戳）以及可选的道路几何信息（车道线、路标物理尺寸或标定点），输出为时序化的 MOR(t)（或衰减系数 β(t)）及每时刻的不确定度/诊断标志。实现步骤与方法（逐步、可复现）：1) 预处理：读取帧并用摄像头元数据或图像统计对每帧做曝光/白平衡和伽玛归一化，剔除严重运动模糊、直射阳光或雨滴遮挡的帧（基于图像熵、饱和像素比和光流突变检测）；2) 语义筛选与参照对象提取：用语义分割/目标检测（例如 pretrained Detectron2、YOLOv5 或语义模型）标识并跟踪可作为距离与亮度参照的语义类（车辆、路牌、路灯、车道线、护栏等），并记录每个检测的置信度与像素包围盒/位置信息；3) 距离映射（像素→距）：若有相机内外参或已知道路标定点，则用透视几何或单平面单应求出像素行坐标到物理距离的函数 d(y)（经验形式可取 d = a/(y−y0)+b 或多项式），若无则用单目深度估计器（如 MiDaS/DPT）得到相对深度图并通过少量已知尺寸对象（或假定车辆宽度/牌高）做尺度标定；4) 亮度/对比特征计算：在每个候选对象或固定景深区间上计算稳定的光学量作为可见性指标，例如局部亮度 Bobj 与背景亮度 Bbg 的对比 K = |Bbg−Bobj|/max(Bbg,Bobj)，或边缘能量/高频谱能量、暗通道值或点光源（夜间路灯/车灯）半径与峰值强度；5) 指数衰减拟合以估计 β：利用同一时间帧或短时间窗口内多个不同距离处的同类目标测得的对比值构造比值关系 R = K(d2)/K(d1) ≈ exp(−β (d2−d1))，由此得 β̂ = −ln R /(d2−d1)；更一般地，用所有采样点对以加权最小二乘拟合对数模型 ln K(d) = ln K0 − β d + ε，估计截距 ln K0 与 β（K0 为无雾基线对比，可作为隐变量或通过晴时基线/历史数据初始化）；夜间点光源可改用 Iobs(d) ≈ I0 /(d^2) · exp(−β d)（或在对数域拟合得到 β）；6) 统计稳健化与时间平滑：对每帧/每分钟得到的多个 β̂ 值按检测置信度、对象面积和对比稳定性加权聚合，并用鲁棒估计（Huber 回归）或卡尔曼滤波/指数加权移动平均平滑时间序列以抑制测量噪声与短期遮挡；7) MOR 计算与不确定度量化：将 β̂ 转换为能见度 MOR̂ = −ln(0.05)/β̂，并通过拟合残差、样本数、检测置信度及时间序列方差合成不确定度估计（例如用拟合标准误差与时间平滑的不确定传播）；8) 置信判断与异常标识：当可用参照对象数低于阈值、图像曝光饱和、深度标定不可靠或场景出现强空间非均匀雾（检测到前后景差异或对比在空间上非一致）时输出“低置信/不可用”标志；9) 验证与轻量标定步骤：在实际部署前建议进行一次人工或半自动标定（用若干帧中已知距离的标志物或人工测距点校准 d(y) 与/或校准 K0），并提供自动日志记录以便后续离线校验；10) 实现工具与接口：推荐使用 OpenCV（图像处理与透视校正）、PyTorch/TensorFlow（单目深度模型与检测器）、Detectron2/YOLO（目标检测）、NumPy/SciPy/statsmodels（统计拟合与滤波），并输出 CSV/JSON 格式的时间序列（时间戳、MOR̂、β̂、置信区间、可用参照计数及诊断码）。关键假设与限制要在实现中显性检查：摄像头固定、雾层在视域近似均匀、参照对象在亮度上随时间内可视为同类或通过聚合消除差异；算法需在昼夜条件下分别调整对比度度量（白天以对比/边缘为主，夜间以点光源强度与光晕为主）。最终产出为按帧或按分钟的 MOR 时间序列、每时刻的置信区间与诊断标志，以及可复现的代码模块（预处理、检测与跟踪、距离校准、β 拟合、时序滤波、不确定度输出），可立即用于生成高速公路路段在给定视频时间段内的能见度随时间变化曲线。",
    "子任务 4（雾演化动力学建模、短期概率预测与“何时散去”时间估计）要求在给定经预处理并对齐的能见度时间序列（可用衰减系数 β(t) 或直接的 MOR(t)）以及同步的近地面气象驱动变量（例如温度、露点/露点差 ΔT、相对湿度、风速与风向分量、气压、辐射/昼夜指示等）和可选的短期气象预报输入下，构建一套既能做实时同化又能给出带不确定度概率预报的数学—统计框架，用以预测未来短时（分钟到数小时）内能见度的演变并估计达到或超过指定阈值（例如 MOR = 150 m）的时间分布；具体工作范围包括：1）数据准备与质量控制——对输入序列做时间戳对齐、异常值检测与短期平滑，明确观测误差模型（观测方差随能见度或采样数变化）；2）模型建构——并行建立（A）确定性/经验动力学形式 dβ/dt = F(β, M(t); θ)（F 可由物理启发的生成/消散项参数化）用于快速点值预测与情景分析，以及（B）随机状态空间或 SDE 模型（例如带驱动项的 Ornstein–Uhlenbeck 形式 dβ = −α[β−β_eq(M(t))]dt + σ dW），其中 β_eq(·) 可由回归/GAM/树模型拟合得到；3）参数估计与同化方法——在历史数据上用最大似然、卡尔曼/扩展/无迹卡尔曼滤波或 EM 算法估计模型参数，必要时采用贝叶斯方法（MCMC／变分推断）得到后验分布，运行时用卡尔曼滤波、Ensemble Kalman 或粒子滤波将实时观测（视频或地面估计）同化进模型以校正状态与不确定度；4）预测与首次到达时间计算——基于估计参数和当前状态，用蒙特卡洛路径模拟（采样模型噪声与若干气象预报情景）并前向积分得到 β(t) 与对应 MOR(t) 的若干样本路径，统计首次满足阈值条件的 hitting-time 分布（含期望、分位数与置信区间），并输出阈值发生概率随时间变化曲线；5）不确定度量化与敏感性分析——报告预测置信区间、事件概率（如在未来 T 小时内 MOR≤150m 的概率）、Brier/CRPS 等校准评分，采用全局（Sobol）或局部灵敏度分析量化驱动变量与参数对到达时间的贡献；6）验证与性能指标——通过时间块交叉验证评估短期预报的 MAE/RMSE、事件预报的检测率/误报率及覆盖率，并用创新序列诊断滤波器一致性；7）在线部署与运维策略——明确同化频率、预测时窗与计算预算，设定在线诊断（如滤波增益、残差自相关或观测创新异常）以触发再校准或模型切换，并提供决策输出（概率化散雾时间、推荐采取措施的置信度与提前量）；以及8）实现与工具建议——建议使用 Python 生态（numpy/scipy、statsmodels、filterpy/pykalman、pymc3/pyro 或 stan、SALib、multiprocessing/numba 加速蒙特卡洛），并在实现文档中明确输入格式、接口、所需计算资源与性能阈值。该子任务的最终交付物应包含：可复现的模型代码与训练/估计脚本、实时同化与蒙特卡洛预测流程、到达阈值的概率时间分布与置信区间、关键性能指标报告及用于在线监控与触发再训练的诊断规则。"
  ]
}