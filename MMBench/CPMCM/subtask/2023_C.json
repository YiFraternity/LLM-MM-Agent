{
  "tasks": [],
  "problem_str": "问题背景：\n现在创新类竞赛很多，其中规模较大的竞赛，一般采用两阶段（网评、现场评审）或三阶段（网评、现场评审和答辩）评审。创新类竞赛的特点是没有标准答案，需要评审专家根据命题人（组）提出的评审框架（建议）独立评审。所以，对同一份作品，不同评委的评分可能存在较大差异。事实上，当竞赛规模大，评委的人数众多时，极差（定义见附件1）大的问题更为突出。显然，简单地依据多位评委评分的总和进行排序并不是创新类竞赛评审的好方案。因此，探讨大规模创新类竞赛评审方案的公正性、公平性和科学性具有深远意义。\n目前，各项创新类竞赛都在摸索、调整自己的评审方案。现有方案包括：\n(1) 对每位评审专家的评分进行标准化（公式见附件1），按作品将标准分相加得每件作品总分，然后依总分排序；\n(2) 去掉同一份作品得分中的最高分、最低分，再将剩余评分相加，最后依总分排序；\n(3) 同一份作品如果专家的评分差异（极差）较大，组织相关专家协商调整，将调整后得分相加，再依总分排序；\n(4) 当竞赛规模很大时，首先利用上述方案（1）或（2）或（3）对作品进行初选，再对初选入围的作品组织专家评审（第二阶段评审）或经过答辩等环节确定获奖名单。\n这些方案都有一定的合理性，但也有局限性。特别是针对大规模创新类竞赛评审，现有方案偏简单，研究不多。\n在大规模创新类竞赛中，增加评审每份作品的专家人数，显然有利于评审工作的公正、公平。然而，由于种种原因，参与评审工作的专家数目是受限的。评审专家少了，评审工作的误差会变大。不过，考虑到大规模创新类竞赛获奖比例通常小于50%，有些误差并不影响是否获奖。因此，在不影响获奖等级的前提下，为了适应评审专家人数较少的现状，不少竞赛采用两阶段评审办法。\n为探索大规模创新类竞赛评审的好方法，附件给出模拟大规模创新类竞赛的数据。其包含两阶段评审，第一阶段由五位专家对作品评审，取标准分后，将五位专家的标准分取均值后排序，按事先约定的比例取排名在前的作品，进入第二阶段评审。第二阶段由三位专家对作品评审，分别取标准分，并对少数极差大作品的标准分进行必要的调整后，再将第一阶段五位专家评审标准分的均值、第二阶段三位专家的评审标准分共4份成绩求和，依最终总成绩再排序。\n\n问题要求：\n请利用这批数据建立数学模型，探讨建立更为合理、公平的评审方案。\n问题一：\n在每个评审阶段，作品通常都是随机分发的，每份作品需要多位评委独立评审。为了增加不同评审专家所给成绩之间的可比性，不同专家评审的作品集合之间应有一些交集。但有的交集大了，则必然有交集小了，则可比性变弱。请针对3000支参赛队和125位评审专家，每份作品由5位专家评审的情况，建立数学模型确定最优的“交叉分发”方案，并讨论该方案的有关指标（自己定义）和实施细节。\n问题二：\n在评审中采用标准分（附件1）为基础的排序方法，其假设是不同评审专家评审的作品集合的学术水平分布相同。但在大规模创新类竞赛评审中，通常任意两位专家评审的作品只有小部分是共同的，绝大多数作品是不同的。(见问题一)，而且每位专家只看到作品集合的很小部分，因此标准分评审方案的假设可能不成立，需要探索新的评审方案。请选择两种或两种以上现有或自己设计的评审方案和题目附件数据，分析每位专家、每份作品原始成绩、调整之后（如取标准分）成绩的分布特点，按不同方案进行排序，并设法比较这些方案的优劣。进而针对大规模创新类竞赛的评审，设计新的标准分（公式）计算模型。另外，一般认为经多位专家协商一致的获奖论文具有最大的可信度，附件 2 提供的数据 1，其第二评审阶段评选出的一等奖作品排序是经专家协商取得一致的，请利用这批数据，改进你们的标准分计算模型。\n问题三：\n“创新类”大赛的特点是“创新性”，即没有标准答案。由于这类竞赛的问题难度较大，一般需要通过创新才能在竞赛期间部分解决。而作品的创新到了什么程度，后续研究的前景如何，很难有一致看法，即使专家面对面的交流，都可能由于各持己见而无法统一。加上研究生的论文表达不到位，评审专家的视角不同，同一份作品的几位专家给出的成绩会有较大的差异（极差）。极差大是大规模创新类竞赛的特点，极差比较大的作品一般处于高分段或低分段。低分段属于淘汰范围，低分段极差大的原因是有专家对违规作品或有重大失误的作品给了很低的分数，或评审专家都认同该作品质量不高，只是其中某位（些）专家更不认同该作品。故这里极差虽大，但属于不获奖范畴，一般不需要调整极差。而高分段作品还要参加权威性较高的第二阶段评审（附件数据表格同一行代表同一个作品在两个阶段的成绩，没有第二阶段评审成绩的作品只参加了第一阶段的评审）。第二阶段评审仍然存在部分极差大的作品，因为是终审，误差可能影响获奖等级，因此对部分极差大的作品，需要复议调整极差（附件的数据中有记录，复议分就是该专家最后给的标准分，用来替换原来的标准分）。第二阶段（注意两个阶段每份作品评审专家人数不同）专家调整“大极差”的规律可以作为建立极差模型的借鉴。\n请根据题目所给的模拟数据 2.1 和 2.2，讨论两阶段的成绩整体的变化和两阶段极差整体的变化，分析两阶段评审方案相比不分阶段评审方案的优劣。注意到极差大和创新性强两大特点之间会有一定的关系，为了发掘创新论文，请建立“极差”模型（含分析、分类、调整等），并针对所给数据，尝试给出第一评审阶段程序化（不需要人工干预）处理非高且非低分段作品的“大极差”的办法。\n问题四：\n对“创新类”竞赛，给出一个完整的评审模型（提示：例如优化模型），并针对所给的数据研究如何求解？也可对现行的评审方案给出改进的具体建议（包括未来还要收集哪些数据）。\nAddendum: \n附件：\n1. 极差的定义及标准分的计算方法\n2. 数据1：模拟某大型创新类竞赛的评审数据，其第二阶段被评选为一等奖作品的排序经专家协商取得一致。\n3. 数据2： 模拟某大型创新类竞赛两阶段的评审数据，有两组2.1和2.2。\nDataset Path:\n['数据1.xlsx', '数据2.1_.xlsx', '数据2.2_.xlsx', '极差的定义及标准分的计算方法.docx']\n\nData Description:\n该数据集由多份表格和一份方法说明文档组成，主要用于评估和改进赛事评审方案的合理性与公平性：数据1（数据1.xlsx）以参赛队伍为主体，记录了队伍的最终成绩、名次与奖项，并包含各评审环节的分数信息（如第一次与第二次评审成绩、复议后的分数）、标准分及其极差等反映评分分布和离散程度的指标；数据2.1_（数据2.1_.xlsx）以参赛作品为单位，保存每件作品在各评审轮次的原始分与经过标准化处理的标准分、评审专家编码、最终成绩、名次与奖项等；数据2.2_（数据2.2_.xlsx）在队伍层面补充了学校编码并汇总各专家的评审原始分与标准分、名次与奖项，用于按学校或队伍维度进行分析。随附的“极差的定义及标准分的计算方法.docx”详细说明了极差的定义、标准分的计算规则以及不同评审阶段作品最终成绩的合成方法，确保评分处理可复现。整体数据既包含逐位专家的原始评分和标识码，便于分析评审者间一致性、偏差与潜在异常值，也包含标准化后分数和极差、复议前后变化等指标，支持对评分离散性、标准化效果、复议影响、不同评审轮次之间评分稳定性以及奖励分配合理性等问题开展统计检验、可视化和建模，从而为优化评审机制、制定更为公平的评分方案提供实证依据。",
  "problem": {
    "background": "现在创新类竞赛很多，其中规模较大的竞赛，一般采用两阶段（网评、现场评审）或三阶段（网评、现场评审和答辩）评审。创新类竞赛的特点是没有标准答案，需要评审专家根据命题人（组）提出的评审框架（建议）独立评审。所以，对同一份作品，不同评委的评分可能存在较大差异。事实上，当竞赛规模大，评委的人数众多时，极差（定义见附件1）大的问题更为突出。显然，简单地依据多位评委评分的总和进行排序并不是创新类竞赛评审的好方案。因此，探讨大规模创新类竞赛评审方案的公正性、公平性和科学性具有深远意义。\n目前，各项创新类竞赛都在摸索、调整自己的评审方案。现有方案包括：\n(1) 对每位评审专家的评分进行标准化（公式见附件1），按作品将标准分相加得每件作品总分，然后依总分排序；\n(2) 去掉同一份作品得分中的最高分、最低分，再将剩余评分相加，最后依总分排序；\n(3) 同一份作品如果专家的评分差异（极差）较大，组织相关专家协商调整，将调整后得分相加，再依总分排序；\n(4) 当竞赛规模很大时，首先利用上述方案（1）或（2）或（3）对作品进行初选，再对初选入围的作品组织专家评审（第二阶段评审）或经过答辩等环节确定获奖名单。\n这些方案都有一定的合理性，但也有局限性。特别是针对大规模创新类竞赛评审，现有方案偏简单，研究不多。\n在大规模创新类竞赛中，增加评审每份作品的专家人数，显然有利于评审工作的公正、公平。然而，由于种种原因，参与评审工作的专家数目是受限的。评审专家少了，评审工作的误差会变大。不过，考虑到大规模创新类竞赛获奖比例通常小于50%，有些误差并不影响是否获奖。因此，在不影响获奖等级的前提下，为了适应评审专家人数较少的现状，不少竞赛采用两阶段评审办法。\n为探索大规模创新类竞赛评审的好方法，附件给出模拟大规模创新类竞赛的数据。其包含两阶段评审，第一阶段由五位专家对作品评审，取标准分后，将五位专家的标准分取均值后排序，按事先约定的比例取排名在前的作品，进入第二阶段评审。第二阶段由三位专家对作品评审，分别取标准分，并对少数极差大作品的标准分进行必要的调整后，再将第一阶段五位专家评审标准分的均值、第二阶段三位专家的评审标准分共4份成绩求和，依最终总成绩再排序。",
    "problem_requirement": "请利用这批数据建立数学模型，探讨建立更为合理、公平的评审方案。\n问题一：\n在每个评审阶段，作品通常都是随机分发的，每份作品需要多位评委独立评审。为了增加不同评审专家所给成绩之间的可比性，不同专家评审的作品集合之间应有一些交集。但有的交集大了，则必然有交集小了，则可比性变弱。请针对3000支参赛队和125位评审专家，每份作品由5位专家评审的情况，建立数学模型确定最优的“交叉分发”方案，并讨论该方案的有关指标（自己定义）和实施细节。\n问题二：\n在评审中采用标准分（附件1）为基础的排序方法，其假设是不同评审专家评审的作品集合的学术水平分布相同。但在大规模创新类竞赛评审中，通常任意两位专家评审的作品只有小部分是共同的，绝大多数作品是不同的。(见问题一)，而且每位专家只看到作品集合的很小部分，因此标准分评审方案的假设可能不成立，需要探索新的评审方案。请选择两种或两种以上现有或自己设计的评审方案和题目附件数据，分析每位专家、每份作品原始成绩、调整之后（如取标准分）成绩的分布特点，按不同方案进行排序，并设法比较这些方案的优劣。进而针对大规模创新类竞赛的评审，设计新的标准分（公式）计算模型。另外，一般认为经多位专家协商一致的获奖论文具有最大的可信度，附件 2 提供的数据 1，其第二评审阶段评选出的一等奖作品排序是经专家协商取得一致的，请利用这批数据，改进你们的标准分计算模型。\n问题三：\n“创新类”大赛的特点是“创新性”，即没有标准答案。由于这类竞赛的问题难度较大，一般需要通过创新才能在竞赛期间部分解决。而作品的创新到了什么程度，后续研究的前景如何，很难有一致看法，即使专家面对面的交流，都可能由于各持己见而无法统一。加上研究生的论文表达不到位，评审专家的视角不同，同一份作品的几位专家给出的成绩会有较大的差异（极差）。极差大是大规模创新类竞赛的特点，极差比较大的作品一般处于高分段或低分段。低分段属于淘汰范围，低分段极差大的原因是有专家对违规作品或有重大失误的作品给了很低的分数，或评审专家都认同该作品质量不高，只是其中某位（些）专家更不认同该作品。故这里极差虽大，但属于不获奖范畴，一般不需要调整极差。而高分段作品还要参加权威性较高的第二阶段评审（附件数据表格同一行代表同一个作品在两个阶段的成绩，没有第二阶段评审成绩的作品只参加了第一阶段的评审）。第二阶段评审仍然存在部分极差大的作品，因为是终审，误差可能影响获奖等级，因此对部分极差大的作品，需要复议调整极差（附件的数据中有记录，复议分就是该专家最后给的标准分，用来替换原来的标准分）。第二阶段（注意两个阶段每份作品评审专家人数不同）专家调整“大极差”的规律可以作为建立极差模型的借鉴。\n请根据题目所给的模拟数据 2.1 和 2.2，讨论两阶段的成绩整体的变化和两阶段极差整体的变化，分析两阶段评审方案相比不分阶段评审方案的优劣。注意到极差大和创新性强两大特点之间会有一定的关系，为了发掘创新论文，请建立“极差”模型（含分析、分类、调整等），并针对所给数据，尝试给出第一评审阶段程序化（不需要人工干预）处理非高且非低分段作品的“大极差”的办法。\n问题四：\n对“创新类”竞赛，给出一个完整的评审模型（提示：例如优化模型），并针对所给的数据研究如何求解？也可对现行的评审方案给出改进的具体建议（包括未来还要收集哪些数据）。",
    "dataset_path": [
      "数据1.xlsx",
      "数据2.1_.xlsx",
      "数据2.2_.xlsx",
      "极差的定义及标准分的计算方法.docx"
    ],
    "dataset_description": {
      "数据1": "数据1.xlsx包含参赛队伍的评审成绩数据，包括最终成绩、名次、奖项、评审标准分极差、复议后极差、第一次评审成绩、第二次评审成绩等信息。数据用于探讨评审方案的合理性和公平性。",
      "数据2.1_": "数据2.1_.xlsx包含参赛作品的评审成绩数据，包括最终成绩、名次、奖项、评审专家的编码、原始分、标准分等信息，用于探讨评审方案的合理性和公平性。",
      "数据2.2_": "数据2.2_.xlsx包含参赛队伍的评审成绩、名次、奖项、学校编码以及评审专家的评审成绩和标准分等信息，用于探讨建立更为合理、公平的评审方案。",
      "极差的定义及标准分的计算方法": "极差的定义及标准分的计算方法.docx提供了极差的定义及标准分的计算方法，详细描述了如何根据专家评审成绩计算标准分，并说明了不同评审阶段作品最终成绩的计算方法。"
    },
    "variable_description": [
      {
        "最终成绩": "参赛队伍的最终评审成绩",
        "名次": "参赛队伍的最终排名",
        "奖项": "参赛队伍获得的奖项",
        "第二次评审标准分极差": "第二次评审中标准分的最大值与最小值之差",
        "复议后极差": "复议后标准分的最大值与最小值之差",
        "第一次评审成绩": "第一次评审中各专家对作品的评分",
        "专家一": "第一次评审中第一位专家的编码",
        "专家二": "第一次评审中第二位专家的编码",
        "专家三": "第一次评审中第三位专家的编码",
        "专家四": "第一次评审中第四位专家的编码",
        "专家五": "第一次评审中第五位专家的编码",
        "专家编码": "专家的唯一标识编码",
        "原始分": "专家对作品的原始评分",
        "标准分": "专家对作品评分的标准分",
        "最高分": "第一次评审中该作品的最高评分",
        "最低分": "第一次评审中该作品的最低评分",
        "极差": "第一次评审中该作品的评分极差",
        "第二次评审成绩": "第二次评审中各专家对作品的评分",
        "复议分": "复议后专家对作品的评分"
      },
      {
        "最终成绩": "作品的最终评审成绩",
        "名次": "作品在所有参赛作品中的排名",
        "奖项": "作品获得的奖项等级",
        "第二次评审标准分极差": "第二次评审中标准分的最大值与最小值之差",
        "复议后极差": "复议后标准分的最大值与最小值之差",
        "第一次评审成绩": "第一次评审的原始成绩",
        "专家一": "评审专家的编码",
        "专家二": "评审专家的编码",
        "专家三": "评审专家的编码",
        "专家四": "评审专家的编码",
        "专家五": "评审专家的编码",
        "专家编码": "评审专家的唯一标识符",
        "原始分": "专家给出的原始分数",
        "标准分": "经过标准化处理后的分数",
        "极差情况": "评审过程中标准分的极差情况",
        "第二次评审成绩": "第二次评审的原始成绩",
        "最高分": "评审专家给出的最高分数",
        "最低分": "评审专家给出的最低分数",
        "极差": "评审专家给出的分数极差",
        "复议分": "复议后的分数"
      },
      {
        "最终成绩": "参赛队伍的最终成绩",
        "名次": "参赛队伍的最终排名",
        "奖项": "参赛队伍获得的奖项",
        "学校编码": "参赛队伍所属学校的编码",
        "第二次评审标准分极差": "第二次评审中标准分的最大值与最小值之差",
        "复议后极差": "复议后标准分的最大值与最小值之差",
        "第一次评审成绩": "第一次评审的原始成绩",
        "专家一": "评审专家的编码",
        "专家二": "评审专家的编码",
        "专家三": "评审专家的编码",
        "专家四": "评审专家的编码",
        "专家五": "评审专家的编码",
        "原始分": "专家评审的原始分数",
        "标准分": "专家评审的标准分数",
        "极差情况": "评审成绩的极差情况",
        "复议分": "复议后的分数"
      },
      {}
    ],
    "addendum": "附件：\n1. 极差的定义及标准分的计算方法\n2. 数据1：模拟某大型创新类竞赛的评审数据，其第二阶段被评选为一等奖作品的排序经专家协商取得一致。\n3. 数据2： 模拟某大型创新类竞赛两阶段的评审数据，有两组2.1和2.2。",
    "data_summary": "Dataset Path:\n['数据1.xlsx', '数据2.1_.xlsx', '数据2.2_.xlsx', '极差的定义及标准分的计算方法.docx']\n\nData Description:\n该数据集由多份表格和一份方法说明文档组成，主要用于评估和改进赛事评审方案的合理性与公平性：数据1（数据1.xlsx）以参赛队伍为主体，记录了队伍的最终成绩、名次与奖项，并包含各评审环节的分数信息（如第一次与第二次评审成绩、复议后的分数）、标准分及其极差等反映评分分布和离散程度的指标；数据2.1_（数据2.1_.xlsx）以参赛作品为单位，保存每件作品在各评审轮次的原始分与经过标准化处理的标准分、评审专家编码、最终成绩、名次与奖项等；数据2.2_（数据2.2_.xlsx）在队伍层面补充了学校编码并汇总各专家的评审原始分与标准分、名次与奖项，用于按学校或队伍维度进行分析。随附的“极差的定义及标准分的计算方法.docx”详细说明了极差的定义、标准分的计算规则以及不同评审阶段作品最终成绩的合成方法，确保评分处理可复现。整体数据既包含逐位专家的原始评分和标识码，便于分析评审者间一致性、偏差与潜在异常值，也包含标准化后分数和极差、复议前后变化等指标，支持对评分离散性、标准化效果、复议影响、不同评审轮次之间评分稳定性以及奖励分配合理性等问题开展统计检验、可视化和建模，从而为优化评审机制、制定更为公平的评分方案提供实证依据。",
    "data_description": {
      "数据1": "数据1.xlsx包含参赛队伍的评审成绩数据，包括最终成绩、名次、奖项、评审标准分极差、复议后极差、第一次评审成绩、第二次评审成绩等信息。数据用于探讨评审方案的合理性和公平性。",
      "数据2.1_": "数据2.1_.xlsx包含参赛作品的评审成绩数据，包括最终成绩、名次、奖项、评审专家的编码、原始分、标准分等信息，用于探讨评审方案的合理性和公平性。",
      "数据2.2_": "数据2.2_.xlsx包含参赛队伍的评审成绩、名次、奖项、学校编码以及评审专家的评审成绩和标准分等信息，用于探讨建立更为合理、公平的评审方案。",
      "极差的定义及标准分的计算方法": "极差的定义及标准分的计算方法.docx提供了极差的定义及标准分的计算方法，详细描述了如何根据专家评审成绩计算标准分，并说明了不同评审阶段作品最终成绩的计算方法。"
    },
    "problem_str": "问题背景：\n现在创新类竞赛很多，其中规模较大的竞赛，一般采用两阶段（网评、现场评审）或三阶段（网评、现场评审和答辩）评审。创新类竞赛的特点是没有标准答案，需要评审专家根据命题人（组）提出的评审框架（建议）独立评审。所以，对同一份作品，不同评委的评分可能存在较大差异。事实上，当竞赛规模大，评委的人数众多时，极差（定义见附件1）大的问题更为突出。显然，简单地依据多位评委评分的总和进行排序并不是创新类竞赛评审的好方案。因此，探讨大规模创新类竞赛评审方案的公正性、公平性和科学性具有深远意义。\n目前，各项创新类竞赛都在摸索、调整自己的评审方案。现有方案包括：\n(1) 对每位评审专家的评分进行标准化（公式见附件1），按作品将标准分相加得每件作品总分，然后依总分排序；\n(2) 去掉同一份作品得分中的最高分、最低分，再将剩余评分相加，最后依总分排序；\n(3) 同一份作品如果专家的评分差异（极差）较大，组织相关专家协商调整，将调整后得分相加，再依总分排序；\n(4) 当竞赛规模很大时，首先利用上述方案（1）或（2）或（3）对作品进行初选，再对初选入围的作品组织专家评审（第二阶段评审）或经过答辩等环节确定获奖名单。\n这些方案都有一定的合理性，但也有局限性。特别是针对大规模创新类竞赛评审，现有方案偏简单，研究不多。\n在大规模创新类竞赛中，增加评审每份作品的专家人数，显然有利于评审工作的公正、公平。然而，由于种种原因，参与评审工作的专家数目是受限的。评审专家少了，评审工作的误差会变大。不过，考虑到大规模创新类竞赛获奖比例通常小于50%，有些误差并不影响是否获奖。因此，在不影响获奖等级的前提下，为了适应评审专家人数较少的现状，不少竞赛采用两阶段评审办法。\n为探索大规模创新类竞赛评审的好方法，附件给出模拟大规模创新类竞赛的数据。其包含两阶段评审，第一阶段由五位专家对作品评审，取标准分后，将五位专家的标准分取均值后排序，按事先约定的比例取排名在前的作品，进入第二阶段评审。第二阶段由三位专家对作品评审，分别取标准分，并对少数极差大作品的标准分进行必要的调整后，再将第一阶段五位专家评审标准分的均值、第二阶段三位专家的评审标准分共4份成绩求和，依最终总成绩再排序。\n\n问题要求：\n请利用这批数据建立数学模型，探讨建立更为合理、公平的评审方案。\n问题一：\n在每个评审阶段，作品通常都是随机分发的，每份作品需要多位评委独立评审。为了增加不同评审专家所给成绩之间的可比性，不同专家评审的作品集合之间应有一些交集。但有的交集大了，则必然有交集小了，则可比性变弱。请针对3000支参赛队和125位评审专家，每份作品由5位专家评审的情况，建立数学模型确定最优的“交叉分发”方案，并讨论该方案的有关指标（自己定义）和实施细节。\n问题二：\n在评审中采用标准分（附件1）为基础的排序方法，其假设是不同评审专家评审的作品集合的学术水平分布相同。但在大规模创新类竞赛评审中，通常任意两位专家评审的作品只有小部分是共同的，绝大多数作品是不同的。(见问题一)，而且每位专家只看到作品集合的很小部分，因此标准分评审方案的假设可能不成立，需要探索新的评审方案。请选择两种或两种以上现有或自己设计的评审方案和题目附件数据，分析每位专家、每份作品原始成绩、调整之后（如取标准分）成绩的分布特点，按不同方案进行排序，并设法比较这些方案的优劣。进而针对大规模创新类竞赛的评审，设计新的标准分（公式）计算模型。另外，一般认为经多位专家协商一致的获奖论文具有最大的可信度，附件 2 提供的数据 1，其第二评审阶段评选出的一等奖作品排序是经专家协商取得一致的，请利用这批数据，改进你们的标准分计算模型。\n问题三：\n“创新类”大赛的特点是“创新性”，即没有标准答案。由于这类竞赛的问题难度较大，一般需要通过创新才能在竞赛期间部分解决。而作品的创新到了什么程度，后续研究的前景如何，很难有一致看法，即使专家面对面的交流，都可能由于各持己见而无法统一。加上研究生的论文表达不到位，评审专家的视角不同，同一份作品的几位专家给出的成绩会有较大的差异（极差）。极差大是大规模创新类竞赛的特点，极差比较大的作品一般处于高分段或低分段。低分段属于淘汰范围，低分段极差大的原因是有专家对违规作品或有重大失误的作品给了很低的分数，或评审专家都认同该作品质量不高，只是其中某位（些）专家更不认同该作品。故这里极差虽大，但属于不获奖范畴，一般不需要调整极差。而高分段作品还要参加权威性较高的第二阶段评审（附件数据表格同一行代表同一个作品在两个阶段的成绩，没有第二阶段评审成绩的作品只参加了第一阶段的评审）。第二阶段评审仍然存在部分极差大的作品，因为是终审，误差可能影响获奖等级，因此对部分极差大的作品，需要复议调整极差（附件的数据中有记录，复议分就是该专家最后给的标准分，用来替换原来的标准分）。第二阶段（注意两个阶段每份作品评审专家人数不同）专家调整“大极差”的规律可以作为建立极差模型的借鉴。\n请根据题目所给的模拟数据 2.1 和 2.2，讨论两阶段的成绩整体的变化和两阶段极差整体的变化，分析两阶段评审方案相比不分阶段评审方案的优劣。注意到极差大和创新性强两大特点之间会有一定的关系，为了发掘创新论文，请建立“极差”模型（含分析、分类、调整等），并针对所给数据，尝试给出第一评审阶段程序化（不需要人工干预）处理非高且非低分段作品的“大极差”的办法。\n问题四：\n对“创新类”竞赛，给出一个完整的评审模型（提示：例如优化模型），并针对所给的数据研究如何求解？也可对现行的评审方案给出改进的具体建议（包括未来还要收集哪些数据）。\nAddendum: \n附件：\n1. 极差的定义及标准分的计算方法\n2. 数据1：模拟某大型创新类竞赛的评审数据，其第二阶段被评选为一等奖作品的排序经专家协商取得一致。\n3. 数据2： 模拟某大型创新类竞赛两阶段的评审数据，有两组2.1和2.2。\nDataset Path:\n['数据1.xlsx', '数据2.1_.xlsx', '数据2.2_.xlsx', '极差的定义及标准分的计算方法.docx']\n\nData Description:\n该数据集由多份表格和一份方法说明文档组成，主要用于评估和改进赛事评审方案的合理性与公平性：数据1（数据1.xlsx）以参赛队伍为主体，记录了队伍的最终成绩、名次与奖项，并包含各评审环节的分数信息（如第一次与第二次评审成绩、复议后的分数）、标准分及其极差等反映评分分布和离散程度的指标；数据2.1_（数据2.1_.xlsx）以参赛作品为单位，保存每件作品在各评审轮次的原始分与经过标准化处理的标准分、评审专家编码、最终成绩、名次与奖项等；数据2.2_（数据2.2_.xlsx）在队伍层面补充了学校编码并汇总各专家的评审原始分与标准分、名次与奖项，用于按学校或队伍维度进行分析。随附的“极差的定义及标准分的计算方法.docx”详细说明了极差的定义、标准分的计算规则以及不同评审阶段作品最终成绩的合成方法，确保评分处理可复现。整体数据既包含逐位专家的原始评分和标识码，便于分析评审者间一致性、偏差与潜在异常值，也包含标准化后分数和极差、复议前后变化等指标，支持对评分离散性、标准化效果、复议影响、不同评审轮次之间评分稳定性以及奖励分配合理性等问题开展统计检验、可视化和建模，从而为优化评审机制、制定更为公平的评分方案提供实证依据。"
  },
  "problem_background": "现在创新类竞赛很多，其中规模较大的竞赛，一般采用两阶段（网评、现场评审）或三阶段（网评、现场评审和答辩）评审。创新类竞赛的特点是没有标准答案，需要评审专家根据命题人（组）提出的评审框架（建议）独立评审。所以，对同一份作品，不同评委的评分可能存在较大差异。事实上，当竞赛规模大，评委的人数众多时，极差（定义见附件1）大的问题更为突出。显然，简单地依据多位评委评分的总和进行排序并不是创新类竞赛评审的好方案。因此，探讨大规模创新类竞赛评审方案的公正性、公平性和科学性具有深远意义。\n目前，各项创新类竞赛都在摸索、调整自己的评审方案。现有方案包括：\n(1) 对每位评审专家的评分进行标准化（公式见附件1），按作品将标准分相加得每件作品总分，然后依总分排序；\n(2) 去掉同一份作品得分中的最高分、最低分，再将剩余评分相加，最后依总分排序；\n(3) 同一份作品如果专家的评分差异（极差）较大，组织相关专家协商调整，将调整后得分相加，再依总分排序；\n(4) 当竞赛规模很大时，首先利用上述方案（1）或（2）或（3）对作品进行初选，再对初选入围的作品组织专家评审（第二阶段评审）或经过答辩等环节确定获奖名单。\n这些方案都有一定的合理性，但也有局限性。特别是针对大规模创新类竞赛评审，现有方案偏简单，研究不多。\n在大规模创新类竞赛中，增加评审每份作品的专家人数，显然有利于评审工作的公正、公平。然而，由于种种原因，参与评审工作的专家数目是受限的。评审专家少了，评审工作的误差会变大。不过，考虑到大规模创新类竞赛获奖比例通常小于50%，有些误差并不影响是否获奖。因此，在不影响获奖等级的前提下，为了适应评审专家人数较少的现状，不少竞赛采用两阶段评审办法。\n为探索大规模创新类竞赛评审的好方法，附件给出模拟大规模创新类竞赛的数据。其包含两阶段评审，第一阶段由五位专家对作品评审，取标准分后，将五位专家的标准分取均值后排序，按事先约定的比例取排名在前的作品，进入第二阶段评审。第二阶段由三位专家对作品评审，分别取标准分，并对少数极差大作品的标准分进行必要的调整后，再将第一阶段五位专家评审标准分的均值、第二阶段三位专家的评审标准分共4份成绩求和，依最终总成绩再排序。",
  "problem_requirement": "请利用这批数据建立数学模型，探讨建立更为合理、公平的评审方案。\n问题一：\n在每个评审阶段，作品通常都是随机分发的，每份作品需要多位评委独立评审。为了增加不同评审专家所给成绩之间的可比性，不同专家评审的作品集合之间应有一些交集。但有的交集大了，则必然有交集小了，则可比性变弱。请针对3000支参赛队和125位评审专家，每份作品由5位专家评审的情况，建立数学模型确定最优的“交叉分发”方案，并讨论该方案的有关指标（自己定义）和实施细节。\n问题二：\n在评审中采用标准分（附件1）为基础的排序方法，其假设是不同评审专家评审的作品集合的学术水平分布相同。但在大规模创新类竞赛评审中，通常任意两位专家评审的作品只有小部分是共同的，绝大多数作品是不同的。(见问题一)，而且每位专家只看到作品集合的很小部分，因此标准分评审方案的假设可能不成立，需要探索新的评审方案。请选择两种或两种以上现有或自己设计的评审方案和题目附件数据，分析每位专家、每份作品原始成绩、调整之后（如取标准分）成绩的分布特点，按不同方案进行排序，并设法比较这些方案的优劣。进而针对大规模创新类竞赛的评审，设计新的标准分（公式）计算模型。另外，一般认为经多位专家协商一致的获奖论文具有最大的可信度，附件 2 提供的数据 1，其第二评审阶段评选出的一等奖作品排序是经专家协商取得一致的，请利用这批数据，改进你们的标准分计算模型。\n问题三：\n“创新类”大赛的特点是“创新性”，即没有标准答案。由于这类竞赛的问题难度较大，一般需要通过创新才能在竞赛期间部分解决。而作品的创新到了什么程度，后续研究的前景如何，很难有一致看法，即使专家面对面的交流，都可能由于各持己见而无法统一。加上研究生的论文表达不到位，评审专家的视角不同，同一份作品的几位专家给出的成绩会有较大的差异（极差）。极差大是大规模创新类竞赛的特点，极差比较大的作品一般处于高分段或低分段。低分段属于淘汰范围，低分段极差大的原因是有专家对违规作品或有重大失误的作品给了很低的分数，或评审专家都认同该作品质量不高，只是其中某位（些）专家更不认同该作品。故这里极差虽大，但属于不获奖范畴，一般不需要调整极差。而高分段作品还要参加权威性较高的第二阶段评审（附件数据表格同一行代表同一个作品在两个阶段的成绩，没有第二阶段评审成绩的作品只参加了第一阶段的评审）。第二阶段评审仍然存在部分极差大的作品，因为是终审，误差可能影响获奖等级，因此对部分极差大的作品，需要复议调整极差（附件的数据中有记录，复议分就是该专家最后给的标准分，用来替换原来的标准分）。第二阶段（注意两个阶段每份作品评审专家人数不同）专家调整“大极差”的规律可以作为建立极差模型的借鉴。\n请根据题目所给的模拟数据 2.1 和 2.2，讨论两阶段的成绩整体的变化和两阶段极差整体的变化，分析两阶段评审方案相比不分阶段评审方案的优劣。注意到极差大和创新性强两大特点之间会有一定的关系，为了发掘创新论文，请建立“极差”模型（含分析、分类、调整等），并针对所给数据，尝试给出第一评审阶段程序化（不需要人工干预）处理非高且非低分段作品的“大极差”的办法。\n问题四：\n对“创新类”竞赛，给出一个完整的评审模型（提示：例如优化模型），并针对所给的数据研究如何求解？也可对现行的评审方案给出改进的具体建议（包括未来还要收集哪些数据）。",
  "problem_analysis": "总体出发点与模型目标。面对大规模创新类竞赛的两阶段或三阶段评审问题，其核心目标既包括统计学意义上的“准确地识别出真实优质作品”（效用最大化、召回与精确率的平衡），也包括社会意义上的“程序公正与可解释性”（每位参赛者感知到的公平性、评审过程的可审计性与可操作性）。从这个双重目标出发，建模思路应同时兼顾三个层面：一是如何在有限的评审资源（专家人数、专家可投入的工作量）下最大化鉴别能力；二是如何通过分配和统计处理降低评审噪声与专家系统性偏差对最终排序的干扰；三是如何构造透明、可操作的规则（包括自动化的极差处理与复议触发机制），使得评审过程既有统计保障又可被人理解与监督。因此在整个建模过程中，任何技术性选择都必须以这些目标为准绳：设计分发方案时考虑可比性与负载平衡，选择分数标准化与汇总规则时兼顾抗干扰能力和可解释性，制定极差处理和第二阶段复议规则时兼顾资源效率与结果稳定性。模型输出既应给出评审方案（例如交叉分发的具体算法、自动化的极差处理程序、最终得分的计算公式），也应给出衡量方案优劣的一组指标（如排名稳定性Kendall τ、选拔错误率、对不同学校/导师的偏置估计、所需专家总人时等）。\n\n显性与隐含假设及其影响。问题陈述隐含若干关键假设：专家评分可被量化且可比较；专家之间的评价误差可被视为独立同分布或可通过标准化消除；作品在不同专家看到的子集上其“真实质量”表现可稳定估计；专家数量与工作量受限需在有限资源下优化。实际上这些假设往往并不完全成立。首先，不同专家的尺度（偏置）与严苛度（方差）不同，且二者可能随其所评的作品集合的学术水平分布而变，导致单纯的标准分（z-score）标准化可能会过度校正或不足以消除系统性偏差；其次，专家之间存在相关性（相似背景的专家可能共同持有相同偏好）和学习效应（专家在评审过程中可能改变尺度），使得独立同分布假设被破坏；再次，样本分配不均与重叠太少会导致跨专家可比性弱，增加估计方差并影响排位稳定性。认识到这些偏离后，模型应引入更为灵活的结构：将专家的“系统性偏置”和“可信度/噪声”作为参数显式建模（例如线性混合效应或贝叶斯层次模型），并在分发与汇总策略中利用可观测信息（专家历史评分、学科背景、时间投入等）作校正或分层设计。\n\n要素关系与潜在复杂性。评审系统由作品、专家、评审阶段、评分规则和资源预算等模块相互耦合。作品的真实质量、专家的偏置与方差、分发设计（谁评哪些作品）、汇总算法（如何把若干分数组合成最终分）和复议政策共同决定最终的排名。复杂性主要体现在三个方面的相互依赖：分发设计影响每位专家看到的作品分布，进而影响其得分分布与标准化效果；汇总方法若过于简单可能放大小样本效应（例如某专家只评少量作品时标准差估计不稳），而复杂模型（如贝叶斯）需要足够的重叠信息才能收敛；复议与第二阶段安排会对首阶段的策略产生反向影响（例如如果第二阶段能大规模纠正误差，首阶段可以用更粗糙的筛选规则节约资源，反之则需更稳健的首轮筛选）。这些耦合关系意味着模型设计不能孤立地优化某个模块，而应采用整体优化或分层决策：在给定预算下，设计一个自适应分配与评分修正流程，使得“更多资源投入到最不确定或最可能影响最终名次的作品上”。\n\n交叉分发（问题一）的框架与实现思路。在3000件作品、125位专家、每件作品由5位专家评审的设置下，总评审次数为15000，因此平均每位专家需评审约120件作品（实际分配需兼顾工作量上限与冲突）。交叉分发的目标是使得不同专家看到的作品集合之间有足够重叠，从而提升跨专家比较的连通性与估计效率，同时避免某些对之间共同评审过多而牺牲其他对的可比性。理论上理想的目标是构建一个5-均匀超图（每件作品对应5个专家的超边），使得专家共现（任意一对专家同时评审的作品数）尽可能均匀分布且整体共现矩阵接近正则图。从组合设计算法角度，可以借鉴平衡不完全区组设计（BIBD）与图论中的均匀超图构造，但由于参数规模大且整数组合解可能不存在，更实用的方案是利用随机近似加上后验的局部优化：先通过配置模型为每位专家分配近似相同数量的稿件，然后以模拟退火或交换算法最小化目标函数（例如所有专家对共现次数的方差、专家负载不平衡度与冲突惩罚的加权和）。评价指标包括专家对共现次数的方差、专家-专家共现图的连通性与直径（低直径意味着信息能在专家群体间更好传播）、以及在假设线性混合模型下对作品固定效应估计方差的理论下界（或用数值仿真近似得到的平均排名误差Kendall τ）。实施细节要点包括：在分发算法中保留对同一学院/学校可能存在利益冲突的排除规则；保证每位专家的工作量在可承受范围；提供少量冗余（例如给每位专家多分配几件以应对弃评）并用实时调整机制（若某位专家弃评则重新调配）；对高度重叠的专家对施加上限，防止“圈内评审”导致局部偏差。实际操作可采用批次化分配：把125名专家分成若干“审稿小组”并跨小组安排部分交叉，或按时间轴分多轮随机交叉，均有助于实现良好的共现结构。\n\n替代评分与标准化策略（问题二）的建模思路。在数据稀疏重叠且专家尺度差异明显的情形下，单纯的按专家内部标准分（z-score）进行合并可能无法恢复真实质量排序。更有力的框架是把每个观测分数建模为“作品真分 + 专家偏置 + 随机误差”，并把专家偏置与误差方差当作参数估计。基于此可以提出多种方案并比较：最简单的是截尾/中位数或去极值均值法（如去最高最低或winsorize），这些方法对极端值鲁棒且易解释；更复杂的是线性混合效应模型（作品为固定效应或随机效应、专家为随机截距与随机斜率）和贝叶斯层次模型（对专家偏置与方差设先验并进行后验收缩），这些方法能在存在少量交叉时通过信息借用实现更稳定的作品质量估计；另一个视角是使用判别式排序模型（如Bradley-Terry或Plackett-Luce），将评分转换为成对比较的数据并估计作品“胜率”或相对排名。比较这些方法应以多项指标为准：与第二阶段专家协商一致的一等奖名单的匹配度（用作准金标准）、排名稳定性（Kendall τ在重复随机重分配或交叉验证下的分布）、对个别专家恶意偏差的鲁棒性以及可解释性与实现成本。根据数据1中第二阶段协商一致的一等奖名单，可以把这一子集作为训练集来校准模型超参数（例如贝叶斯模型的先验强度、极差阈值等），或采用监督学习思路（例如利用第一阶段各项统计量预测某件作品是否会成为协商一致的一等奖），从而反向验证与优化标准分的计算公式。一个改进的“标准分”建议是采用经验贝叶斯调整：先用混合效应模型估计每位专家的偏置与尺度，然后对专家内部z-score进行软收缩（shrinkage），即标准化后不直接等于z而是向总体分布中心回缩，回缩程度与该专家看到的样本量和方差估计不确定性相关；这种做法兼顾了对样本不足专家的稳健处理与对大量交叉信息的充分利用。\n\n极差（问题三）的本质与程序化处理。极差大的现象既可能来源于评分噪声或专家偏见，也可能是高创新性导致的专家观点分歧。区分这两类情况对决策至关重要：若极差源于创新性，则应倾向于给予机会（如进入第二阶段或增加评审人手）；若源于违规或明显错误，则应快速否决。可以从统计角度建立极差模型：对每件作品计算标准化的极差指标（例如标准差与中位绝对偏差MAD，或极差本身与预计在相似分位段中出现的极差的标准化残差），并对极差与平均得分之间的联合分布进行分层建模。基于这种模型，可定义三类带有操作性规则的分区：低分区（直接淘汰，不做极差复议）、高分区（强制复议或进入第二阶段）、中间不确定区（若极差超阈值则自动触发程序化处理）。程序化处理可采用若干策略：优先进行模型纠偏（用混合效应模型估计并扣除专家偏置后再汇总）、用稳健统计量（中位数或经调整的M估计）代替均值、或者对被判定为“高创新潜力”的高极差中间分段作品自动分配若干额外专家以获取更高置信度。阈值和触发规则应通过仿真或历史数据（数据2.1/2.2）校准，使得自动复议资源主要耗在对最终名次可能产生实质影响的边缘案例上。此外可以把极差本身作为一个正则化项引入到最终得分计算中：在某些场景下给与高极差作品一定的“创新激励分”或“怀疑罚分”，但任何此类调整必须透明并基于可验证的统计准则，以免引入额外的不公平。\n\n完整评审模型与资源优化（问题四）。把前述思想整合为一个可实施的系统性模型，核心是一个贝叶斯/混合效应的估计层与一个预算优化的评审分配层并行运行。估计层把所有原始分数视为由作品真分、专家偏置/可信度、阶段效应及可能的作品-专家交互效应生成，利用贝叶斯或REML估计出每件作品的后验分布（均值与不确定度）。基于这些后验分布，决策层采用“主动采样/边际收益最大化”的原则分配额外评审资源：对于当前后验均值接近淘汰/晋级阈值且不确定度大的作品，优先分配更多专家；对于后验分布已集中、置信区间远离阈值的作品，减少资源。目标可以形式化为在给定总评审次数约束下最大化选对前K名的期望数或最小化预期排名误差。求解方法既可以用启发式的贪心算法（基于期望信息增益排序分配）也可以用较严谨的贝叶斯最优试验设计近似（例如多臂老虎机或贝叶斯优化的框架）来实现。计算实现上，贝叶斯模型可采用变分推断或Laplace近似以满足规模化需求（数千件、上万评分），参数估计还可以借助经验贝叶斯加速。评估指标包括预测二阶段协商一致结果的精度、排名稳定性、多次随机化分配下的变异系数、以及资源利用效率（例如每多分配一位专家带来的排名改进）。为保证方案可操作，还需给出标准的数据采集需求（记录每次评分的时间戳、专家背景、对作品的评论标签、是否存在利益冲突、是否弃评）和可视化报告（如每件作品的后验均值与置信区间、极差报警列表、专家偏置与可靠度指标），便于人工监督与事后审计。\n\n不确定性、风险与模型迭代。所有模型都依赖数据质量与建模假设，关键风险包括专家刻意操纵评分、交叉分配不充分导致参数估计偏差、以及模型复杂性带来的可解释性问题。应采取多重防护：在设计阶段采用随机化与均衡化以限制操纵空间；在估计阶段结合鲁棒方法（如M估计或重尾分布）以抵抗异常分数；在决策阶段引入人机混合审核，对于模型建议的边界案例由人工复核或线上讨论决定。此外把模型建成迭代式，使用每届竞赛的数据来估计专家的长期可靠度并作为先验输入，从而逐步提升系统的校准能力。长期效果（如专家声誉、学校通行率）也应被监测以防系统性偏差累积。最后，应明确解释权与申诉通道，公布关键统计规则与阈值，保证程序的透明性与可接受性。\n\n总结性建议。综合以上分析，推荐的方向是在分发层采用准均匀的随机化加局部优化的交叉分发算法以最大化专家间可比性；在评分汇总层使用层次模型/经验贝叶斯方法对专家偏置与尺度进行校正并输出后验不确定度；在极差处理层建立基于标准化极差与分数区间的自动触发和稳健汇总规则，把有限的复议资源优先用于高不确定度且可能影响最终名次的作品；在资源分配上采用基于信息增益的自适应分配策略以在总预算固定时最大化选拔准确率。整个系统应以可解释性与可操作性为准绳，配套必要的数据收集（专家特征、评分时间、评价文本）、仿真评估与持续迭代机制，以便在实践中不断校准与完善。上述方法既可用现有数据（数据1、数据2.1/2.2）进行离线回测与参数校准，也能在真实竞赛中逐步部署并通过A/B测试比较不同规则的具体效果。",
  "modeling_solution": "总体思路与目标陈述。针对题目中描述的大规模“创新类”竞赛评审场景（3000 件作品、125 位专家、每件作品第一阶段由 5 位专家评审等），我提出一个从分配层（交叉分发）、估计层（评分建模与标准化/汇总）、决策层（极差判别与复议资源自适应分配）三层整合的数学与算法框架。该框架的总体目标是：在有限专家资源下最大化对“真实优质作品”识别的准确性（尤其是 Top-K 精度），同时保证程序透明、统计可解释并能量化不确定性，从而为是否进入第二阶段、是否触发复议、最终排名与获奖决策提供可审计、可重复的规则与数值依据。为便于描述，先列出基本假设、符号与变量，然后给出分配模型、评分模型、极差模型与决策优化模型的关键方程、算法与实现路线，并说明如何基于所给数据进行估计、校准与验证。\n\n基本假设与符号。令 N 表示作品总数（N = 3000），M 表示专家总数（M = 125），r 表示每件作品需被评审的专家数（第一阶段 r = 5，第二阶段 r2 = 3），L_j 表示专家 j 的负载（评审件数），通常设近似均衡 L_j ≈ L = r N / M ≈ 120。定义二值分配矩阵 A ∈ {0,1}^{N×M}，A_{i,j} = 1 当且仅当专家 j 评审作品 i。定义专家共现矩阵 C ∈ Z^{M×M}，C_{j,k} = ∑_{i=1}^N A_{i,j} A_{i,k}（j≠k 时为两位专家共同评审的作品数）。设 y_{i,j} 为专家 j 给作品 i 的原始打分（若 j 未评审 i 则缺失）。本框架假定每次评分可视作观测值由作品真实质量 θ_i、专家系统偏置 b_j、专家尺度（方差）σ_j^2 及随机误差 ε_{i,j} 共同生成（可扩展含阶段效应与交互项）。即基本数据生成模型（DGM）为：y_{i,j} = θ_i + b_j + ε_{i,j}, ε_{i,j} ∼ N(0, σ_j^2)（或以稳健分布如 t 分布替换以对抗离群值）。这里 θ_i 为需估计的作品“真实质量”标量；b_j 与 σ_j 描述专家的系统性偏差与可信度。上述为最简模型，可扩展为加入交互项 γ_{i,j}（当某些专家对某类题目有系统不同尺度）或阶段固定效应 δ_s（第一/第二阶段不同评价尺度）。\n\n问题一：交叉分发（assignment）模型与优化。设计目标是在满足每件作品被恰好 r 位专家评审、且每位专家评审负载近似 L 的约束下，使专家-专家共现结构均衡化并保证专家-作品子图的良好连通性，从而提高跨专家参数可辨识性并降低 θ_i 后验方差。数学化目标可写为整数规划：给定 A ∈ {0,1}^{N×M}，约束 ∑_j A_{i,j} = r 对每个 i；∑_i A_{i,j} = L_j（或在 [L_min, L_max] 范围内）对每个 j；并可能有冲突二进制约束（若专家 j 与作品 i 存在潜在利益冲突则 A_{i,j} = 0）。目标函数可选择如下形式的加权二次目标以实现均衡共现与连通性：\nmin_A F(A) = w1 ∑_{j<k} (C_{j,k} - μ)^2 + w2 Var_j(L_j) + w3 φ(C),\n其中 μ = expected co-occurrence（目标均值），Var_j(L_j) 为专家负载方差，φ(C) 为惩罚函数以抑制某对专家共现过多（例如上界约束），w1,w2,w3 为权重以平衡目标。该整数规划规模巨大且 NP 难，实用解法为分两阶段启发式：先用准均匀随机化生成满足行列和（可用循环置换或带有冲突排除的随机分配），然后用局部改进（交换算法或模拟退火）最小化 F(A)。交换操作为在两个作品间交换专家分配（或在同一作品中替换评审专家）以减少目标值。评估指标包括专家对共现次数的样本方差、共现图的连通性与谱间隙（大谱间隙指信息流更快混合）、以及在假设 DGM 下通过 Fisher 信息或数值仿真估计的 θ 的平均后验方差/排名误差（例如用蒙特卡洛模拟计算不同 A 下估计 θ 的均方误差或 Kendall τ 的期望）。实施细节：在分配时同时满足利益冲突、地域/院校限制；保留冗余与替补专家以应对弃评；分批次发放（将专家分为若干小组，组内外交叉）可降低集中共现与提高整体连通性。该分配算法易并行化（每轮并发计算若干局部交换候选），并可在赛前模拟不同权重 w 后选择折中方案。\n\n问题二：评分标准化与汇总的统计建模与改进标准分。单纯按专家内部标准分（z-score）假设每位专家评审的作品样本服从相同级别分布，且其均值与方差可稳定估计。在交叉较少时，该假设破裂。更稳健且解释性强的方案是利用层次模型或经验贝叶斯来同时估计作品质量 θ_i 与专家偏置/可信度 (b_j, σ_j^2)。形式上以线性混合效应（LME）或贝叶斯层次模型（HBM）为基础：y_{i,j} = θ_i + b_j + ε_{i,j}, b_j ∼ N(μ_b, τ^2), ε_{i,j} ∼ N(0, σ_j^2). 在该模型下，给定观测矩阵与交叉结构，利用 REML 或经验贝叶斯估计 b_j 与 σ_j^2，随后计算每个作品的加权合并得分（即 θ 的后验均值）： \\hat{θ}_i = (∑_{j: A_{i,j}=1} w_{i,j} (y_{i,j} - \\hat{b}_j)) / ∑_{j: A_{i,j}=1} w_{i,j}, 其中权重 w_{i,j} = 1/ \\hat{σ}_j^2（若专家方差受信任，或更保守用 w_{i,j} = 1/( \\hat{σ}_j^2 + τ_θ^2 )），并且对估计不确定度给出后验方差 Var(θ_i | data)。 与常规 z-score 的改进是：首先对每个观测减去估计的专家偏置 \\hat{b}_j，再按专家的估计方差加权合并，而不是对每位专家内部作标准差标准化后直接求均值。为提高稳健性，可把 ε 的分布换为重尾分布（如 Student-t），或对异常分数进行 Winsorize/trim。另一个可选方法是把评分视为隐含比较的结果并用 Bradley–Terry / Plackett–Luce 模型来估计相对优先级，尤其在部分或整个评分可以转化为成对比较信息时更有效。为保留简洁可实施的“标准分公式”，我建议如下改良标准分：先估计专家偏置与尺度，通过经验贝叶斯获得 \\hat{b}_j, \\hat{σ}_j；定义调整后分 s_{i,j} = (y_{i,j} - \\hat{b}_j) / \\hat{σ}_j；然后对 s_{i,j} 做“收缩标准化”得到 s'_{i,j} = α_j s_{i,j} + (1-α_j) s̄，全局平均 s̄ 为全部调整后分的均值，权重 α_j = n_j / (n_j + κ) 根据该专家评审样本量 n_j 与常数 κ（反映 prior 强度/不确定性）确定，这实现了对样本量小专家的收缩；最终每件作品的标准分为 S_i = ∑_j w'_{i,j} s'_{i,j}（可取等权或按 1/\\hat{σ}_j^2 加权），并按 S_i 排序。用数据1（第二阶段专家经协商一致的一等奖作为“准金标准”）可以监督式地选择 κ 与权重形式，最大化对该“金标准”前若干名的召回与精确率，从而把模型调参为在高分端表现更可靠。\n\n问题三：极差模型、分类与程序化处理规则。定义极差 r_i = max_j y_{i,j} - min_j y_{i,j}，及标准化极差 zrang_i = (r_i - E[r | μ_i]) / sd[r | μ_i] 条件于该作品的平均分 μ_i（或处于的分数分段），因为题目中观察到极差与得分段位存在耦合（高分和低分更易出现大极差）。基于历史数据（数据2.1/2.2）拟合极差的条件分布 f(r | μ)，例如用局部回归或分位回归估计其均值与方差，以便将观测极差标准化。然后把作品分为三类：低分区（μ_i 低且不在复议范围：直接淘汰）、高分区（μ_i 高：强制复议或第二阶段审理）、中间不确定区。对中间区内且 zrang_i 超过阈值 τ 的“高极差”作品，采用程序化处理以替代人工逐件审查：方法一为“模型纠偏”——使用 LME/EB 模型估计并移除专家偏置后重算合并分数（若偏差来源于专家系统性偏置则能纠正）；方法二为“鲁棒合并”——改用中位数或删去最高最低后的加权均值；方法三为“增补评审”——在预算允许下按信息增益最大化原则自动分配额外 k 个专家来评审该作品。为了形式化增补评审分配问题，可把每件候选作品 i 的 θ_i 后验分布视为当前不确定性 U_i（例如后验方差），分配一个额外评审 j 将使后验方差降低 ΔU_{i,j}，而该降低量可估计或通过近似 analytic form 计算（若假设额外测量方差为 σ̄^2，则约减量为 function of σ̄^2 和现有 n_i）。目标是在总额外评审预算 B 下最大化对最终 Top-K 准确度的期望提升，可近似为贪心选择具有最大 ΔU_i / cost 的作品逐步分配（即每步选择具有最大不确定度边际收益的作品）。若不希望人工介入，可设定自动阈值使得在第一阶段结束后被触发的作品进入“自动复评池”由系统按优先级批量再分配专家。\n\n对于第二阶段中的“人工协商后复议”现象，可用数据1 建立专家在面对同一作品讨论后对自身评分调整的统计模型（例如学习偏向：b_j 在讨论后向总体靠拢的收缩系数），并把这种协商效应估计作为第一阶段是否触发人工复议的依据：若模型预测协商会显著减少某作品的后验方差且可能改变其名次，才启用人工复议。\n\n问题四：集成优化模型、求解策略与运筹实现。将上述三个模块合并为一个迭代的“分配—评估—再分配”闭环系统。初始阶段利用交叉分发算法 A^{(0)} 生成第一轮评分样本；估计阶段用经验贝叶斯/LME 模型得到 θ̂^{(0)} 与后验不确定度 U^{(0)}；决策阶段基于 U^{(0)} 和分数临界（如进入二阶段比例线）运行资源优化问题：在总预算约束下，选择若干作品分配额外评审、或列入第二阶段人工协商，目标为最小化最终名次误判代价（例如期望的 Top-K 错误数或 Kendall τ 距离）。该优化问题可形式化为：在预算 B 下选择集合 S，使得 Δ(S) 最大，Δ(S) 代表将 S 的作品由当前方案升级（如增评、人工复议或进入第二阶段）后对目标效用（Top-K 精确度）带来的期望增益。Δ(S) 通常不可直接解析，但可用启发式贪心算法近似（每一步选择带来最大边际增益的作品直到预算耗尽），或用近似动态规划/贝叶斯最优化方法精化。求解 θ 与 b 的估计可用 REML/EM 或贝叶斯变分推断/Stan（若完全贝叶斯）。在规模上 N≈3000、观测数约 15000，LME/EB 的计算量不大，可用线性代数直接求解（BLUP 形式）或用快速迭代法（如交替最小二乘、坐标下降）。对于交叉分配的整数优化，模拟退火或局部交换在数千到万级迭代中可收敛到满意解，且极易并行化。\n\n具体数学关系与公式回顾。分配目标：C = A^T A （对角项为每专家评审数），最小化 ∑_{j<k} (C_{j,k}-μ)^2 subject to A ∈ {0,1}, row sums r, column sums L_j。评分模型：y_{i,j} = θ_i + b_j + ε_{i,j}, b_j ∼ N(0, τ^2), ε_{i,j} ∼ N(0, σ_j^2)。经验贝叶斯估计流程：先在当前 A 下用 REML 得到 \\hat{b}_j, \\hat{σ}_j^2, τ^2；再计算加权后验均值 \\hat{θ}_i = (∑_{j: A_{i,j}=1} (y_{i,j} - \\hat{b}_j)/\\hat{σ}_j^2) / (∑_{j: A_{i,j}=1} 1/\\hat{σ}_j^2)（等价于多元正态下的条件期望），其后验方差约为 1/(∑_{j} 1/\\hat{σ}_j^2) + prior term（若对 θ 有先验）。收缩式标准分改良为 s'_{i,j} = α_j (y_{i,j}-\\hat{b}_j)/\\hat{σ}_j + (1-α_j) s̄，α_j = n_j/(n_j+κ)。极差标准化定义 zrang_i = (r_i - μ_r(μ_i)) / σ_r(μ_i)，以 μ_r(·), σ_r(·) 从历史数据估计。增补分配的边际不确定度减少可近似为 ΔVar(θ_i) ≈ (1/(∑_{j: existing} 1/σ_j^2) - 1/(∑_{j: existing} 1/σ_j^2 + 1/σ̄^2))。\n\n仿真、验证与性能指标。用题目提供的数据集（数据1、数据2.1、2.2）进行模型估计、调参与离线回测。验证方案的主要指标包括：Top-K 准确率（与第二阶段协商一致的一等奖名单或专家共识名单比较）、排名稳定性（Kendall τ 在重复随机分配/重采样下的分布）、平均后验方差（不确定度）、对单个专家极端操纵的鲁棒性（恶意专家插入实验）、以及资源效率（为提高一位入围者准确率所需的额外专家人时）。对比基线包括现行的标准分 z-score 合并、去极值均值（去最高最低）、以及中位数合并法。通过交叉验证或自举法估计各方法在 Top-K 检索上的期望误差，并用数据1 的第二阶段协商一致集作为“金标准”检验高分端表现以指导超参数（如 κ、极差阈值 τ）的选择。\n\n计算实现细节与复杂度。评分估计（LME/EB/BLUP）在 N≈3000 与观测 ~15000 规模可在单台普通服务器上用 R 的 lme4、glmmTMB 或用 Python 的 statsmodels/pyro 等工具高效完成；贝叶斯变分推断或 Stan 的 HMC 也可在可接受时间内完成但更耗时，若需实时或在线决策建议可使用快速近似（经验贝叶斯 + 迭代加权最小二乘）。交叉分发局部优化的计算量依赖于交换迭代次数，常用 10^4–10^6 次交换即可获得良好均衡，且每次交换的计算仅需更新受影响行列的共现计数，适合并行化。增补评审的贪心分配为 O(B log N) 的复杂度。为减轻复杂模型负担，可采用降维或代理模型：用分段估计（按分数带或按作品主题聚类）替代逐件独立估计，或用迭代收缩方法近似 BLUP。\n\n敏感性分析与模型鲁棒性。建议对下列参数进行敏感性分析：专家方差 σ_j^2 的估计偏差、专家偏置 b_j 的先验强度 τ^2、收缩常数 κ、交叉分配目标权重 w1、极差阈值 τ 以及增补评审预算 B。通过蒙特卡洛仿真（在不同 DGM 参数设定下生成数据并运行整个流程）评估模型在各种偏离假设下的表现（如专家间相关评分、部分专家恶意操纵、作品质量分布非正态等）。如果结果对某些参数高度敏感，应在实际操作中采用更为保守的阈值并保留人工复核通道。\n\n基于实际数据的具体应用建议。用数据2.1/2.2 对交叉分发方案进行仿真验证：先随机模拟若干 A 矩阵（含现有分配与优化后分配），基于已给出的 y_{i,j} 子样本估计 θ 并比较与真实第二阶段/复议结果的匹配。用数据1 的协商一致一等奖作为高分端的监督目标进行参数调优。对于第一阶段程序化处理大极差作品，建议先按模型自动触发：若作品位于中间分段且 zrang_i > τ（τ 可用历史数据校准，例如取 95% 分位），则系统自动对该作品重新估计 θ 用鲁棒方法（中位数或经调整的 BLUP）并决定是否进入第二阶段或追加 k 位专家进行评审。若追加资源后的后验均值仍靠近入围阈值则提交人工专家小组复议。整个规则与阈值应事先公开以保证透明性。\n\n未来扩展方向与长期演进。建议长期记录并利用专家元数据（学科/专业背景、历史评分分布、评分耗时、是否多次弃评、复议行为等）构建专家信誉/可信度模型，并将其纳入先验以提高估计稳定性；采集并分析专家评语文本，通过自然语言处理提取的特征作为作品质量 θ 的协变量，以增强对真实质量的预测能力；建立跨届累积数据库以对专家长期偏好建模并用作未来竞赛的先验信息。技术上可将该体系演化为在线贝叶斯更新系统：每次评分结果进入后即更新专家偏置与作品后验，从而在比赛过程中实现动态分配与及时复评触发。最后，建议在未来收集更多用于验证的“外部质量证据”（例如后续发表/项目获资助等长期指标）以评估并校准模型的长期有效性。\n\n总结性工作流建议。在实际运作中，先采用优化的交叉分配 A 保证足够的共现；第一阶段结束后用经验贝叶斯/LME 模型估计每件作品的后验均值与不确定度，并用改良的收缩标准分进行排序；根据后验均值与极差标准化指标把作品分入“直接淘汰”“需程序化复评”“强制人工复议/进入第二阶段”三类；在预算内按边际不确定度收益贪心分配追加评审资源；第二阶段人工协商后再用更新后的模型输出最终排名并公布每件作品的后验均值与置信区间以便申诉与审计。该方案在理论上兼顾了统计效率（通过跨专家信息借用与加权）、鲁棒性（对极值与操纵的稳健性处理）与可操作性（自动触发规则与公开奖惩阈值），并可以用题目给出的数据集进行参数估计、仿真验证与逐步优化。",
  "task_descriptions": [
    "子任务1（交叉分发方案设计与求解）— 在给定 N=3000 件作品、M=125 名评审、每件作品需由 r=5 名专家评审的约束下，构造并输出一个二元分配矩阵 A∈{0,1}^{N×M}（A_{i,j}=1 当且仅当专家 j 评审作品 i），使其同时满足每行和为 r、每列和在 [L_min,L_max]（期望负载 L≈rN/M≈120）及事先提供的利益冲突/回避约束，并在这些硬约束下优化专家间“共现”结构以最大化跨专家可比性与估计可识别性；具体任务包括（1）明确输入数据和参数：作品清单、专家清单、二元冲突矩阵或院校/导师分组约束、每位专家的最小/最大学负载、对任一专家对共同评审同一作品数的上限或目标均值 μ、随机种子和容错冗余量；（2）定义精确的目标函数与软约束，例如最小化专家-专家共现计数矩阵 C=A^T A 的元素与目标 μ 的平方偏差之和（∑_{j<k}(C_{j,k}-μ)^2）、同时加权惩罚负载不平衡 Var_j(L_j) 与任对专家共现超过上限的罚项，或采用多目标加权形式以便在均匀性与负载平衡间折中；（3）设计可行求解流程：先生成满足行列和和冲突约束的初始准均匀分配（例如基于循环置换/分批随机化或受限拉丁方/带冲突的随机贪心算法），然后采用高效的局部改进方法对目标函数进行迭代优化——允许的原子操作包括在两件作品间交换某位专家（或交换专家对）、替换单个专家分配、或在小块内重排，采用贪心局部搜索、模拟退火、禁忌搜索或基于局部元启发式的并行多起点搜索以避免局部最优；（4）实现细节与工程约束：在交换更新时仅局部维护 C 的增量更新以保持算法高效并易并行化，设定收敛与终止准则（最大迭代数、目标改善阈值或时间上限），保留备用专家名额及增量重分配接口以处理弃评/缺席情形，并在分配过程中强制执行院校/利益冲突过滤与每位专家的工作量上下界；（5）评估指标与检验程序：计算并报告分配结果的关键度量——专家对共现次数的均值与方差、共现图的连通性指标（连通分量数、直径）、谱间隙（algebraic connectivity）作为信息混合速率的代理、负载不平衡度、任对共现超限的频次，以及基于仿真（在指定的简单观测模型下）估计的作品固定效应参数的平均后验方差或排名稳定性指标（如蒙特卡洛下的 Kendall τ 或 Top-K 精度）以定量比较不同分配方案；（6）交付物与可操作接口：最终交付 A 矩阵及 C 矩阵、上述评估报告、变更日志与可重复的随机种子、一个用于在发生弃评时快速局部重分配的交换/补分配子例程，以及可配置的参数（μ、w 权重、L_min/L_max、冗余量、最大迭代数）；（7）建议使用的工具与实现技术包括：整数规划/约束编程（CP-SAT、Gurobi）用于小规模基准与可行性验证，规模化实施采用 Python/R 实现的启发式交换算法并行化执行（使用 numpy/pandas、networkx 做图分析，利用并行库或分布式任务队列），以及脚本化的仿真器用于评估对不同 A 的统计效应。该子任务的成功标准是生成满足所有硬约束、在目标函数上显著优于随机均匀基线的分配矩阵，并提供一套可重复、可扩展且在实际运行中能处理弃评和冲突的实施细则与评估报告。",
    "子任务2（精确任务说明）：建立并实现一个面向逐位评分的统计估计与“改良标准分”计算管线，其目标是在存在专家间系统性偏置与异质噪声（少量交叉样本）的现实条件下，稳健、可解释地估计每件作品的真实质量分数 θ_i、每位专家的系统偏置 b_j 与可信度（观测方差）σ_j^2，并据此输出经偏差校正、方差加权和收缩处理后的每件作品汇总得分 S_i 及其不确定度，以供排序与判别决策；该子任务的输入为原始评分表（y_{i,j}，含作品ID、专家ID、评审阶段标签）、每位专家的评审数量 n_j、可能的冲突/缺评标识以及数据1、数据2.1/2.2 中提供的第二阶段协商一致的高分样本（用于监督调参），明确步骤如下：1) 数据预处理：剔除冲突/无效记录、标注缺失并记录每位专家的样本量 n_j，初步做单变量异常检测（保留异常但记录）。2) 基本建模假设与可选扩展：以线性层次模型 y_{i,j} = θ_i + b_j + ε_{i,j} 为基础，允许扩展项包括阶段效应 δ_s（不同评审阶段的系统偏移）、作品-专家交互项或群组层次（如同校/同领域偏好），并允许 ε_{i,j} ~ N(0, σ_j^2) 或使用 Student-t 以增强对离群评分的鲁棒性；对专家偏置 b_j 采用随机效应先验 b_j ~ N(0, τ^2)。3) 参数估计流程：在规模（N≈3000, 总观测≈15000）可承受下优先采用经验贝叶斯/REML+BLUP 估计以获得快速、可解释的 b_j、σ_j^2、τ^2（工具建议：R(lme4/glmmTMB)、Python(statsmodels)），如需完整贝叶斯不确定度输出则用 Stan/PyMC3/变分推断加速；在估计时对样本量很小的专家使用层次先验自动收缩以避免方差估计不稳。4) 改良标准分计算：先计算偏差校正分 s_{i,j}^0 = y_{i,j} - \\hat b_j，再按专家可信度标准化 s_{i,j} = s_{i,j}^0 / \\hat σ_j；为避免小样本过度波动，采用经验贝叶斯收缩 s'_{i,j} = α_j s_{i,j} + (1-α_j) s̄，其中 α_j = n_j / (n_j + κ)（κ 为可调的收缩常数，通过交叉验证或以数据1 中专家协商一致的高分样本作为监督目标调参）；最终每件作品的合并得分采用加权平均 \\hat θ_i = sum_{j} w_{i,j} s'_{i,j} / sum_j w_{i,j}，权重可选择等权或 1/(\\hat σ_j^2) 型的逆方差加权，且同时输出后验方差 Var(θ_i | data)≈1/(sum_j 1/\\hat σ_j^2)+先验项 以量化不确定度。5) 鲁棒替代与诊断：并行实现简单鲁棒汇总器（中位数、去最高最低、Winsorize）与配对比较模型（Bradley-Terry/Plackett-Luce，当将评分转为相对胜负或序列时适用），对比其在高分端的稳定性；进行残差诊断、专家偏置分布检验、后验预测检验与自助法估计排名不确定性。6) 调参与验证：用交验证、AIC/BIC、预测对数似然以及以数据1 中第二阶段协商一致的一等奖名单作为“准金标准”的监督指标（Top-K 召回率、Kendall τ）来选择 κ、权重形式、是否采用 t 分布、以及是否包含阶段效应；对小样本专家可采用更强收缩并记录收缩程度以供解释。7) 输出与交付物：为每件作品输出经校正的得分 S_i、排序与置信区间、后验方差、各专家偏置估计 b_j 与可信度指标 σ_j^2、收缩参数 κ 的选定值与调参日志、以及模型诊断报告（残差图、后验预测检查、对比鲁棒方法的稳健性分析）。8) 计算注意事项：优先用 REML/BLUP 保证可扩展性与速度，当需要贝叶斯后验时优先使用变分或 Laplace 近似以缩短运行时间，并在模型拟合过程中对 n_j 很小或 σ_j^2 极端的专家采用下界约束或截尾以避免数值不稳定。该子任务的成功标准为：在提供的数据上可重复计算出稳定、可解释且在高分端通过监督验证优于传统按专家内部 z-score 简单标准化的校正分，并提供完整代码、参数与诊断结果以便审计与后续应用。",
    "子任务3（精确描述：极差建模、分类规则与程序化处理流程）：本子任务的目标是在给定每件作品的原始专家评分 y_{i,j}（含专家ID、阶段标签）及可用的专家偏置/方差估计（若无则在该流程第一步估计）基础上，建立一套可程序化、可复现的“极差判别→分区→自动处理→升级”工作流，明确极差的统计定义、条件标准化方法、分区阈值与动作规则、增评的自动分配准则及其近似量化公式，并输出对每件作品的最终处理决策和可审计记录。具体方法与步骤：一、输入与预处理：接收表格化原始评分 y_{i,j}、每位专家的评审数 n_j 与（可选的）先验专家偏置 b_j 与观测方差 σ_j^2，去除明确冲突/无效评分并记录缺评；二、极差定义与条件标准化：对每件作品计算原始极差 r_i = max_j y_{i,j} - min_j y_{i,j}，并定义作品平均得分 μ_i（可用偏差校正后的合并估计，如去偏后加权均值或初始θ̂_i），基于历史样本（或当前批次的分位拟合）估计条件极差的均值 μ_r(μ) 与尺度 σ_r(μ)（通过局部回归 LOESS/GAM、分位回归或分段统计量在 μ 上平滑估计），由此得到标准化极差 zrang_i = (r_i - μ_r(μ_i)) / σ_r(μ_i)；三、分区规则：按 μ_i 与 zrang_i 将作品分为三类：低分区（μ_i 低于淘汰阈值，直接淘汰且不触发极差复议）、高分区（μ_i 高于进入复议/第二阶段阈值，强制人工复议或进入下一阶段）、中间不确定区（介于两阈值之间），在中间区中若 zrang_i > τ（τ 的初始建议用历史数据的 95% 条件分位或通过交叉验证、模拟以优化对 Top-K 准确率的效用阈值）则标记为“高极差候选”；四、程序化自动处理顺序（仅针对中间区的高极差候选）：步骤A（模型纠偏）：基于当前专家偏置 b_j 与方差 σ_j^2 用经验贝叶斯/混合效应模型去除专家偏置并按逆方差加权重算新的合并得分 θ̂_i^{(corr)} 与其后验方差 Var^{(corr)}，若 θ̂_i^{(corr)} 与原排名差异足以改变入围结论则输出修正并记录；否则进入步骤B（鲁棒聚合）：采用稳健估计替代均值（中位数、去最高最低后加权均值、Winsorize 或 M-估计/Huber）并计算稳健得分与不确定度，若已决则输出；若仍不确定且资源允许进入步骤C（增补评审）：基于当前后验方差 U_i = Var(θ̂_i) 估计增配一位典型额外专家（假设其观测方差为 σ̄^2）的近似边际不确定度减少量 ΔVar_i ≈ 1/(∑_{j existing} 1/σ_j^2) - 1/(∑_{j existing} 1/σ_j^2 + 1/σ̄^2)，在总体增评预算 B 下采用贪心策略每次选择具有最大 ΔVar_i / cost 的作品分配额外评审，重复直至预算耗尽或 U_i 降至可接受阈值；五、升级与人工复议触发：对在自动处理后仍保持高不确定度且可能改变最终名次（例如后验均值与阈值相距小于 ε 或后验分布覆盖入围阈值概率介于 α_low 与 α_high）者，自动列为人工专家小组复议对象；六、阈值与参数校准：用历史数据集（例如提供的 data 文件）或自助蒙特卡罗仿真以最大化期望 Top-K 精确率、或以最小化名次误判代价为准则，通过交叉验证确定 τ、σ̄^2、增评上限 k、预算 B 与人工复议触发的概率阈值 α；七、输出与可审计记录：对每件作品输出（1）原始 r_i 与 zrang_i、（2）μ_i 与 θ̂_i（各阶段）、（3）所采取的自动化处理路径（A/B/C）、（4）追加评审数与分配日志、（5）最终合并得分与后验不确定度、（6）是否上报人工复议及理由；八、工具与实现建议：推荐使用 R 或 Python（pandas/numpy 做数据处理，statsmodels/lme4 或 REML/BLUP 实现经验贝叶斯去偏，scikit-learn/pygam/locfit 用于平滑回归与 LOESS，quantreg 做分位回归），并将流程写成可重复执行的批处理脚本以便在大样本下并行运行与日志化；九、评价指标与审计：提供用于事后评估的指标（被触发自动处理的比例、自动处理后改变入围结论的比例、人工复议召回率、单位增评成本带来的名次改进等），并要求所有判定阈值与参数在系统中可配置且在赛前公开以保证透明性与可追溯性。",
    "子任务 4（集成决策优化、迭代工作流与部署）—— 在给定初始评分数据、专家-作品分配与可用增评/复议预算 B 的前提下，构建并实现一个端到端的迭代决策系统，其目标是在固定资源下最大化最终排名的准确性（可用目标函数表述为最大化 Top‑K 识别率或最小化预期 Kendall τ），并以可审计、可配置的规则驱动“分配→估计→再分配→决策”闭环；具体范围包括（1）输入：原始打分表（作品ID、专家ID、阶段标签、时间戳）、当前分配矩阵与每位专家的可用工作量/冲突约束、以及增评/复议总预算 B 与可配置阈值；（2）估计模块：基于线性混合效应或经验贝叶斯模型（实现建议：REML/BLUP 为主、可选变分/Laplace 近似或 MCMC 于离线校准）周期性估计每件作品的后验均值与不确定度（后验方差），并同时更新专家偏置与方差估计；（3）优化模块：在每一次迭代中把作品的不确定度与接近决策边界的后验概率作为“信息价值”度量，求解受预算与专家负载约束下的资源分配子问题——优先按最大边际收益（预期减少的不确定度或预期提升的 Top‑K 准确度）分配额外评审或标注进入人工复议，求解策略以贪心边际增益或近似贝叶斯最优试验设计为主，必要时用多臂老虎机启发或整数规划作局部精化；（4）迭代规则与终止条件：在每轮分配后更新模型并重复，直至预算耗尽、排名收敛（例如最大名次变动小于预设 ε）或无边际收益可得，并在每轮对被选为人工复议的边缘案例触发人工小组审定；（5）约束与规则执行：在分配与再分配时强制执行利益冲突、地域/单位回避与每位专家的最小/最大负载，并记录弃评与重分配情形；（6）输出与审计日志：对每次迭代输出并存档每件作品的后验均值、后验方差、进入下一轮的决策理由（如被增评/人工复议/淘汰/晋级）、所使用阈值及随机种子、以及所有分配更改的时间戳与责任人，以保证可复现与可追溯；（7）参数校准与验证：提供仿真/回测接口用于用历史数据或半合成数据评估不同目标函数、阈值与贪心策略的性能（度量包括 Top‑K 精确率、Kendall τ 分布、单位专家时间的效用增益），并据此确定可配置参数；（8）实现与运维建议：建议以模块化服务部署（数据摄取、估计引擎、优化引擎、任务分发器與审计数据库），使用常见工具链（Python: pandas/numpy、scikit‑learn、NumPyro/Stan/Statsmodels；R: lme4 用于快速 REML；消息队列或任务队列用于并行分配），并实现并行化估计与局部交换优化以满足 N≈3000、观测≈15000 的规模；（9）容错与人工交互：内置弃评补分配子例程与人工干预接口，规定何类边缘案例必须人工复核；（10）交付物：可运行的作业脚本/API、配置化阈值集合、性能评估报告、以及详尽的审计日志与使用手册，使操作方可在不参照其它文档下部署、运行、调整与审计整个闭环决策系统。"
  ]
}