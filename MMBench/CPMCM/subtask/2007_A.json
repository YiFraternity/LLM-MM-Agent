{
  "tasks": [],
  "problem_str": "问题背景：\n我国是一个拥有13亿人口的发展中国家，每天都在消费大量的各种食品，这批食品是由成千上万的食品加工厂、不可计数的小作坊、几亿农民生产出来的，并且经过较多的中间环节和长途运输后才为广大群众所消费，加之近年来我国经济发展迅速而环境治理没有能够完全跟上，以至环境污染形势十分严峻;而且随着我国进出口贸易的迅速增加，加上某些国外媒体的炒作，对外食品贸易中的矛盾也开始尖锐起来，因此建立包括食品卫生安全保障体系在内的公共安全应急机制是关系国计民生和对外贸易的重大而迫切的任务。\n\n据初步了解，目前美国和欧盟对公共食品卫生安全实行监控的做法是建立膳食暴露评估数学模型并制成软件，只要将有关的调查或检测数据输入软件，就可以对当时的公共食品卫生安全做出评估。它们所采用的膳食暴露评估数学模型根据现有资料看是分成人群食物摄入量模型、污染物分布模型、风险评估模型三部分。其中人群食物摄入量模型（膳食模型）是用于估计不同地区、不同性别、不同年龄、不同季节、不同劳动强度、不同经济收入的人群各类食品的一天摄入量；污染物分布模型是根据农药、化工等污染行业的污染物排放数据和食品卫生安全监测部门日常对水、农贸市场和大宗食品中污染物的抽查数据以及进出口口岸的检测数据来估计各类食物中各种污染物的含量；风险评估模型则根据前两个模型所提供的数据计算得出全国或某地区人群某些污染物每天摄入量的99.999%的右分位点（把每个人每天某种污染物摄入量看成是一个随机变量），从而能够对某一时刻食品安全风险作出评估。该模型的目标是保证绝大多数（99.999%以上）居民的食品安全,但重点却在对高暴露人群(即污染物摄入量比较大的人群)的监控上,而不仅是居民污染物的平均摄入量。如果用数学的语言严格地表述，就是如果把每个人每天某种污染物摄入量看成是一个随机变量，则我们关心的不仅是它的均值，更关心的是它的99.999%的右分位点。如果这个右分位点的数值明显地小于由食品卫生安全主管部门制定的、经过大量试验被证明是安全的标准，则我们就有比较充分的理由相信目前的食品卫生状况是安全的。当然这个右分位点相对于上述标准能够再向左一些，就能够保证更多居民的食品安全。很可惜美国和欧盟向外提供的软件只是一个黑箱，我们无法断定这个黑箱是否合乎我国的实际情况，对他们的数学模型也从加以考证。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n人群食物摄入量模型可以根据我国总膳食数据来建立，这批数据应该由调查人员入户调查获得，让调查人员事先进入被确定为调查对象的家庭，对居民家里的大米、面粉、食油、食盐，糖等全部食品进行称重并加以记录，几天后再来到这户居民家中并将他们家里的大米、面粉、食油、食盐，糖等全部食品称重，将两次结果相减就可以得出这户居民在这几天中所消费的各类食品的总量，并对没有称重的食品，如蔬菜、水等的消费情况也进行登记；再将调查所得的全部统计数据汇总就得到我国总膳食数据的抽样结果。由于这项调查工作量太大，如果实行普查，其工作量甚至超过全国人口普查，故而只可能在全国几亿户家庭中随机抽取几千户，至多几万户进行一次性调查。因此如何设计抽样调查方案使调查结果能尽量反映全国的实际情况，调查结果的数据使用起来效果比较理想，同时使调查的全部工作量在可以承受的范围内，是一项困难的任务。这项工作的另一个难点在于中国居民消费的食品种类比其他国家居民消费的食品种类复杂得多，包括：主食、肉类、蔬菜、水果、水、饮料、各种调味剂和经过加工的食品，细分将达数千种以上，在实际调查过程中进行如此详细地分类，其调查工作量太大，而如果随意粗糙进行分类，则将影响调查的精度，因此需要根据污染物分布模型的数据合理设计抽样调查中食物的分类办法。这项工作的第三个任务是要用通过万分之一（甚至更小）的抽样率得到的数据建立起全国比较准确的人群食品摄入量模型，因此要确定合理的技术路线，充分利用从其他一切渠道可以获得的信息，可以并且应该建立不止一个这样的模型以满足各方面的需求。（这个问题只供感兴趣的研究生队选做，也完全可以不做）\n\n污染物分布模型主要是根据食品卫生监测部门日常对市场上食物的检测数据（包括例行监测数据和偶然抽查数据，符合性检验和监测性检验数据，前者的结果可能只是定性的，而后者检测的结果精度高）和市场上各类食品的流通量，此外还包括进出口口岸的检测数据来估计市场上各种食品的污染物含量。建立这个模型同样有以下几个难点：第一个难点是这里的数据也是抽样率很低的随机抽样的数据，否则工作量太大，且无法满足监测时间方面的要求，问题是我们应该怎样充分利用这批数据去建立模型？第二个难点是由于食品的季节性、区域性、多样性特点，日常监测无法获得详细的、完整的分类数据，问题是如何利用这些数据尽量提高模型的精度？第三个难点是由于监测时间方面的要求和经费的限制，在日常检测时往往采用比较快捷的检测方法，即符合性检验，其缺点是当检测项目的检测结果是安全时就不再精确测量污染物具体的含量了，而笼统地用“未检出”作为检测结果。这对判断这批食品是否安全而言是完全满足要求的，但作为污染物分布模型的输入而言，如果“未检出”全部当成零来计算就一定会产生比较大的误差，因此一定要改进。用数学的语言严格地描述就是要设法根据随机变量取值大于某一数值的部分样本数据再加上其他可以利用的信息（如通过大约占数据总量2%的偶然抽查数据所获得的小于等于同一数值的部分样本数据）估计出这个随机变量的整体分布。\n\n风险评估模型就是利用前两个模型的结果对全国、某个地区、某类食品的安全状况做出评价，对可能出现的食品安全事件给出预警。首先这个模型的输入都是抽样率很低的随机抽样的数据，而且这两批数据是不配套的，即人群食品摄入量模型中的调查对象极大可能不是污染物分布模型中被调查食品的消费者，如何根据上述两批结果建立模型？第二个难点是两个模型的数据分类也很可能不配套，人群食品摄入量模型中的食品很可能远多于污染物分布模型中被调查食品或者两者的分类不完全一致（历史数据无法按现在的要求进行修改），在模型中如何妥善处理这样的问题？第三个难点是这个模型要求给出全体居民某项污染物摄入量的99.999%的右分位点，你们的模型采用什么方法提高它的精度？\n\n从以上介绍的大致情况看，其中的确有一些严重的困难和问题，但美国和欧盟已经建立了有关模型并且开始使用，这说明他们已经根据他们的国情将上述困难解决或基本解决，当然也可能仍然含有一些缺陷或存在比较大的误差。\n\n问题要求：\n因此我们要建立食品卫生安全保障体系除按美国和欧盟的方法需要建立三个数学模型外，还希望提出有创造性的技术路线（如食品卫生安全保障体系数学模型的全新的整体设计方案，调查数据的总体结构和调查方案，如何综合利用一切有用信息等等），同时迫切需要研究、解决大量的理论问题。例如：1.污染物含量的分布显然不是正态分布而且很可能是左偏态的，因为污染物含量总是非负的，显然污染物含量越高则概率密度就越小，如何根据随机变量取值大于某一值的部分统计数据估计出随机变量（或向量）的概率分布函数，或者退一步仅求出其均值。2.两个不配套的抽样调查数据用什么方法去衔接使用并达到理想的效果，为启发思考，这里抛砖引玉，提出一种思路，例如认为两批抽样调查是完全独立进行的。3.在调查数据中统计分类标准不相同怎么转化，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从一些随机变量总体的并集中抽样得到的数据，并设法用它们来估计另一些随机变量（与前者部分相同，部分不同）总体的并集的概率分布函数。4.当需要利用某些省、市的日常监测数据来估计全国的情况时也面临着两者的概率分布函数可能并不相同的问题，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从若干个比较相近的总体的并集中有一定选择性地抽样所获得的数据，并用来估计这若干个有比较大共性的总体的并的概率分布函数。这里的难点是我们对比较多的情况都掌握得并不十分清楚，因此你们不妨做出一些必要、合理的假设，并在此基础上进行详细的分析。此外，我们现在没有而且在竞赛的短短几天内也无法使用大规模的调查数据，而建立数学模型又离不开数据，但我们相信参赛的研究生队完全能够创造性地解决这一困难。",
  "problem": {
    "background": "我国是一个拥有13亿人口的发展中国家，每天都在消费大量的各种食品，这批食品是由成千上万的食品加工厂、不可计数的小作坊、几亿农民生产出来的，并且经过较多的中间环节和长途运输后才为广大群众所消费，加之近年来我国经济发展迅速而环境治理没有能够完全跟上，以至环境污染形势十分严峻;而且随着我国进出口贸易的迅速增加，加上某些国外媒体的炒作，对外食品贸易中的矛盾也开始尖锐起来，因此建立包括食品卫生安全保障体系在内的公共安全应急机制是关系国计民生和对外贸易的重大而迫切的任务。\n\n据初步了解，目前美国和欧盟对公共食品卫生安全实行监控的做法是建立膳食暴露评估数学模型并制成软件，只要将有关的调查或检测数据输入软件，就可以对当时的公共食品卫生安全做出评估。它们所采用的膳食暴露评估数学模型根据现有资料看是分成人群食物摄入量模型、污染物分布模型、风险评估模型三部分。其中人群食物摄入量模型（膳食模型）是用于估计不同地区、不同性别、不同年龄、不同季节、不同劳动强度、不同经济收入的人群各类食品的一天摄入量；污染物分布模型是根据农药、化工等污染行业的污染物排放数据和食品卫生安全监测部门日常对水、农贸市场和大宗食品中污染物的抽查数据以及进出口口岸的检测数据来估计各类食物中各种污染物的含量；风险评估模型则根据前两个模型所提供的数据计算得出全国或某地区人群某些污染物每天摄入量的99.999%的右分位点（把每个人每天某种污染物摄入量看成是一个随机变量），从而能够对某一时刻食品安全风险作出评估。该模型的目标是保证绝大多数（99.999%以上）居民的食品安全,但重点却在对高暴露人群(即污染物摄入量比较大的人群)的监控上,而不仅是居民污染物的平均摄入量。如果用数学的语言严格地表述，就是如果把每个人每天某种污染物摄入量看成是一个随机变量，则我们关心的不仅是它的均值，更关心的是它的99.999%的右分位点。如果这个右分位点的数值明显地小于由食品卫生安全主管部门制定的、经过大量试验被证明是安全的标准，则我们就有比较充分的理由相信目前的食品卫生状况是安全的。当然这个右分位点相对于上述标准能够再向左一些，就能够保证更多居民的食品安全。很可惜美国和欧盟向外提供的软件只是一个黑箱，我们无法断定这个黑箱是否合乎我国的实际情况，对他们的数学模型也从加以考证。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n人群食物摄入量模型可以根据我国总膳食数据来建立，这批数据应该由调查人员入户调查获得，让调查人员事先进入被确定为调查对象的家庭，对居民家里的大米、面粉、食油、食盐，糖等全部食品进行称重并加以记录，几天后再来到这户居民家中并将他们家里的大米、面粉、食油、食盐，糖等全部食品称重，将两次结果相减就可以得出这户居民在这几天中所消费的各类食品的总量，并对没有称重的食品，如蔬菜、水等的消费情况也进行登记；再将调查所得的全部统计数据汇总就得到我国总膳食数据的抽样结果。由于这项调查工作量太大，如果实行普查，其工作量甚至超过全国人口普查，故而只可能在全国几亿户家庭中随机抽取几千户，至多几万户进行一次性调查。因此如何设计抽样调查方案使调查结果能尽量反映全国的实际情况，调查结果的数据使用起来效果比较理想，同时使调查的全部工作量在可以承受的范围内，是一项困难的任务。这项工作的另一个难点在于中国居民消费的食品种类比其他国家居民消费的食品种类复杂得多，包括：主食、肉类、蔬菜、水果、水、饮料、各种调味剂和经过加工的食品，细分将达数千种以上，在实际调查过程中进行如此详细地分类，其调查工作量太大，而如果随意粗糙进行分类，则将影响调查的精度，因此需要根据污染物分布模型的数据合理设计抽样调查中食物的分类办法。这项工作的第三个任务是要用通过万分之一（甚至更小）的抽样率得到的数据建立起全国比较准确的人群食品摄入量模型，因此要确定合理的技术路线，充分利用从其他一切渠道可以获得的信息，可以并且应该建立不止一个这样的模型以满足各方面的需求。（这个问题只供感兴趣的研究生队选做，也完全可以不做）\n\n污染物分布模型主要是根据食品卫生监测部门日常对市场上食物的检测数据（包括例行监测数据和偶然抽查数据，符合性检验和监测性检验数据，前者的结果可能只是定性的，而后者检测的结果精度高）和市场上各类食品的流通量，此外还包括进出口口岸的检测数据来估计市场上各种食品的污染物含量。建立这个模型同样有以下几个难点：第一个难点是这里的数据也是抽样率很低的随机抽样的数据，否则工作量太大，且无法满足监测时间方面的要求，问题是我们应该怎样充分利用这批数据去建立模型？第二个难点是由于食品的季节性、区域性、多样性特点，日常监测无法获得详细的、完整的分类数据，问题是如何利用这些数据尽量提高模型的精度？第三个难点是由于监测时间方面的要求和经费的限制，在日常检测时往往采用比较快捷的检测方法，即符合性检验，其缺点是当检测项目的检测结果是安全时就不再精确测量污染物具体的含量了，而笼统地用“未检出”作为检测结果。这对判断这批食品是否安全而言是完全满足要求的，但作为污染物分布模型的输入而言，如果“未检出”全部当成零来计算就一定会产生比较大的误差，因此一定要改进。用数学的语言严格地描述就是要设法根据随机变量取值大于某一数值的部分样本数据再加上其他可以利用的信息（如通过大约占数据总量2%的偶然抽查数据所获得的小于等于同一数值的部分样本数据）估计出这个随机变量的整体分布。\n\n风险评估模型就是利用前两个模型的结果对全国、某个地区、某类食品的安全状况做出评价，对可能出现的食品安全事件给出预警。首先这个模型的输入都是抽样率很低的随机抽样的数据，而且这两批数据是不配套的，即人群食品摄入量模型中的调查对象极大可能不是污染物分布模型中被调查食品的消费者，如何根据上述两批结果建立模型？第二个难点是两个模型的数据分类也很可能不配套，人群食品摄入量模型中的食品很可能远多于污染物分布模型中被调查食品或者两者的分类不完全一致（历史数据无法按现在的要求进行修改），在模型中如何妥善处理这样的问题？第三个难点是这个模型要求给出全体居民某项污染物摄入量的99.999%的右分位点，你们的模型采用什么方法提高它的精度？\n\n从以上介绍的大致情况看，其中的确有一些严重的困难和问题，但美国和欧盟已经建立了有关模型并且开始使用，这说明他们已经根据他们的国情将上述困难解决或基本解决，当然也可能仍然含有一些缺陷或存在比较大的误差。",
    "problem_requirement": "因此我们要建立食品卫生安全保障体系除按美国和欧盟的方法需要建立三个数学模型外，还希望提出有创造性的技术路线（如食品卫生安全保障体系数学模型的全新的整体设计方案，调查数据的总体结构和调查方案，如何综合利用一切有用信息等等），同时迫切需要研究、解决大量的理论问题。例如：1.污染物含量的分布显然不是正态分布而且很可能是左偏态的，因为污染物含量总是非负的，显然污染物含量越高则概率密度就越小，如何根据随机变量取值大于某一值的部分统计数据估计出随机变量（或向量）的概率分布函数，或者退一步仅求出其均值。2.两个不配套的抽样调查数据用什么方法去衔接使用并达到理想的效果，为启发思考，这里抛砖引玉，提出一种思路，例如认为两批抽样调查是完全独立进行的。3.在调查数据中统计分类标准不相同怎么转化，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从一些随机变量总体的并集中抽样得到的数据，并设法用它们来估计另一些随机变量（与前者部分相同，部分不同）总体的并集的概率分布函数。4.当需要利用某些省、市的日常监测数据来估计全国的情况时也面临着两者的概率分布函数可能并不相同的问题，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从若干个比较相近的总体的并集中有一定选择性地抽样所获得的数据，并用来估计这若干个有比较大共性的总体的并的概率分布函数。这里的难点是我们对比较多的情况都掌握得并不十分清楚，因此你们不妨做出一些必要、合理的假设，并在此基础上进行详细的分析。此外，我们现在没有而且在竞赛的短短几天内也无法使用大规模的调查数据，而建立数学模型又离不开数据，但我们相信参赛的研究生队完全能够创造性地解决这一困难。",
    "dataset_path": [],
    "dataset_description": {},
    "variable_description": [],
    "addendum": "",
    "data_summary": "",
    "data_description": {},
    "problem_str": "问题背景：\n我国是一个拥有13亿人口的发展中国家，每天都在消费大量的各种食品，这批食品是由成千上万的食品加工厂、不可计数的小作坊、几亿农民生产出来的，并且经过较多的中间环节和长途运输后才为广大群众所消费，加之近年来我国经济发展迅速而环境治理没有能够完全跟上，以至环境污染形势十分严峻;而且随着我国进出口贸易的迅速增加，加上某些国外媒体的炒作，对外食品贸易中的矛盾也开始尖锐起来，因此建立包括食品卫生安全保障体系在内的公共安全应急机制是关系国计民生和对外贸易的重大而迫切的任务。\n\n据初步了解，目前美国和欧盟对公共食品卫生安全实行监控的做法是建立膳食暴露评估数学模型并制成软件，只要将有关的调查或检测数据输入软件，就可以对当时的公共食品卫生安全做出评估。它们所采用的膳食暴露评估数学模型根据现有资料看是分成人群食物摄入量模型、污染物分布模型、风险评估模型三部分。其中人群食物摄入量模型（膳食模型）是用于估计不同地区、不同性别、不同年龄、不同季节、不同劳动强度、不同经济收入的人群各类食品的一天摄入量；污染物分布模型是根据农药、化工等污染行业的污染物排放数据和食品卫生安全监测部门日常对水、农贸市场和大宗食品中污染物的抽查数据以及进出口口岸的检测数据来估计各类食物中各种污染物的含量；风险评估模型则根据前两个模型所提供的数据计算得出全国或某地区人群某些污染物每天摄入量的99.999%的右分位点（把每个人每天某种污染物摄入量看成是一个随机变量），从而能够对某一时刻食品安全风险作出评估。该模型的目标是保证绝大多数（99.999%以上）居民的食品安全,但重点却在对高暴露人群(即污染物摄入量比较大的人群)的监控上,而不仅是居民污染物的平均摄入量。如果用数学的语言严格地表述，就是如果把每个人每天某种污染物摄入量看成是一个随机变量，则我们关心的不仅是它的均值，更关心的是它的99.999%的右分位点。如果这个右分位点的数值明显地小于由食品卫生安全主管部门制定的、经过大量试验被证明是安全的标准，则我们就有比较充分的理由相信目前的食品卫生状况是安全的。当然这个右分位点相对于上述标准能够再向左一些，就能够保证更多居民的食品安全。很可惜美国和欧盟向外提供的软件只是一个黑箱，我们无法断定这个黑箱是否合乎我国的实际情况，对他们的数学模型也从加以考证。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n人群食物摄入量模型可以根据我国总膳食数据来建立，这批数据应该由调查人员入户调查获得，让调查人员事先进入被确定为调查对象的家庭，对居民家里的大米、面粉、食油、食盐，糖等全部食品进行称重并加以记录，几天后再来到这户居民家中并将他们家里的大米、面粉、食油、食盐，糖等全部食品称重，将两次结果相减就可以得出这户居民在这几天中所消费的各类食品的总量，并对没有称重的食品，如蔬菜、水等的消费情况也进行登记；再将调查所得的全部统计数据汇总就得到我国总膳食数据的抽样结果。由于这项调查工作量太大，如果实行普查，其工作量甚至超过全国人口普查，故而只可能在全国几亿户家庭中随机抽取几千户，至多几万户进行一次性调查。因此如何设计抽样调查方案使调查结果能尽量反映全国的实际情况，调查结果的数据使用起来效果比较理想，同时使调查的全部工作量在可以承受的范围内，是一项困难的任务。这项工作的另一个难点在于中国居民消费的食品种类比其他国家居民消费的食品种类复杂得多，包括：主食、肉类、蔬菜、水果、水、饮料、各种调味剂和经过加工的食品，细分将达数千种以上，在实际调查过程中进行如此详细地分类，其调查工作量太大，而如果随意粗糙进行分类，则将影响调查的精度，因此需要根据污染物分布模型的数据合理设计抽样调查中食物的分类办法。这项工作的第三个任务是要用通过万分之一（甚至更小）的抽样率得到的数据建立起全国比较准确的人群食品摄入量模型，因此要确定合理的技术路线，充分利用从其他一切渠道可以获得的信息，可以并且应该建立不止一个这样的模型以满足各方面的需求。（这个问题只供感兴趣的研究生队选做，也完全可以不做）\n\n污染物分布模型主要是根据食品卫生监测部门日常对市场上食物的检测数据（包括例行监测数据和偶然抽查数据，符合性检验和监测性检验数据，前者的结果可能只是定性的，而后者检测的结果精度高）和市场上各类食品的流通量，此外还包括进出口口岸的检测数据来估计市场上各种食品的污染物含量。建立这个模型同样有以下几个难点：第一个难点是这里的数据也是抽样率很低的随机抽样的数据，否则工作量太大，且无法满足监测时间方面的要求，问题是我们应该怎样充分利用这批数据去建立模型？第二个难点是由于食品的季节性、区域性、多样性特点，日常监测无法获得详细的、完整的分类数据，问题是如何利用这些数据尽量提高模型的精度？第三个难点是由于监测时间方面的要求和经费的限制，在日常检测时往往采用比较快捷的检测方法，即符合性检验，其缺点是当检测项目的检测结果是安全时就不再精确测量污染物具体的含量了，而笼统地用“未检出”作为检测结果。这对判断这批食品是否安全而言是完全满足要求的，但作为污染物分布模型的输入而言，如果“未检出”全部当成零来计算就一定会产生比较大的误差，因此一定要改进。用数学的语言严格地描述就是要设法根据随机变量取值大于某一数值的部分样本数据再加上其他可以利用的信息（如通过大约占数据总量2%的偶然抽查数据所获得的小于等于同一数值的部分样本数据）估计出这个随机变量的整体分布。\n\n风险评估模型就是利用前两个模型的结果对全国、某个地区、某类食品的安全状况做出评价，对可能出现的食品安全事件给出预警。首先这个模型的输入都是抽样率很低的随机抽样的数据，而且这两批数据是不配套的，即人群食品摄入量模型中的调查对象极大可能不是污染物分布模型中被调查食品的消费者，如何根据上述两批结果建立模型？第二个难点是两个模型的数据分类也很可能不配套，人群食品摄入量模型中的食品很可能远多于污染物分布模型中被调查食品或者两者的分类不完全一致（历史数据无法按现在的要求进行修改），在模型中如何妥善处理这样的问题？第三个难点是这个模型要求给出全体居民某项污染物摄入量的99.999%的右分位点，你们的模型采用什么方法提高它的精度？\n\n从以上介绍的大致情况看，其中的确有一些严重的困难和问题，但美国和欧盟已经建立了有关模型并且开始使用，这说明他们已经根据他们的国情将上述困难解决或基本解决，当然也可能仍然含有一些缺陷或存在比较大的误差。\n\n问题要求：\n因此我们要建立食品卫生安全保障体系除按美国和欧盟的方法需要建立三个数学模型外，还希望提出有创造性的技术路线（如食品卫生安全保障体系数学模型的全新的整体设计方案，调查数据的总体结构和调查方案，如何综合利用一切有用信息等等），同时迫切需要研究、解决大量的理论问题。例如：1.污染物含量的分布显然不是正态分布而且很可能是左偏态的，因为污染物含量总是非负的，显然污染物含量越高则概率密度就越小，如何根据随机变量取值大于某一值的部分统计数据估计出随机变量（或向量）的概率分布函数，或者退一步仅求出其均值。2.两个不配套的抽样调查数据用什么方法去衔接使用并达到理想的效果，为启发思考，这里抛砖引玉，提出一种思路，例如认为两批抽样调查是完全独立进行的。3.在调查数据中统计分类标准不相同怎么转化，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从一些随机变量总体的并集中抽样得到的数据，并设法用它们来估计另一些随机变量（与前者部分相同，部分不同）总体的并集的概率分布函数。4.当需要利用某些省、市的日常监测数据来估计全国的情况时也面临着两者的概率分布函数可能并不相同的问题，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从若干个比较相近的总体的并集中有一定选择性地抽样所获得的数据，并用来估计这若干个有比较大共性的总体的并的概率分布函数。这里的难点是我们对比较多的情况都掌握得并不十分清楚，因此你们不妨做出一些必要、合理的假设，并在此基础上进行详细的分析。此外，我们现在没有而且在竞赛的短短几天内也无法使用大规模的调查数据，而建立数学模型又离不开数据，但我们相信参赛的研究生队完全能够创造性地解决这一困难。"
  },
  "problem_background": "我国是一个拥有13亿人口的发展中国家，每天都在消费大量的各种食品，这批食品是由成千上万的食品加工厂、不可计数的小作坊、几亿农民生产出来的，并且经过较多的中间环节和长途运输后才为广大群众所消费，加之近年来我国经济发展迅速而环境治理没有能够完全跟上，以至环境污染形势十分严峻;而且随着我国进出口贸易的迅速增加，加上某些国外媒体的炒作，对外食品贸易中的矛盾也开始尖锐起来，因此建立包括食品卫生安全保障体系在内的公共安全应急机制是关系国计民生和对外贸易的重大而迫切的任务。\n\n据初步了解，目前美国和欧盟对公共食品卫生安全实行监控的做法是建立膳食暴露评估数学模型并制成软件，只要将有关的调查或检测数据输入软件，就可以对当时的公共食品卫生安全做出评估。它们所采用的膳食暴露评估数学模型根据现有资料看是分成人群食物摄入量模型、污染物分布模型、风险评估模型三部分。其中人群食物摄入量模型（膳食模型）是用于估计不同地区、不同性别、不同年龄、不同季节、不同劳动强度、不同经济收入的人群各类食品的一天摄入量；污染物分布模型是根据农药、化工等污染行业的污染物排放数据和食品卫生安全监测部门日常对水、农贸市场和大宗食品中污染物的抽查数据以及进出口口岸的检测数据来估计各类食物中各种污染物的含量；风险评估模型则根据前两个模型所提供的数据计算得出全国或某地区人群某些污染物每天摄入量的99.999%的右分位点（把每个人每天某种污染物摄入量看成是一个随机变量），从而能够对某一时刻食品安全风险作出评估。该模型的目标是保证绝大多数（99.999%以上）居民的食品安全,但重点却在对高暴露人群(即污染物摄入量比较大的人群)的监控上,而不仅是居民污染物的平均摄入量。如果用数学的语言严格地表述，就是如果把每个人每天某种污染物摄入量看成是一个随机变量，则我们关心的不仅是它的均值，更关心的是它的99.999%的右分位点。如果这个右分位点的数值明显地小于由食品卫生安全主管部门制定的、经过大量试验被证明是安全的标准，则我们就有比较充分的理由相信目前的食品卫生状况是安全的。当然这个右分位点相对于上述标准能够再向左一些，就能够保证更多居民的食品安全。很可惜美国和欧盟向外提供的软件只是一个黑箱，我们无法断定这个黑箱是否合乎我国的实际情况，对他们的数学模型也从加以考证。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n我国建立食品卫生安全保障体系的时间还不长，根据国际上的热点和我国的国情，据初步估计，我国现阶段可能会集中力量对众多污染物中少数几种危害面广、后果严重的污染物，如：铅、镉、有机磷、有机氯等实行监控，其他污染物的监控工作则待时机成熟后再推广。因此我国肯定也需要建立膳食暴露评估数学模型，建立我国自己的膳食模型，在实施对污染物监控的同时，对公共食品卫生安全做出评估，并可以供领导决策时参考。\n\n人群食物摄入量模型可以根据我国总膳食数据来建立，这批数据应该由调查人员入户调查获得，让调查人员事先进入被确定为调查对象的家庭，对居民家里的大米、面粉、食油、食盐，糖等全部食品进行称重并加以记录，几天后再来到这户居民家中并将他们家里的大米、面粉、食油、食盐，糖等全部食品称重，将两次结果相减就可以得出这户居民在这几天中所消费的各类食品的总量，并对没有称重的食品，如蔬菜、水等的消费情况也进行登记；再将调查所得的全部统计数据汇总就得到我国总膳食数据的抽样结果。由于这项调查工作量太大，如果实行普查，其工作量甚至超过全国人口普查，故而只可能在全国几亿户家庭中随机抽取几千户，至多几万户进行一次性调查。因此如何设计抽样调查方案使调查结果能尽量反映全国的实际情况，调查结果的数据使用起来效果比较理想，同时使调查的全部工作量在可以承受的范围内，是一项困难的任务。这项工作的另一个难点在于中国居民消费的食品种类比其他国家居民消费的食品种类复杂得多，包括：主食、肉类、蔬菜、水果、水、饮料、各种调味剂和经过加工的食品，细分将达数千种以上，在实际调查过程中进行如此详细地分类，其调查工作量太大，而如果随意粗糙进行分类，则将影响调查的精度，因此需要根据污染物分布模型的数据合理设计抽样调查中食物的分类办法。这项工作的第三个任务是要用通过万分之一（甚至更小）的抽样率得到的数据建立起全国比较准确的人群食品摄入量模型，因此要确定合理的技术路线，充分利用从其他一切渠道可以获得的信息，可以并且应该建立不止一个这样的模型以满足各方面的需求。（这个问题只供感兴趣的研究生队选做，也完全可以不做）\n\n污染物分布模型主要是根据食品卫生监测部门日常对市场上食物的检测数据（包括例行监测数据和偶然抽查数据，符合性检验和监测性检验数据，前者的结果可能只是定性的，而后者检测的结果精度高）和市场上各类食品的流通量，此外还包括进出口口岸的检测数据来估计市场上各种食品的污染物含量。建立这个模型同样有以下几个难点：第一个难点是这里的数据也是抽样率很低的随机抽样的数据，否则工作量太大，且无法满足监测时间方面的要求，问题是我们应该怎样充分利用这批数据去建立模型？第二个难点是由于食品的季节性、区域性、多样性特点，日常监测无法获得详细的、完整的分类数据，问题是如何利用这些数据尽量提高模型的精度？第三个难点是由于监测时间方面的要求和经费的限制，在日常检测时往往采用比较快捷的检测方法，即符合性检验，其缺点是当检测项目的检测结果是安全时就不再精确测量污染物具体的含量了，而笼统地用“未检出”作为检测结果。这对判断这批食品是否安全而言是完全满足要求的，但作为污染物分布模型的输入而言，如果“未检出”全部当成零来计算就一定会产生比较大的误差，因此一定要改进。用数学的语言严格地描述就是要设法根据随机变量取值大于某一数值的部分样本数据再加上其他可以利用的信息（如通过大约占数据总量2%的偶然抽查数据所获得的小于等于同一数值的部分样本数据）估计出这个随机变量的整体分布。\n\n风险评估模型就是利用前两个模型的结果对全国、某个地区、某类食品的安全状况做出评价，对可能出现的食品安全事件给出预警。首先这个模型的输入都是抽样率很低的随机抽样的数据，而且这两批数据是不配套的，即人群食品摄入量模型中的调查对象极大可能不是污染物分布模型中被调查食品的消费者，如何根据上述两批结果建立模型？第二个难点是两个模型的数据分类也很可能不配套，人群食品摄入量模型中的食品很可能远多于污染物分布模型中被调查食品或者两者的分类不完全一致（历史数据无法按现在的要求进行修改），在模型中如何妥善处理这样的问题？第三个难点是这个模型要求给出全体居民某项污染物摄入量的99.999%的右分位点，你们的模型采用什么方法提高它的精度？\n\n从以上介绍的大致情况看，其中的确有一些严重的困难和问题，但美国和欧盟已经建立了有关模型并且开始使用，这说明他们已经根据他们的国情将上述困难解决或基本解决，当然也可能仍然含有一些缺陷或存在比较大的误差。",
  "problem_requirement": "因此我们要建立食品卫生安全保障体系除按美国和欧盟的方法需要建立三个数学模型外，还希望提出有创造性的技术路线（如食品卫生安全保障体系数学模型的全新的整体设计方案，调查数据的总体结构和调查方案，如何综合利用一切有用信息等等），同时迫切需要研究、解决大量的理论问题。例如：1.污染物含量的分布显然不是正态分布而且很可能是左偏态的，因为污染物含量总是非负的，显然污染物含量越高则概率密度就越小，如何根据随机变量取值大于某一值的部分统计数据估计出随机变量（或向量）的概率分布函数，或者退一步仅求出其均值。2.两个不配套的抽样调查数据用什么方法去衔接使用并达到理想的效果，为启发思考，这里抛砖引玉，提出一种思路，例如认为两批抽样调查是完全独立进行的。3.在调查数据中统计分类标准不相同怎么转化，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从一些随机变量总体的并集中抽样得到的数据，并设法用它们来估计另一些随机变量（与前者部分相同，部分不同）总体的并集的概率分布函数。4.当需要利用某些省、市的日常监测数据来估计全国的情况时也面临着两者的概率分布函数可能并不相同的问题，为启发思考，这里抛砖引玉，提出一种思路，是否可以把调查数据看成是从若干个比较相近的总体的并集中有一定选择性地抽样所获得的数据，并用来估计这若干个有比较大共性的总体的并的概率分布函数。这里的难点是我们对比较多的情况都掌握得并不十分清楚，因此你们不妨做出一些必要、合理的假设，并在此基础上进行详细的分析。此外，我们现在没有而且在竞赛的短短几天内也无法使用大规模的调查数据，而建立数学模型又离不开数据，但我们相信参赛的研究生队完全能够创造性地解决这一困难。",
  "problem_analysis": "这个题目的本质是一项典型的大规模、不完全观测、异质性强且以极值为关注点的概率统计与决策问题；其最终目标既有技术层面的：以有限抽样数据估计并量化“人群对某些污染物的膳食暴露分布”（特别是极端右尾，如99.999%分位点）——以便判断是否超出安全阈值；又有制度层面的：为食品卫生监管与应急决策提供可解释、可追溯并能量化不确定性的评估结果。这个目标直接决定了解题思路必须同时兼顾三个核心模块并重视它们之间的耦合：人群食物摄入的“需求侧”模型、食品中污染物浓度的“供给侧”分布模型，以及把二者组合后得到的暴露与风险的“合成/风险评估”模块。实现这些目标的关键思路是把不配套、稀疏、带删失的数据通过合理的统计建模与外部信息融合（包括监管检测记录、进出口与流通量数据、生产地与季节性指标、人口结构与消费统计等）转化为可用于个体或合成总体的概率分布，从而在可量化不确定性的前提下对极端暴露进行推断与决策支持。\n\n为清晰化后续分析，需要把题目文本中显性与隐含的假设点明并批判性地讨论。一方面存在必要的理想化假设：抽样是随机的或可通过加权校正使之近似代表总体；食品分类之间可以建立可映射的对应关系；污染物在同类食品中具有可借力估计的相似性（即可用分层或层级模型“借强度”）；个体摄入量与食品污染浓度在统计上可视为独立或可通过可观测协变量建模关联。另一方面这些假设可能是不成立或仅部分成立：实际监测数据的抽样设计往往非完全随机、存在选择性偏倚（例如高风险区域或进口口岸被重点抽检）；“未检出”并非真零而是低于检出限（左删失/区间删失），若盲目以0或LOD/2替换将严重低估总体暴露；食品分类不一致可能导致信息丢失或误配；个体对某类食品的偏好与其消费来源（本地生产 vs 进口）相关，从而消费量与污染浓度并非独立。上述假设的偏离会在不同环节非线性放大，尤其对极端分位点的估计影响极大，因此模型设计必须把这些偏差与不确定性显式建模并在结果中反映。\n\n针对各模块的技术挑战与可行思路需要深入展开。人群食物摄入方面，应区分常规主食（几乎日常消费、样本稠密）与偶发食品（零膳食率、高零膨胀）：对前者可用日常调查平均量或多日重复测量估计“usual intake”，对后者应采用两部分模型（消费概率模型+条件消费量模型），并用混合效应模型刻画个体内与个体间变异。现成方法包括国家饮食研究中使用的NCI方法、日常化摄入估计与多日重复测量的去日内变异技术、以及小区/分层权重校准（raking、post-stratification）以把样本扩展到全国人口结构。污染物分布方面必须针对“低检测限”和“未检出”采用删失数据的似然建模或多重插补而非简单替换；分布通常高度右偏，可用对数变换后的连续分布、或更加稳健的半参数／分段模型来描述；为提高估计精度，应采用层级贝叶斯框架在食品类别、产地、季节与检测方法之间借用信息，同时引入检测限信息、符合性检验与偶然抽查的不同精度水平。两者合成时传统做法是蒙特卡洛微观模拟：为每个合成个体先抽取食品摄入量，再抽取对应食品浓度，计算个体暴露并积累为总体分布；这种方法需要确保摄入与浓度抽样在条件上与真实世界相符（例如按地域、购买渠道、消费习惯联合抽样），否则独立抽样会低估或高估尾部概率。\n\n关于极端分位数（例如99.999%）的估计，这一要求在统计学上是非常苛刻的：所需的信息量之大远超常规样本，因此必须采用带结构的外推策略而非完全非参数方法。两类互补手段值得考虑：在样本中能观测到的高位段使用极值理论（EVT）的阶段性方法，如阈值上极值的广义帕累托分布（GPD）拟合；不足样本的极端处则依赖带有可识别参数的半参或参数化尾模型（例如对数正态尾、布莱克斯通混合模型或Pareto尾），并且用贝叶斯先验融合外部信息以获得可靠的不确定度评估。计算层面应使用重要性抽样或重采样方法来准确估计极端分位点的置信区间；若用贝叶斯，需关注先验敏感性并做情景分析。值得强调的是，对99.999%分位点的推断几乎总是高度不确定的，因此在决策上应与政策制定者约定容忍度，可能采用保守原则（例如估计上限或采用上置信界）以保障公共安全。\n\n数据不配套与分类不一致是贯穿全题的结构性难题。一个可行的总体策略是构建“合成微观总体”或“模拟人口”（synthetic population）作为桥梁：基于人口普查与消费结构统计、零售销售与流通数据、以及小样本的家庭日记调查，运用多层次回归与后分层（MRP）生成各人口子群（按省、市、城乡、年龄、职业等）的个体消费分布。然后把污染物检测数据通过食品类别映射、产地匹配与购买渠道比率映射到这些子群的食品来源结构中，使用层级模型把区域性或类别间的差异建模并估计出条件浓度分布。对分类不一致的情形，可以建立一个食品分类的“转移矩阵”或分解比例表（concordance matrix），该矩阵可从少量详细调查、行业统计或专家知识中估计，用于把一种分类下的浓度分布分配到另一种摄入分类上；此步骤最好以概率方式实现（多重插补或贝叶斯分配），并把由此引入的不确定性纳入最终暴露分布的置信区间。\n\n在把两批独立抽样数据结合时，统计学上有两种思想路径：以设计为基础的加权推断与以模型为基础的融合推断。设计为基础的做法保留每一数据源的抽样权重并进行校准合并，但对不配套的变量（例如不同分类）处理乏力。模型为基础的做法通过层级贝叶斯或潜变量框架把不同数据源看成对同一或重叠总体的观测，并引入测量误差、选择性抽样机制与数据源特有偏差项来联合拟合，这能显著借力信息但同时依赖模型假设；实践中应通过模型诊断、后验预测检查以及敏感性分析来评估模型对关键假设（独立性、同质性、尾部模型形式、映射矩阵）的脆弱性。\n\n问题的动态性与尺度效应也不容忽视。一方面污染物浓度与食品流通具有明显的时间性（季节性收获、突发污染事件、进口批次等）和空间性（地区差异、局部污染点）。因此模型需要时间序列或状态空间扩展以支持短期预警与长期趋势分析；若把历史监测与当期抽样结合，应该允许参数随时间漂移并采用卡尔曼滤波或贝叶斯在线更新机制以实现“渐进学习”。另一方面个体饮食模式会随营养政策、价格变动与城市化演化，长期暴露评估应考虑替代性情景分析。对监管决策有用的不是单一点估计，而是一套情景化的风险边界：在不同假设（如采样偏差存在与否、尾部分布形式、消费-浓度相关结构）下给出暴露上下界并据此设计补充监测或重点抽样策略。\n\n在方法选择与不确定性管理上，需要一个可操作的权衡原则。非参数方法稳健但在尾部无力；强参数方法在小样本下可输出看似精确的极端分位数但高度依赖模型选型；层级贝叶斯便于信息融合与不确定性传播但计算复杂且需谨慎选择先验。实践建议采纳混合策略：对中低分位采用较少假设的半参或非参估计并用自助法估计不确定性；对高分位采用基于EVT的尾部模型并用贝叶斯或蒙特卡罗技术稳健评估尾部不确定性；始终以情景分析（包括极端但合理的偏差情形）为补充。同时，需建立模型验证与更新机制：用可获得的外部资料（如突发事件后实测暴露、独立小样本调查）对模型预测进行回测，若偏差显著则按证据调整模型结构或采样方案。\n\n最后，建模过程应被设计为一个迭代、开放并能为政策制定提供优先级指引的工程而非一次性学术推导。初期可采用可解释且保守的模型为监管提供基线预警，同时并行部署目标性抽样计划（基于模型识别的高风险群体与边界不确定区域）以填补信息空白并在后续轮次中用新数据递归更新模型。信息透明化——把关键假设、敏感性分析与不确定区间随评估一并报告——对于政策沟通与公众信任至关重要。综合而言，技术路径应以层级贝叶斯/半参数混合为主干，配合删失数据的似然处理、两段消费模型、EVT尾部建模、合成微观人口与后分层校准，以及明确的模型诊断与逐步更新机制，为我国建立可操作、可验证并能量化不确定性的食品卫生膳食暴露评估体系奠定基础。",
  "modeling_solution": "为了解决上述食品卫生膳食暴露评估中的稀疏抽样、分类不一致、删失观测与极端右尾推断等核心难题，我提出一个集成化、层级化且可动态自适应的数学建模框架（下称综合模型）。该框架由三大模块组成并通过若干桥接结构耦合：一是人群食物摄入（膳食）模型，用以估计不同人口子群的“常态摄入分布”及个体日变异；二是食品中污染物浓度的分布模型，显式处理检测限下删失、不同数据源与区域/季节异质性；三是风险合成与极端分位估计模块，基于蒙特卡洛微观模拟并在尾部采用极值理论（EVT）及重要性抽样进行外推与不确定性量化。整个模型以层级贝叶斯为主干，结合半参数方法与数据驱动的映射矩阵，实现不同数据源、不完全配套分类与抽样偏差的融合，并通过自适应抽样与信息价值最大化引导后续监测。\n\n模型的基本假设如下。第一，人口可分为若干分层（按省/市、城乡、年龄、性别、劳动强度、收入等）且每一分层内个体的消费与食品来源结构在短期内近似平稳；第二，食品分类之间存在可估的概率性映射矩阵（concordance matrix），可从少量详细调查、流通/销售数据或专家知识以多重插补方式估计并将不确定性纳入传播；第三，污染物浓度在同一食品类别/产地/季节下服从某种右偏分布（例如对数正态或伽玛），但尾部可由广义帕累托分布（GPD）进行建模；第四，“未检出”是因检测限（LOD）导致的左删失，应用删失似然而非简单替换；第五，摄入量与污染浓度在总体上可能相关，但在缺乏配对样本时可通过共享协变量（地域、购买渠道、季节、价格）和潜变量耦合，若有证据则用Copula或回归模型刻画依赖结构；第六，抽样可能存在选择性偏差（例如重点抽检高风险区域），该选择机制可以参数化并纳入观测模型以校正偏倚。\n\n符号与变量定义（核心）：对任意个体 i，食品类别 j（按膳食模型定义的分类标准），数据源标识 s，区域 r，时间 t，定义 X_{i,j,t} 为个体 i 在日 t 对食品 j 的摄入量（克/日）；对于某一具体样本批次 k 属于食品类别 j，定义 C_{j,k,t} 为该批次中污染物浓度（单位: mg/kg 或 μg/kg）；个体 i 当日的污染物总暴露 E_{i,t} = sum_j X_{i,j,t} * C_{j,source(i,j),t}，其中 source(i,j) 表示该食品来源（本地、进口、加工厂编号等）；人口分层索引 g(i) 对应个体所属的分层。检测限为 LOD_{j,s}（可能依检测方法和数据源不同而异）。映射矩阵 M 将污染物浓度按数据源的食品分类映射到摄入数据的食品分类；M 的每一列为对应概率向量，满足列和为1。\n\n膳食模型的结构采用两部分模型（two-part model）以处理零膳食与条件摄入量的不对称性。具体地，对每个分层 g 和食品 j，在日 t 的消费概率 p_{g,j,t} 用Logit(p_{g,j,t}) = Z_{g,j,t}^T theta_{p} 的广义线性模型表示，其中 Z 包括季节、工资水平、价格、地域等协变量；条件摄入量 A_{i,j,t}（在消费发生时）在对数尺度上服从混合效应模型 log A_{i,j,t} ~ Normal(mu_{A,g,j,t} + b_i, sigma_{A,g,j}^2)，其中 b_i 表示个体随机效应以刻画个体间长期偏好，且可由若干重复测量估计出个体内与个体间变差比（用于得到usual intake）。因此 X_{i,j,t} = Bernoulli(p_{g,j,t}) * A_{i,j,t}。分层参数 mu_{A,g,j,t} 可以进一步以层级形式建模：mu_{A,g,j,t} = alpha_{A,j} + beta_{A,r(g)} + gamma_{A,season(t)} + delta_{A}^T W_{g,t}，并对 alpha, beta, gamma 施以弱信息性先验以实现借强度（shrinkage）。\n\n污染物分布模型采用删失似然与层级结构来处理左删失、方法差异和空间/时间异质性。对某食品类别 j、区域 r、时间 t，设对数浓度 Y = log C。若观测值 y > log(LOD_{j,s})，则观测似然是 y ~ Normal(mu_{C,j,r,t}, sigma_{C,j,r}^2)；若观测被左删失（未检出），则贡献为 P(Y ≤ log(LOD)) = Phi((log(LOD)-mu)/sigma)。mu_{C,j,r,t} 自身以层级模型建模：mu_{C,j,r,t} = alpha_{C,j} + beta_{C,r} + gamma_{C,season} + eta_{C,method(s)} + epsilon_{t}，其中 beta_{C,r} 为区域效应，eta 捕捉检测方法系统差异，epsilon_{t} 捕捉短期漂移。对于具有明显厚尾的类别，在高阈值 u_{j}之上对超额量 Y-u 采用广义帕累托分布（GPD）建模：P(Y-u > y | Y>u) ≈ GPD(kappa_{j,r}, sigma_{GPD,j,r})，并以贝叶斯层级方式估计kappa与sigma，以便尾部外推。检测方法的不同精度通过观测误差层加入模型：观测值 y_obs = y_true + e_method，e_method ~ Normal(0, tau_{method}^2)。\n\n针对分类不一致，构造食品分类映射矩阵 M。若数据源 A 的分类是 {a1,...,a_m}，膳食模型的分类是 {b1,...,b_n}，则设有概率转移矩阵 M_{m×n}，元素 m_{pq} = P(source category = ap 贡献给 intake category = bq)。M 的每列满足多项分配约束，先验可设为Dirichlet，若存在少量详细映射数据则以贝叶斯更新。通过对浓度分布按 M 进行概率性分配，可以将浓度数据从源分类投影到摄入分类，并将映射不确定性一并传播。若流通量或贸易流数据可用，可将 M 中的概率由销售权重或流向矩阵校准。\n\n当两批数据（摄入与浓度）不配套时，采用合成微观人口（synthetic population）和数据融合。首先基于人口普查与消费统计、家庭日记与零售销售数据，用后分层（post-stratification）或多层回归与后分层（MRP）方法生成分层 g 的代表性“虚拟个体”样本，每个虚拟个体带有协变量（地域、渠道偏好、购买频率）。然后根据该虚拟个体的购买渠道与食品来源分布从污染物分布模型抽取相应的浓度样本（通过映射矩阵 M 和区域/季节条件），从而产生配对的 (X,C) 样本，计算暴露 E。为刻画消费-浓度可能存在的相关性，可在抽样时使用条件分布 P(C | source, g, season, price) 并在必要时采用Copula模型将摄入量与浓度在协变量条件下联合模拟。\n\n暴露合成与极端分位估计通过大规模蒙特卡洛微观模拟实现：对每一虚拟个体 i 的每一天 t，先从膳食模型抽取消费事件及数量 X_{i,j,t}，再为每个食品来源抽取相应浓度 C_{j,source,t}（注意此处若同一批次食品供应多名消费者，则可建批次依赖结构），然后计算个体暴露 E_{i,t} 并累积生成总体暴露分布。为了准确估计极端分位数（例如99.999%），在尾部采用阈值法（POT）拟合GPD：选择阈值 u（通过均衡偏差-方差的诊断图与稳定性分析），在样本超阈部分拟合GPD并对超过样本观测范围的分位进行外推。由于样本在尾部信息稀薄，采用贝叶斯估计以融合外部先验（如相似食品的历史尾指数、毒理学知识）并得到后验分布。为了提高估计效率，使用重要性抽样集中模拟在高暴露区域：在抽样时对多因素（高消费量、高浓度来源）施加倾斜采样并用相应的权重校正，配合自适应重采样以控制方差。极端分位的不确定度通过后验样本或引导法/bootstrap与重要性重加权联合估计，报告点估计与上置信界（例如95%上界）以满足监管保守原则。\n\n模型融合与选择性抽样的校正通过联合建模实现：将每个数据源的抽样机制显式建模为选择概率 s_{d} = logit^{-1}(psi_d^T W_d)。若发现抽样并非随机，可在似然中引入选择权重或直接联合估计 psi_d 并以逆概率加权（IPW）或模型校正方法修正参数估计。对于观测精度不同的数据（例行符合性检验 vs 偶然抽查的定量数据），在模型中分别设定不同的观测方差并用层级结构估计它们的相对信赖度，从而在信息整合时自动加权。\n\n计算求解策略及可行实现。整体模型因层级复杂且含删失与混合分布，建议采用贝叶斯推断以自然传播不确定性。首选使用Hamiltonian Monte Carlo（如Stan）或基于NUTS的实现进行参数后验抽样，对于维度极高或需要快速响应的场景可使用变分推断（VI）作为近似。对尾部参数的GPD拟合与重要性抽样，建议将这部分作为独立子模型并用专门的极值套件估计参数，再将后验样本并入主模型的蒙特卡洛流程。为减轻计算负担，可采取下列策略：对食品类别、区域与时间进行分层并行化计算；对不重要或信息稀薄的子模型采用弱参数化或共享参数（参数池化）；使用代理模型（例如Gaussian Process或多项式回归）逼近膳食-浓度映射以替代昂贵的嵌套采样；对重复性高的微观模拟采用重要性抽样与多重重用（reuse）以降低模拟次数。计算资源方面，建议在集群或云平台部署并行MCMC，对极端分位估计与自适应抽样阶段使用GPU加速的并行抽样器。期望精度以监管需求为导向：对中低分位（≤95%）目标达到相对误差小于10%，而对类似99.999%此类极端分位，因信息不足，重点提供后验上界与不确定区间，而非单一精确点估计，权衡稳健性和可用性。\n\n模型的动态适应与校准。模型应设计为可在线更新：每次获得新的监测数据或专项抽样结果，使用贝叶斯后验更新原则即时修正后验分布（可采用Sequential Monte Carlo/particle filter或周期性MCMC重估）。对时间演变，引入状态空间模型或随机游走成分（例如 mu_{C,j,r,t+1} = mu_{C,j,r,t} + nu_{j,r,t}, nu~N(0,sigma_nu^2)）以捕捉长期趋势或突发事件的持续影响，并用卡尔曼滤波（若线性高斯近似可行）或粒子滤波（非线性）进行在线估计与预警。对于模型健壮性，系统化地开展敏感性分析：一是对先验假设与尾部形式进行情景分析（例如用对数正态尾、Pareto尾或GPD分别拟合并比较）；二是对映射矩阵 M 的不确定性、选择偏差参数 psi 的不同假设与LOD替换规则（如LOD/2、Tobit或全删失似然）做后验比较；三是对摄入-浓度相依性假设（独立 vs 条件相关）进行替代模型比对。这些敏感性结果应作为决策支持的一部分向监管者透明报告。\n\n模型验证与数据需求。尽管竞赛时间短无法获取大规模实测数据，但可设计小规模多轮试验用于验证与校准：第一轮在代表性分层中开展目标性配对采样（同时测量特定家庭的食物摄入与对应食品浓度），用于直接验证摄入与浓度的联动；第二轮在被模型识别为高不确定区域进行加强监测，以检验尾部外推的可靠性。模型内部校验使用后验预测检查（posterior predictive checks），交叉验证（对不同地域/季节留出测试集）以及历史事件回溯（若有中毒或超标事件的暴露重构可用于比较）。为长期改进，建议纳入生物监测数据（例如血铅、尿镉）作为“最终检验”并通过逆模型校准摄入转化因子与代谢参数。\n\n在政策与采样设计层面的创新。模型不仅用于评估现状，还应指导资源最优配置。基于贝叶斯决策理论，定义目标为在给定监测预算下最小化目标统计量（例如99.999%暴露上界的不确定度或超阈概率的不确定度），通过计算价值信息（expected information gain）对不同分层/食品类别设计自适应抽样方案，优先抽样能最大减少极端分位不确定性的格局（通常是高消费-高浓度交互区域、进口批次集中或流通链关键节点）。另外，制定操作性决策规则：若某污染物在给定分层的后验分布使得其99.999%分位的95%后验上界超过安全阈值，则触发预警并启动分层内高密度抽样与限流管理措施；若只是上界接近阈值，则以临界监测做进一步确认。\n\n可扩展性与未来改进方向。随着数据累积与计算能力提升，可将模型向以下方向扩展：一是将个体代谢动力学与生物监测模块耦合，建立暴露—内剂量—生物标志物的完整链路；二是引入基于代理人的微观经济/行为模型以模拟价格、政策或突发事件下消费行为的快速调整；三是在尾部的外推中采用多源信息（国际数据库、行业批次检验）进行跨国借强度（transfer learning）；四是开发实时仪表板与自动化更新流程，将模型输出（暴露分布、风险地图、优先抽样建议）直接交付监管决策系统。最后，强调透明性：所有关键假设、映射矩阵与敏感性分析结果需要以可审计的方式保存并公开，以便科学检验与社会信任。\n\n总结性陈述：该综合模型以层级贝叶斯为主轴，结合两部分摄入模型、删失感知的浓度层级模型、食品分类的概率映射与合成微观人口策略，通过蒙特卡洛微观模拟与极值理论并行估计暴露总体分布并对极端右尾使用GPD外推与重要性抽样加以稳健估计。模型显式处理“未检出”与采样偏差问题、通过映射矩阵解决分类不一致、并以自适应抽样与价值信息最大化指导监测投入，从而在有限抽样资源下为监管部门提供可解释、可追溯并带有不确定性量化的暴露与预警结果，兼具实用性与可扩展性。",
  "task_descriptions": [
    "子任务一的目标是把来源多样、分类不一致且可能存在选择性抽样偏差的摄入与浓度观测数据整合为一套可供微观模拟使用的、具有代表性的“合成微观人口”数据集（每个虚拟个体含人口学协变量、食品消费概率/数量分布、购买渠道与来源分布及对应权重），并把由分类映射与抽样偏差引入的不确定性以可重复的方法量化并输出。为实现该目标，必须按步骤执行：首先清点并规范化所有可用数据源（人口普查与分层边际表、家庭饮食调查/日记、零售销售/流通量与贸易统计、少量配对/详细映射样本及监管抽检记录），统一时间与空间索引并定义一个“目标摄入分类表”（target intake categories）作为微观模拟的基准分类体系；其次构建食品分类概率映射矩阵M（源分类→目标摄入分类），将每一源分类按概率分配到目标分类，要求M每列和为1，M的元素以Dirichlet先验参数化并用可得的少量详细映射样本、大宗流通/贸易权重及行业/专家信息进行贝叶斯或最大似然校准，必要时使用分层Dirichlet以反映区域或渠道差异，并通过多重插补保留映射不确定性；第三基于多层回归与后分层（MRP）方法构建合成微观人口：在可得的家庭调查上对目标摄入分类下的消费概率与条件分布（或其替代统计量）以人口学与地区协变量建多水平回归模型，预测到所有按普查定义的后分层单元，再按普查边际频数或销售流量对预测值进行后分层抽样或加权生成虚拟个体样本，从而得到每个虚拟个体的消费行为表征与初始采样权重；第四把浓度观测按映射矩阵M以概率方式投影到目标摄入分类上：对每一浓度记录用M的抽样分配将其分解到对应的摄入分类并保留分配的不确定性样本（多次抽样或后验样本），同时记录原始数据源标识以便后续偏差校正；第五显式估计各数据源的选择/抽样机制（例如通过对观测与非观测可得协变量拟合logit选择模型或采用外部信息参数化选择概率），并据此对被合并的数据实施校正：在频率框架用逆概率加权（IPW）或校准权重、在贝叶斯框架将选择机制并入联合似然以同步估计并传播不确定性；第六为整合过程设计多重不确定性传播策略——对映射矩阵M、选择模型参数与源数据测量差异采用多重插补或贝叶斯后验抽样，在每一后验/插补样本上重复合成微观人口生成流程，从而得到一组可供下游模拟使用的候选合成总体并保留不确定性信息；最后明确所需输出与诊断：输出应包括（1）带有权重与协变量的虚拟个体清单；（2）每一目标摄入分类对应的、由不同源概率分配得到的浓度样本集合；（3）映射矩阵M的后验样本或多重插补样本；（4）每一数据源的选择模型参数与校正权重；并提供一组可操作的质量诊断（后验预测检查、映射后边际总量与已知流量或普查边际的对比、敏感性到M与选择模型假设的基本报告）。实施工具与方法上建议使用R或Python进行数据处理、MRP与加权（survey、raking/iterative proportional fitting）、Stan或PyMC进行Dirichlet/贝叶斯映射与选择模型的联合估计，多重插补框架或EM算法用于缺失/映射不确定性处理，并保持所有中间产品可重复、可审计以便下游模块调用。",
    "子任务2（人群食物摄入模型）的目标是以分层、可解释且可推广的方法精确估计不同人口子群（按省/市/城乡、年龄、性别、职业/劳动强度、收入等分层）对若干目标食品类别的“usual intake”（长期平均日摄入量）分布及其不确定性，为此应建立一个两部分（two‑part）分层混合效应模型并给出可直接用于下游风险计算的个体级和分层级摄入量预测与不确定度输出。具体范围包括：输入数据为家庭/个人的短期重复膳食记录（例如多日称重记录或24小时回忆的若干天数据）、人口学协变量、调查设计信息（抽样权重、分层与聚类标识）、时间标识（季节/调查日）与可能的外生影响因子（食品价格、节假日等）；输出为每一观察/合成个体在每一食品类别上的消费概率模型参数、条件消费量（在消费发生时）的对数尺度混合效应参数、个体随机效应估计、日内与日间方差分解结果、每一分层的usual intake分布（含不确定区间）以及模型诊断指标。方法上，对每一食品类别采用两部分建模：第一部分用广义线性混合模型（如Logit/Probit GLMM）拟合消费事件概率 p_{g,j,t}，固定效应包含人口学与时间协变量，随机截距或随机斜率反映家庭/个体/小区层级的异质性；第二部分对条件消费量 A（仅在发生消费时）在对数尺度上建立线性混合效应模型 log A = Xβ + Zb + ε，其中b包含个体长期偏好随机效应（用于分离个体内日内变异与个体间变异，从而通过去日内变异的方法估计usual intake），并允许消费概率模型与条件量模型之间通过共享随机效应或联合建模反映二者相关性（处理偶发食品的零膨胀特性）；对消费次数极低或信息稀疏的类别采用参数池化或层级先验以借用强度。模型估计可采用两类实现路径：频率学派的REML/ML估计（glmmTMB、lme4）配合方差分解与近似朴素贝叶斯预测校正，或贝叶斯层级建模（Stan/brms/PyMC）以完整传播参数与随机效应的不确定性并自然生成后验预测分布；若数据来自复杂抽样设计，模型应在估计或后处理阶段融入抽样权重与分层/聚类信息（通过加权似然、伪最大似然或后分层/校准（post‑stratification/raking）将样本预测扩展到目标人口）。实施步骤包括：清洗并统一食品分类与单位、检查与处理重复测量和极端值；确定协变量与随机效应层级结构；拟合两部分混合模型并进行方差分解以获取个体内/间方差比以计算usual intake（例如使用NCI方法或在贝叶斯框架中直接从后验抽样）；如需联合估计多种食品间的相关摄入，应扩展为多元混合模型或采用Copula/共变结构以模拟摄食搭配与相关性；用后验/自助法生成个体级usual intake预测样本并按人口后分层得到分层与总体分布估计；进行模型诊断（后验预测检查、残差分析、零膨胀拟合检验、交叉验证与敏感性分析对协变量选择与随机效应结构的稳健性）。推荐工具与实现环境包括R（glmmTMB、lme4、survey、brms、rstanarm）、Stan或PyMC进行贝叶斯推断，以及支持脚本化的数据处理与可重复性文档化；在样本稀疏或计算受限情形，可采用经验贝叶斯或参数池化近似。最终产出应明确说明每一分层与食品类别的usual intake分布的点估计与不确定区间、个体级预测样本及模型诊断报告，以便独立使用和后续整合。",
    "子任务3——污染物浓度分布建模（删失处理、层级结构、尾部建模与来源/方法误差）：本子任务的目标是以对数浓度为建模尺度，构建一个能同时处理检测限左删失（“未检出”）、不同检测方法/数据源的观测误差、食品类别—产地—季节等多层次异质性、批次/样本相关性以及右尾厚尾外推需要的、可用于下游推断的条件分布模型 P(C | food_category, region, season, method, batch)，并输出参数后验样本、预测分布与尾部不确定性量化；为此需按以下步骤和技术实现：首先输入要求为定量浓度测量表（每条记录含观测值或“未检出”标记、对应LOD值）、样本元数据（食品类别编码、样本采样地点/行政区/产地、采样日期/季节、检测/分析方法标识、批次或样本来源ID、样本权重或流通量信息若有）；数据预处理包括统一单位、对LOD进行记录并识别定性/定量样本、探索性分析（直方图、对数后箱线图、分组箱线图、经验生存函数）、评估各方法LOD分布及样本量分布以决定分层粒度；模型构成以对数浓度 Y = log C 为主干，主体对数浓度采用删失正态或灵活对称/偏态分布（如对数正态、对数伽玛或对数偏正态）通过删失似然（若 y>log(LOD) 则观测项为密度，若被删失则为累积分布 P(Y ≤ log(LOD))）来处理左删失并把方法特异性观测误差建模为 y_obs = y_true + e_method，e_method ~ Normal(0, tau_method^2)（tau_method可为已知或层级估计）；多层异质性通过层级效应 mu_{j,r,t} = alpha_j + beta_r + gamma_season + delta_method + u_batch + … 建模，其中 j=食品类别、r=区域、season=季节、method=检测方法，u_batch 为批次/样本来源随机效应并允许相关性或簇内依赖；针对右尾厚尾现象，在每一细分（或在信息不足时在更高层次上）采用阈值法（POT）对 Y 在阈值 u_j 以上的超额部分拟合广义帕累托分布 (GPD) 并将GPD参数（形状ξ、尺度σ）设置为层级参数以便不同类别/区域之间借强度，模型需保证阈值处的一致性（可强制密度连续或用合适连接项）；阈值 u 的选择通过均余寿命图（mean residual life）、阈值稳定性图与诊断统计决定，并在模型中对阈值选择不确定性做敏感性分析；推断与实现建议采用贝叶斯层级框架以自然传播删失、观测误差与层级不确定性（使用Stan/NUTS或PyMC实现，必要时可用EM或TMB做频率近似），对尾部GPD参数同样采用贝叶斯层级估计并合并后验样本；必须进行模型诊断：后验预测检查（包括对“未检出”比例的复现）、残差与正态性检验、组内与组间方差解释、阈值稳定性与尾部拟合优度（QQ图、POT诊断、KS检验或概率图）、交叉验证或留一组验证（分区域/季节留出）以评估外推稳健性，并开展敏感性分析（LOD替代策略、主体分布族选择、阈值位置、method误差假设）；输出应包含对每一食品类别—区域—季节—方法单元的后验样本（mu、sigma）、批次随机效应估计、方法误差方差估计、针对指定阈值的GPD后验参数与由此推导的尾部分位数及其不确定区间、并能生成给定单元的完整预测分布样本（含被删失情形下的后验预测）；实现与工具建议明确：用R/Python做数据处理与诊断，可用rstan/brms/Stan或PyMC进行贝叶斯拟合，extRemes/evd或ismev包辅助POT诊断与GPD拟合，必要时并行计算以加速MCMC，所有中间产物（数据清单、LOD表、模型代码、后验样本）应可复现与审计。",
    "子任务4的目标是把已建的个体级摄入分布与食品浓度分布作为输入，通过可重复的、计算可行的流程生成全国或分层人群的日暴露微观模拟、稳健外推极端右尾并为监管决策提供量化不确定性与触发规则；为此，首先明确输入数据（合成微观个体样本或后验摄入样本、按食品分类—区域—季节条件化的浓度后验样本或预测分布、食品来源/批次依赖结构、检测限LOD与映射/权重信息、监管安全阈值与监测预算约束），然后按步骤实施： (1) 蒙特卡洛微观模拟——对每一虚拟个体与模拟日，按其所属分层和来源条件从摄入预测分布抽取食品消费量，从相应的浓度预测分布抽取批次/来源相关的污染物浓度（可用条件分布或Copula保持消费-浓度关联，必要时在同一批次内为多个消费者抽取共享浓度以体现批次依赖），计算个体日暴露 E = sum_j X_j * C_j 并累积得到总体暴露样本；(2) 尾部建模与外推——对模拟暴露样本的高阈值超额部分采用POT方法拟合广义帕累托分布（GPD），阈值通过均余寿命图和阈值稳定性图选择并做灵敏度分析；当超额样本不足时采用贝叶斯层级GPD以借用结构化先验并获得后验分布；(3) 提高尾部效率——在微观模拟中引入重要性/倾斜抽样或分层再采样（对高消费、高浓度来源和高风险分层加权采样），并用相应权重校正以获得无偏极端分位估计，同时监控有效样本量与方差；(4) 不确定性量化——通过参数后验抽样结合重复微观模拟、重要性重加权与bootstrap并报告暴露分布的后验样本、目标分位数（如99.999%）的点估计及置信/后验区间，且提供监管所需的保守度量（例如分位数的95%后验上界）；(5) 计算与实现细节——参数后验建议采用HMC/NUTS（Stan或PyMC）获取，尾部GPD可以独立或嵌入贝叶斯流程估计，微观模拟和重要性采样并行化实现（多核/集群或GPU），对高计算成本的内部映射使用代理模型（例如Gaussian Process或轻量神经网络）作为近似加速，并保存权重与随机种子以保证可重复性；(6) 在线更新与自适应监测——支持Sequential Monte Carlo或周期性贝叶斯更新以在收到新监测数据时及时更新暴露后验与极端估计，并基于预期信息增益计算对不同分层/食品/区域的优先抽样策略，以在有限预算下最大化对目标分位不确定性的减少；(7) 验证与诊断——为每次运行生成后验预测检查（再现“未检出”比例、分层边际与历史观测对比）、有效样本量、权重方差、阈值稳定性图、尾部拟合诊断图和敏感性分析（尾部分布形式、LOD处理、重要性方案）以评估结果稳健性；(8) 决策规则与输出——明确定义操作性触发规则（例如当目标分位的95%后验上界超过监管安全阈值则触发高密度抽样与限流/召回措施，或当预期信息增益小于阈值则停止额外抽样），并输出可交付的产品：暴露总体与分层分布后验样本、极端分位点及其区间、保守上界、重要性采样权重与有效样本量、优先监测清单和完整的诊断报告，所有计算流程、参数先验与随机性控制应可审计并适配并行化执行以满足实时预警与定期风险评估的需求。"
  ]
}