{
  "tasks": [],
  "problem_str": "问题背景：\n研究表明，一般人所获取的信息大约有80\\%来自视觉。视觉信息的主要载体是图像和视频，视觉情报指的是通过图像或者视频获取的情报。\n\n从图像或视频中提取物体的大小、距离、速度等信息是视觉情报分析工作的重要内容之一，如在新中国最著名的“照片泄密案”中，日本情报专家就是通过《中国画报》的一幅封面照片解开了大庆油田的秘密\\cite{ref1}。在当前很热门的移动机器人、无人驾驶、计算机视觉、无人机侦察等领域，更是存在着大量的应用需求。尽管在对未来智能交通系统的设计等工作中，科研人员正在研究使用双目\\cite{ref2}或多目视觉系统或者特殊配置的单目视觉系统\\cite{ref3}获取相关信息，但在某些特定条件下，分析人员所能利用的，只能是普通的图像或视频\\cite{ref4,ref5}，其中的信息需要综合考虑各种因素，通过合适的数学模型来提取。\n\n问题要求：\n本题从实际需求出发，选择单幅图像距离信息分析、平面视频距离信息分析和立体视频距离信息分析几个典型场景，提出如下四项任务：\n\n\\textbf{任务1：} 测算图1中红色车辆A车头和白色车辆B车头之间的距离、拍照者距马路左侧边界的距离；图2中黑色车辆A车头和灰色车辆C车尾之间的距离以及拍照者距白色车辆B车头的距离；图3中拍照者距岗亭A的距离以及拍照者距离地面的高度；图4中塔体正面（图中四边形ABCD）的尺寸，即AB和CD的长度以及AB和CD之间的距离（已知地砖尺寸为80cm×80cm）。\n\n任务2：附件“车辆.mp4”（右键点击后选择“保存到文件”可导出视频文件）是别克英朗2016款车上乘客通过后视镜拍摄的视频。（1）估算该车和后方红色车辆之间的距离；（2）估算该车超越第一辆白色车辆时两车的速度差异。\n\n任务3：附件“水面.mp4”是高铁乘客拍摄的一块水面，测算高铁行驶方向左侧第一座桥桥面距水面的高度、距高铁轨道的距离以及水面宽度，估算拍摄时高铁的行驶速度。\n\n任务4：附件“无人机拍庄园.mp4”记录了某老宅的全景。（1）估算其中环绕老宅道路的长度、宽度、各建筑物的高度、后花园中树木的最大高度；（2）估算该老宅的占地面积；（3）测算无人机的飞行高度和速度。\nAddendum: \n温馨提示：1. 建模过程中，除题中明确限定的条件外，你们可以作任何合理的假设或者补充真实的数据；\n\n2. 对题中你们认为有歧义的表述，可以按照你们明确说明的理解解题而不会影响你们的最终成绩；\n\n3. 论文中用到的非通用程序必须以附录形式附在文末，所有引用的文献资料（含计算机程序）都必须明确注明出处。\n\n4. 论文主体（含摘要、目录、正文、参考文献，不含附录）不要超过40页。\nDataset Path:\n['图1.png', '图2.png', '图3.png', '图4.png', '无人机拍庄园.mp4', '水面.mp4', '车辆.mp4']\n\nData Description:\n该数据集由若干视频记录组成，主要包含三类拍摄场景：车内后视镜视角的车辆视频（文件名“车辆.mp4”，多处条目重复记录，说明来源为别克英朗2016款车辆上的乘客通过后视镜拍摄，属任务2）、无人机航拍的庄园全景（文件名“无人机拍庄园.mp4”，属任务4）以及高铁乘客拍摄的一段水面视频（文件名“水面.mp4”，属任务3）；数据条目中有图1–图4等索引指向同一车辆视频，表明元信息存在冗余或重复记录。总体上这是一个以视频为主的小型多场景数据集，包含固定车内反射视角、移动航拍全景和行进中的车窗视角三种典型拍摄条件，适合用于视角感知、运动模糊与抖动鲁棒性测试、反射/镜像处理、水面纹理与运动分析及航拍全景重建等计算机视觉任务；当前描述仅提供拍摄设备/场景和任务归属等高层元信息，未见更细粒度标注或时间码等详细标签。",
  "problem": {
    "background": "研究表明，一般人所获取的信息大约有80\\%来自视觉。视觉信息的主要载体是图像和视频，视觉情报指的是通过图像或者视频获取的情报。\n\n从图像或视频中提取物体的大小、距离、速度等信息是视觉情报分析工作的重要内容之一，如在新中国最著名的“照片泄密案”中，日本情报专家就是通过《中国画报》的一幅封面照片解开了大庆油田的秘密\\cite{ref1}。在当前很热门的移动机器人、无人驾驶、计算机视觉、无人机侦察等领域，更是存在着大量的应用需求。尽管在对未来智能交通系统的设计等工作中，科研人员正在研究使用双目\\cite{ref2}或多目视觉系统或者特殊配置的单目视觉系统\\cite{ref3}获取相关信息，但在某些特定条件下，分析人员所能利用的，只能是普通的图像或视频\\cite{ref4,ref5}，其中的信息需要综合考虑各种因素，通过合适的数学模型来提取。",
    "problem_requirement": "本题从实际需求出发，选择单幅图像距离信息分析、平面视频距离信息分析和立体视频距离信息分析几个典型场景，提出如下四项任务：\n\n\\textbf{任务1：} 测算图1中红色车辆A车头和白色车辆B车头之间的距离、拍照者距马路左侧边界的距离；图2中黑色车辆A车头和灰色车辆C车尾之间的距离以及拍照者距白色车辆B车头的距离；图3中拍照者距岗亭A的距离以及拍照者距离地面的高度；图4中塔体正面（图中四边形ABCD）的尺寸，即AB和CD的长度以及AB和CD之间的距离（已知地砖尺寸为80cm×80cm）。\n\n任务2：附件“车辆.mp4”（右键点击后选择“保存到文件”可导出视频文件）是别克英朗2016款车上乘客通过后视镜拍摄的视频。（1）估算该车和后方红色车辆之间的距离；（2）估算该车超越第一辆白色车辆时两车的速度差异。\n\n任务3：附件“水面.mp4”是高铁乘客拍摄的一块水面，测算高铁行驶方向左侧第一座桥桥面距水面的高度、距高铁轨道的距离以及水面宽度，估算拍摄时高铁的行驶速度。\n\n任务4：附件“无人机拍庄园.mp4”记录了某老宅的全景。（1）估算其中环绕老宅道路的长度、宽度、各建筑物的高度、后花园中树木的最大高度；（2）估算该老宅的占地面积；（3）测算无人机的飞行高度和速度。",
    "dataset_path": [
      "图1.png",
      "图2.png",
      "图3.png",
      "图4.png",
      "无人机拍庄园.mp4",
      "水面.mp4",
      "车辆.mp4"
    ],
    "dataset_description": {
      "图1": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图2": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图3": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图4": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "无人机拍庄园": "任务4的视频文件“无人机拍庄园.mp4”记录了某老宅的全景。",
      "水面": "任务3的视频文件“水面.mp4”是高铁乘客拍摄的一块水面。",
      "车辆": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。"
    },
    "variable_description": [
      {},
      {},
      {},
      {},
      {},
      {},
      {}
    ],
    "addendum": "温馨提示：1. 建模过程中，除题中明确限定的条件外，你们可以作任何合理的假设或者补充真实的数据；\n\n2. 对题中你们认为有歧义的表述，可以按照你们明确说明的理解解题而不会影响你们的最终成绩；\n\n3. 论文中用到的非通用程序必须以附录形式附在文末，所有引用的文献资料（含计算机程序）都必须明确注明出处。\n\n4. 论文主体（含摘要、目录、正文、参考文献，不含附录）不要超过40页。",
    "data_summary": "Dataset Path:\n['图1.png', '图2.png', '图3.png', '图4.png', '无人机拍庄园.mp4', '水面.mp4', '车辆.mp4']\n\nData Description:\n该数据集由若干视频记录组成，主要包含三类拍摄场景：车内后视镜视角的车辆视频（文件名“车辆.mp4”，多处条目重复记录，说明来源为别克英朗2016款车辆上的乘客通过后视镜拍摄，属任务2）、无人机航拍的庄园全景（文件名“无人机拍庄园.mp4”，属任务4）以及高铁乘客拍摄的一段水面视频（文件名“水面.mp4”，属任务3）；数据条目中有图1–图4等索引指向同一车辆视频，表明元信息存在冗余或重复记录。总体上这是一个以视频为主的小型多场景数据集，包含固定车内反射视角、移动航拍全景和行进中的车窗视角三种典型拍摄条件，适合用于视角感知、运动模糊与抖动鲁棒性测试、反射/镜像处理、水面纹理与运动分析及航拍全景重建等计算机视觉任务；当前描述仅提供拍摄设备/场景和任务归属等高层元信息，未见更细粒度标注或时间码等详细标签。",
    "data_description": {
      "图1": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图2": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图3": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "图4": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。",
      "无人机拍庄园": "任务4的视频文件“无人机拍庄园.mp4”记录了某老宅的全景。",
      "水面": "任务3的视频文件“水面.mp4”是高铁乘客拍摄的一块水面。",
      "车辆": "任务2的视频文件“车辆.mp4”是别克英朗2016款车上乘客通过后视镜拍摄的视频。"
    },
    "problem_str": "问题背景：\n研究表明，一般人所获取的信息大约有80\\%来自视觉。视觉信息的主要载体是图像和视频，视觉情报指的是通过图像或者视频获取的情报。\n\n从图像或视频中提取物体的大小、距离、速度等信息是视觉情报分析工作的重要内容之一，如在新中国最著名的“照片泄密案”中，日本情报专家就是通过《中国画报》的一幅封面照片解开了大庆油田的秘密\\cite{ref1}。在当前很热门的移动机器人、无人驾驶、计算机视觉、无人机侦察等领域，更是存在着大量的应用需求。尽管在对未来智能交通系统的设计等工作中，科研人员正在研究使用双目\\cite{ref2}或多目视觉系统或者特殊配置的单目视觉系统\\cite{ref3}获取相关信息，但在某些特定条件下，分析人员所能利用的，只能是普通的图像或视频\\cite{ref4,ref5}，其中的信息需要综合考虑各种因素，通过合适的数学模型来提取。\n\n问题要求：\n本题从实际需求出发，选择单幅图像距离信息分析、平面视频距离信息分析和立体视频距离信息分析几个典型场景，提出如下四项任务：\n\n\\textbf{任务1：} 测算图1中红色车辆A车头和白色车辆B车头之间的距离、拍照者距马路左侧边界的距离；图2中黑色车辆A车头和灰色车辆C车尾之间的距离以及拍照者距白色车辆B车头的距离；图3中拍照者距岗亭A的距离以及拍照者距离地面的高度；图4中塔体正面（图中四边形ABCD）的尺寸，即AB和CD的长度以及AB和CD之间的距离（已知地砖尺寸为80cm×80cm）。\n\n任务2：附件“车辆.mp4”（右键点击后选择“保存到文件”可导出视频文件）是别克英朗2016款车上乘客通过后视镜拍摄的视频。（1）估算该车和后方红色车辆之间的距离；（2）估算该车超越第一辆白色车辆时两车的速度差异。\n\n任务3：附件“水面.mp4”是高铁乘客拍摄的一块水面，测算高铁行驶方向左侧第一座桥桥面距水面的高度、距高铁轨道的距离以及水面宽度，估算拍摄时高铁的行驶速度。\n\n任务4：附件“无人机拍庄园.mp4”记录了某老宅的全景。（1）估算其中环绕老宅道路的长度、宽度、各建筑物的高度、后花园中树木的最大高度；（2）估算该老宅的占地面积；（3）测算无人机的飞行高度和速度。\nAddendum: \n温馨提示：1. 建模过程中，除题中明确限定的条件外，你们可以作任何合理的假设或者补充真实的数据；\n\n2. 对题中你们认为有歧义的表述，可以按照你们明确说明的理解解题而不会影响你们的最终成绩；\n\n3. 论文中用到的非通用程序必须以附录形式附在文末，所有引用的文献资料（含计算机程序）都必须明确注明出处。\n\n4. 论文主体（含摘要、目录、正文、参考文献，不含附录）不要超过40页。\nDataset Path:\n['图1.png', '图2.png', '图3.png', '图4.png', '无人机拍庄园.mp4', '水面.mp4', '车辆.mp4']\n\nData Description:\n该数据集由若干视频记录组成，主要包含三类拍摄场景：车内后视镜视角的车辆视频（文件名“车辆.mp4”，多处条目重复记录，说明来源为别克英朗2016款车辆上的乘客通过后视镜拍摄，属任务2）、无人机航拍的庄园全景（文件名“无人机拍庄园.mp4”，属任务4）以及高铁乘客拍摄的一段水面视频（文件名“水面.mp4”，属任务3）；数据条目中有图1–图4等索引指向同一车辆视频，表明元信息存在冗余或重复记录。总体上这是一个以视频为主的小型多场景数据集，包含固定车内反射视角、移动航拍全景和行进中的车窗视角三种典型拍摄条件，适合用于视角感知、运动模糊与抖动鲁棒性测试、反射/镜像处理、水面纹理与运动分析及航拍全景重建等计算机视觉任务；当前描述仅提供拍摄设备/场景和任务归属等高层元信息，未见更细粒度标注或时间码等详细标签。"
  },
  "problem_background": "研究表明，一般人所获取的信息大约有80\\%来自视觉。视觉信息的主要载体是图像和视频，视觉情报指的是通过图像或者视频获取的情报。\n\n从图像或视频中提取物体的大小、距离、速度等信息是视觉情报分析工作的重要内容之一，如在新中国最著名的“照片泄密案”中，日本情报专家就是通过《中国画报》的一幅封面照片解开了大庆油田的秘密\\cite{ref1}。在当前很热门的移动机器人、无人驾驶、计算机视觉、无人机侦察等领域，更是存在着大量的应用需求。尽管在对未来智能交通系统的设计等工作中，科研人员正在研究使用双目\\cite{ref2}或多目视觉系统或者特殊配置的单目视觉系统\\cite{ref3}获取相关信息，但在某些特定条件下，分析人员所能利用的，只能是普通的图像或视频\\cite{ref4,ref5}，其中的信息需要综合考虑各种因素，通过合适的数学模型来提取。",
  "problem_requirement": "本题从实际需求出发，选择单幅图像距离信息分析、平面视频距离信息分析和立体视频距离信息分析几个典型场景，提出如下四项任务：\n\n\\textbf{任务1：} 测算图1中红色车辆A车头和白色车辆B车头之间的距离、拍照者距马路左侧边界的距离；图2中黑色车辆A车头和灰色车辆C车尾之间的距离以及拍照者距白色车辆B车头的距离；图3中拍照者距岗亭A的距离以及拍照者距离地面的高度；图4中塔体正面（图中四边形ABCD）的尺寸，即AB和CD的长度以及AB和CD之间的距离（已知地砖尺寸为80cm×80cm）。\n\n任务2：附件“车辆.mp4”（右键点击后选择“保存到文件”可导出视频文件）是别克英朗2016款车上乘客通过后视镜拍摄的视频。（1）估算该车和后方红色车辆之间的距离；（2）估算该车超越第一辆白色车辆时两车的速度差异。\n\n任务3：附件“水面.mp4”是高铁乘客拍摄的一块水面，测算高铁行驶方向左侧第一座桥桥面距水面的高度、距高铁轨道的距离以及水面宽度，估算拍摄时高铁的行驶速度。\n\n任务4：附件“无人机拍庄园.mp4”记录了某老宅的全景。（1）估算其中环绕老宅道路的长度、宽度、各建筑物的高度、后花园中树木的最大高度；（2）估算该老宅的占地面积；（3）测算无人机的飞行高度和速度。",
  "problem_analysis": "这个建模问题本质上是“从单张图像或单目视频中恢复现实世界的绝对或相对几何量（距离、尺寸、高度、速度等）”，它把计算机视觉的若干基础主题——针孔投影模型与摄像机标定、平面与三维重建、单目结构-运动（SfM）、视差/光流与运动估计、透视校正与单应性（homography）——结合到工程化测量任务中。把问题放在更宏观的背景下，可以将建模目标清晰化为两类：一类是几何测量目标（任意时刻在世界坐标系下求取点到点之间的欧氏距离、平面上各边长、物体高度、占地面积等），另一类是动力学目标（通过连续帧的时序信息估计相对速度或航速）。这两个目标共同塑造了解题思路：要得到绝对量必须解决“尺度（scale）歧义”；要得到速度则必须结合时间信息（帧率、时间戳）并消除或建模运动的几何变形与相机自运动的影响。因此在方法选择上会在两种策略间权衡：一是基于明确几何先验与少量已知真实尺度（例如题目中给出的80 cm×80 cm地砖、轨道间距、车辆常见尺寸或相机安装高度等），采用解析几何与标定方法以获得可解释且可量化误差界的结果；二是采用数据驱动的深度估计或学习方法以在无显式尺度先验时给出相对深度或尺度估计，但这类方法的绝对度量能力依赖训练数据及先验，误差界不易解析。\n\n在建模前必须批判性地识别并明确所有显性与隐性假设，因为这些前提直接决定了可行性与结果的可信度。常见且通常必须声明的重要假设包括：所分析的关键点（车辆车头、地面标志物、建筑物底边等）位于或能被近似为一个已知的参考平面（通常假定为地面或桥面为平面）；摄像机可用针孔模型近似（在高变形的广角镜头或显著桶形畸变下需要先做畸变矫正）；拍摄时场景中的关键物体处于静止或可由独立追踪分离出的刚体运动（否则位移混叠）；摄像机的内参（焦距、主点）或可通过EXIF、厂商资料获取，或可通过图像中平行线的消失点、棋盘或已知尺寸物体来估计；时间信息（视频帧率、时间戳）是准确的且匀速采样，必要时可从视频元数据或文件头读取。对镜像/反射的场景（例如后视镜拍摄）需额外考虑镜面是否为平面、是否存在畸变或反光区域，这些都可能改变投影关系。若任何一个关键假设被打破（例如地面并非平面、物体未在同一平面、镜头存在显著畸变或滚动快门效应），那么基于简单几何模型的测量会产生系统性偏差，必须在模型中显式引入这些非理想因素或改用鲁棒方法。\n\n在几何关系层面，问题内部各要素的相互依赖性非常强。单张图片测量的核心是利用针孔投影方程 x = K [R|t] X（这里x为像素，X为三维点，K为内参矩阵）来建立像素坐标与世界坐标之间的映射，但该映射在单幅图像下固有地缺少尺度（深度Z和f等参数会耦合），所以必须引入额外的约束以恢复尺度：典型约束有已知物体真实尺寸（地砖、车辆尺寸）、共面点构成的单应性（ground plane homography可将像素点反投影到地面坐标并用已知地面尺度定标）、消失点和消失线（利用平行线与垂直线的消失点可以恢复相机朝向与尺度关系的线性部分）、或利用多帧的运动（通过估计本质矩阵/基本矩阵，结合已知相机移动基线来恢复尺度）。在视频情形中，连续帧提供的轨迹信息允许用光流或特征匹配估计相对运动与场景深度（结构-运动分解），但这是有尺度不定性的——除非知道相机在真实世界移动的基线（例如无人机的GPS/气压计/高度计、车速表、两摄像机已知基线），否则恢复的深度只到一个比例常数。任务之间的内在张力在于“可解释的解析解”与“对现实场景复杂性的鲁棒处理”之间的权衡：几何解析方法在假设成立下精度高且误差可控，但对假设违背（例如水面缺乏纹理、树木高度不规则）敏感；学习方法在纹理匮乏或传统特征失效时表现更鲁棒，但其输出缺乏可解释的不确定度并依赖训练域一致性。\n\n复杂性还体现在不同尺度与时间维度上。空间尺度上，地面平面尺度（地砖80cm）可以用来校准小范围平面测量（例如图4的塔体与地砖），而对于高高度的测量（建筑屋顶、树高）需要更多垂直方向的几何信息：利用垂直消失点、已知垂直尺度样本或在多帧中利用立体-运动基线来确定高度。时间尺度上，视频序列提供了瞬时速度估计和轨迹形状，但同时带来动态影响：运动模糊、滚动快门畸变、摄像机自转抖动、景深变化都会随时间改变测量质量，必须在时间域上做运动估计和滤波（例如卡尔曼滤波或滑动窗口Bundle Adjustment）。此外环境因素（光照、阴影、反射）会在不同时间点影响特征可见性，尤其在水面场景中，水面反射会对特征匹配产生“镜像”误导，需要用反射对称性或极线约束来识别与过滤假匹配。长期稳定性方面，摄像机内参在短期一般稳定，但在多机位或多日拍摄下可能变化（焦距变动、镜头热膨胀），因此若要追踪长期测量或生成高精度地图，需要周期性重校准和基于冗余约束的自适应校正。\n\n从方法学角度可以提出多种替代性问题表述，每种引导出不同的解法路径：如果把任务看成“几何解算问题”，可以优先使用从单幅图像恢复平面单应、消失点求相机姿态、并用已知地砖尺度恢复尺度；若把任务看成“时序运动估计问题”，则以特征跟踪、光流、基本矩阵/本质矩阵与视角分解为核心，最终需要一个已知基线或已知物体尺度来定标；如果允许外部信息（例如从文件元数据读取焦距、从车辆仪表读取速度、从无人机元数据读取高度或GPS）则应以传感器融合为主；若不信任这些先验，则可采用学习方法（端到端深度估计、单目深度网络）提供相对深度，再用用户给定的一个尺度标记进行定标。每种替代视角的利弊很明显：基于先验的几何方法在先验成立时可给出小而可量化的误差，但对先验敏感；学习方法更鲁棒但解释性和误差界限差；融合传感器信息则在物理可用时最可靠，但依赖外部数据的可得性与真实性。\n\n不确定性与风险管理在此类问题中至关重要。在模型构建与结果解释时必须区分两类不确定性：参数不确定性（摄像机内外参、地砖尺寸测量误差、像素定位误差）与模型不确定性（地面不是严格平面、目标不是刚体、镜面/反射/遮挡的影响）。对前者可以用误差传播分析或蒙特卡罗仿真来量化：例如对像素点定位误差（以像素标准差表示）、焦距误差、相机姿态误差做随机采样，通过反向投影与几何运算得到距离/高度的分布，从而报告置信区间而非单一数值。对于模型不确定性，应该在报告中明确指出关键假设及其潜在违背情形，并提供若干替代假设下的敏感性分析（例如地面倾角±2°对测量结果的影响、地砖尺寸偏差±1cm对塔体长度估计的影响）。另外，视频与图像本身质量（分辨率、压缩、帧率、噪声）会对特征提取与匹配带来不确定性，应在预处理阶段进行质量评估并把结果纳入不确定度预算。\n\n在实际算法流程与工程化实现上，推荐采用迭代式、多阶段的策略而非一次性求解。初步阶段用于问题理解与粗量级估计：对单幅图像，检测并标注场景中可供标定的已知尺度物体（地砖角、车轮基线、轨道间距等），估算消失点求相机姿态，构建平面单应并获得粗尺度。对视频，先做稳定化、畸变校正与关键帧选择，运用特征检测与跟踪（如SIFT/ORB+KLT）估计相机间相对位姿，进行滑动窗口的Bundle Adjustment以获得更稳健的三维结构，再用已知尺度点或传感器数据进行定标。精化阶段进行非线性最小二乘优化并同时估计不确定度（通过雅可比矩阵或蒙特卡罗），必要时引入物理约束（地面法线一致、垂直线共方向等）作为先验。对于难点场景（如水面纹理稀少）可结合语义分割与学习方法：先用深度网络获得相对深度或语义分区，再在可测区域应用几何方法以获得绝对尺度。对无人机航拍，若存在EXIF/telemetry（海拔、GS）应优先采用融合算法；若无，可采用地面控制点（已知尺寸的路、建筑物）或通过多视点光束法生成稠密点云并用已知单点尺度定标。\n\n最后要强调建模过程的开放性与迭代性：初步建模往往伴随对原始假设的修正（例如发现地砖并非完全规则，或镜面存在轻微曲率），因此应在每一步保留可复现的诊断输出（残差分布、重投影误差、可视化验证图），并基于这些信息调整模型复杂度或引入额外数据源。在撰写结论时应以不确定区间和条件化陈述为主（例如“在假设地面与地砖共面且地砖尺寸为80±1 cm的前提下，估计塔体AB长度为X±Δ米”），并提供若干情景分析（最乐观/最保守/中性假设下的结果），以便决策者或后续研究者理解结果的适用边界与潜在误差来源。总体目标是通过透明的假设声明、严谨的几何或统计推理、以及充分的不确定性量化，使得从单目图像或视频中获得的视觉情报既具有实际可用性，又在科学上可被批判性检验与逐步改进。",
  "modeling_solution": "总体思路与模型概览：本建模方案以针孔投影模型为基础，结合平面单应（homography）、消失点/消失线几何、单目结构-运动（SfM）及光流/本质矩阵（Essential matrix）分解的时序信息，通过引入一个或若干“尺度锚”（已知真实尺寸的目标，如题目中80 cm×80 cm地砖、标准轨距、常见车辆尺寸等）来解除单目固有的尺度不定性，从而实现图像/视频中距离、尺寸、高度与速度的量测。模型分为两大模块：静态几何测量模块（用于单幅图像的长度、距离、高度测算）与动态运动测量模块（用于视频中的相对/绝对速度估算、航高与航速估算）。两模块共享相机几何与尺度定标的子模块，并以概率化误差建模（像素定位噪声、内参不确定性、尺度先验误差）来给出置信区间，使结论既具物理可解释性又可量化不确定性。方案同时包含用于特殊场景的附加项：对后视镜（任务2）的镜面曲率模型、对水面（任务3）的镜像/反射剔除策略与对无人机（任务4）的可能遥测/影像元数据融合。\n\n关键假设与符号约定：假设镜头可由针孔相机近似，存在可校正的径向/切向畸变（若显著则在预处理阶段校正）。假设可识别且稳定的“地面平面”(ground plane)或桥面在图像中可被近似为同一平面（对于塔体底座、地砖相关测量尤为重要）。假设视频帧率已知且恒定。对后视镜拍摄，假设镜面为平面镜或可近似为小曲率的球面镜并可以通过额外参数刻画。符号：像素点列为 x = [u, v, 1]^T，世界三维点为 X = [X, Y, Z, 1]^T（以地面为Z = 0平面），相机内参矩阵为 K，外参为 [R|t]。单幅图像到地面坐标的单应为 H (3×3)，其逆映射到世界坐标上取决于尺度因子 s。视频时间间隔为 Δt（由帧率 f 得 Δt=1/f），跟踪的特征在第i帧到第i+1帧的像素位移用光流 u_i 表示。\n\n静态测量核心方程：针孔投影方程 x ∼ K [R|t] X 是建模基础。若世界中某一平面（例如地面Z=0）与相机的投影满足 x ∼ H X_plane（X_plane=[X,Y,1]^T），则存在单应矩阵 H = K [r1 r2 t]（其中 r1,r2为旋转矩阵R的前两列，t为平移向量），利用图像上至少四对平面点——真实地面点的像素坐标与其真实世界坐标（若已知）——可求解H（通过线性最小二乘或RANSAC保证鲁棒性）。一旦得到H并以某一已知长度L_ref（例如地砖边长0.8m）进行尺度定标，任两点在地面上的像素坐标 x1,x2 经逆变换得到世界坐标 X1,X2（X = s H^{-1} x，尺度s由已知参考长度唯一确定），进而可计算地面距离 d = ||X1 - X2||。对图1/图2问题中地面上车头到车头的距离与拍照者到路侧边界的距离，优先使用地面单应法。对于非地面目标（如塔体高度、岗亭高度、建筑物高度），采用垂直消失点与相似截距关系进行高度测算：若已知某参考垂直物体高 H_ref，其图像中顶端/底端分别为 y_ref_top, y_ref_base；目标物体的顶端/底端为 y_top,y_base；垂直方向消失点在图像的纵坐标为 v_y，则目标高度 H 由投影比关系给出：H = H_ref * ((y_top - v_y)/(y_base - v_y)) / ((y_ref_top - v_y)/(y_ref_base - v_y))。这一公式来源于直线在投影几何下的重合投影比例因子，适用于世界中共线的垂直方向。消失点可通过在图像中检测多条垂直（或平行）线的交点并用鲁棒估计（例如RANSAC）得到。对图3中拍照者到地面的高度，可通过其身高或相机安装位置的参考点与地面交点、或若有连续帧可通过运动估算与地面单应结合得到。\n\n动态测量与速度估计：当视频可用时，先用特征检测（SIFT/ORB）与跟踪（KLT）建立跨帧对应，然后使用本质矩阵/基本矩阵算法（八点法+RANSAC）得到F或E=K^T F K，再对E做SVD分解以确定相对旋转R和方向上的平移向量 t（仅能得到方向和比例因子）。若无外部尺度，t仅为方向，深度存在比例不定性；通过将平面地面点约束与已知尺度（地砖、轨距、车辆长度）相结合，或在滑动窗口上做Bundle Adjustment并加入尺度先验（以最小二乘方式约束某条地面直线长度等于真实长度）可同时优化点深度、相机位姿与尺度因子。对任务2中后视镜视角，像素运动来自于自车前进和后方车辆的相对速度，两车相对速度 Δv 可由被跟踪点在地面平面或车体平面上的世界坐标在时间上的差分得出：Δv = (d(t+Δt) - d(t))/Δt，其中d为世界坐标下的沿车向距离。若后视镜为平面镜且镜像关系为简单对称，映像尺度近似一致；若镜面为球面（轻微凸），需在模型中引入镜面曲率参数 ρ，并用镜面成像方程校正像素坐标再进行上述解算。总的运动估计在数值上通过最小化像素重投影误差的非线性优化（Bundle Adjustment）完成，目标函数为 Σ || x_ij - Proj(K,[R_i|t_i],X_j) ||^2，加上尺度与平面约束的惩罚项。速度估计置信区间可通过求解后验协方差（Gauss-Newton/Hessian近似）或Monte Carlo模拟像素噪声传播得到。\n\n对水面场景与反射处理：水面呈镜像反射，会给匹配带来镜像特征。首先运用语义分割或基于纹理的水域检测分割出水面区域并在该区域内鉴别真实纹理与其镜像（镜像关于水面中线对称）。若测量对象（桥、轨道）有对应水面的镜像，应识别并利用桥面与其镜像间的中线（即水面位置与水面法线）以计算桥面距离水面的高度。若轨道可见，可利用标准轨距 g=1.435 m 作尺度定标（高铁多为标准轨距），从而测桥面到水面的绝对高度及到轨道的水平距离。高铁速度可用沿水面或地面上跟踪的静态特征的世界坐标随时间变化计算，或通过匹配图像上同一地面点在连续帧中的视差并已知尺度与帧率计算速度：v = ΔX/Δt。注意水面闪烁与反射带来的匹配错误需用RANSAC与时间平滑滤波剔除。\n\n无人机航拍场景的特殊处理：无人机视角多为俯视，若有影像元数据（EXIF中的焦距、GPS高度、云台俯仰角）应优先利用以直接恢复尺度与位姿；若无，可利用地面可识别物（车辆、道路宽度、地砖等）作为尺度锚，通过多视点稠密匹配（SfM + MVS）生成点云并拟合地面平面与建筑物边界，然后用平面投影得到占地面积与道路长度。建筑高度可使用立体重建得到的点云垂直跨度或使用影像中的投影比与消失点方法（同单幅高度测量）估算。无人机飞行高度若无直接遥测，可由地面参考对象尺寸与影像中投影尺度反推，同样可通过光束法求解相机外参与高度。无人机速度通过在连续帧间限定的地面特征运动计算，或通过在图像序列中解算相邻相机位姿并计算相机中心的位移/Δt直接得到。\n\n求解策略与数值实现要点：预处理包括畸变矫正（若存在显著畸变则用OpenCV的畸变校正基于标定或自标定方法）、图像增强与稳定化（对抖动大的视频可先做全局帧间配准或视频稳定化）。然后进行特征检测/匹配与RANSAC求单应或基本矩阵，求消失点与单应矩阵H，基于H和尺度锚反投影到地面坐标，计算所需距离或长度。对于多帧任务，构建滑动窗口Bundle Adjustment（参数为多帧相机位姿与若干3D点，代价为重投影误差加尺度先验项），用Levenberg-Marquardt优化（如Ceres solver）求解。对于速度估计，优先对同一刚体点序列做线性化的差分估计并用卡尔曼滤波或鲁棒滤波器平滑时间序列。不确定性估计通过两种方式：对线性化解可用雅可比与协方差传播计算置信区间；对更复杂情况采用Monte Carlo仿真，随机扰动像素位置、焦距与尺度锚值，重复解算得到统计分布。计算资源需求取决于图像分辨率与优化窗口大小：常规720p或1080p影像做特征匹配与小规模BA可在普通工作站（8-16核CPU，1-2 GPU用于加速特征与深度网络）上实时或近实时处理；更大规模稠密重建或长序列BA可能需要并行化或分段处理。\n\n敏感性与鲁棒性分析：对关键参数（焦距 f、尺度锚 L_ref、像素定位误差 σ_p、地面倾角误差 θ）做局部灵敏度分析，计算输出（距离/高度/速度）的偏导数，如 ∂d/∂f, ∂d/∂L_ref 等，或通过Monte Carlo给出置信区间。在报告中以条件化结论呈现结果，例如“在地砖尺寸为0.80±0.01 m且焦距估计相对误差不超过±2%条件下，塔体AB长度为 X±Δ m（95%置信）”。对镜面、反射与动态遮挡等非理想因素，应给出替代假设场景并分别计算结果以说明稳健性。\n\n验证、扩展与数据驱动融合：模型验证通过交叉验证（若场景中存在多个尺度锚可互相验证），或用人工量测的若干地面真值点进行残差统计。为提高在纹理稀少（如水面）情境下的鲁棒性，可把基于学习的单目深度估计网络（如MiDaS或DPT）作为先验补充到BA中，赋予深度先验的正则化项，并用已知尺度锚做后验定标。对长期改进，可引入IMU/GNSS数据与视觉-惯性紧耦合（VIO）以解除尺度与漂移问题，或在无人机场景中加入多传感器遥测融合以提高航高与速度估计精度。关于任务特定的扩展：后视镜场景应尝试估计镜面曲率参数并用镜像模型校正；水面场景应加入镜像检测与极线几何以识别误匹配；无人机场景在可能条件下应该尽量获取EXIF或遥测以直接定标。\n\n结论性陈述：本建模框架把几何解析与时序估计、有监督尺度锚与概率化误差分析有机结合，既能用单幅图像通过单应与消失点测量地面长度与高度，也能利用视频中的运动信息与Bundle Adjustment得到时间序列的相对/绝对速度。通过明示假设并对关键假设进行敏感性分析与蒙特卡洛不确定性量化，可以在实际应用中提供可用的度量结果及其置信区间。随着外部信息（轨距、地砖尺寸、EXIF/GPS/IMU）的增加与数据驱动先验（深度网络）融合，模型的精度与鲁棒性将进一步提升，能满足任务1至任务4中对距离、尺寸、高度与速度的工程化量测需求。",
  "task_descriptions": [
    "子任务1（数据预处理、相机内外参估计与尺度锚识别）旨在把原始图像和视频转化为几何可用的、经校正且带不确定度评估的输入，并输出（1）矫正后的影像序列或关键帧、（2）相机内参与畸变参数及其不确定性、（3）候选尺度锚（位置与置信度）、（4）地面平面单应或相机相对于地面/参考平面的初步外参估计、以及（5）用于后续几何测量的语义掩码和诊断信息；为此本子任务按以下步骤和方法执行：首先读取并解析输入文件（图像、视频流、帧率、时间戳及可用的EXIF/telemetry），并按需求抽取关键帧；其次进行影像预处理：去噪、对比度增强并在视频上做全局运动估计/稳定（基于特征匹配与全局仿射/单应配准）以减少抖动对后续几何估计的影响；然后进行畸变与内参的初步确定：若存在厂商EXIF或已知传感器参数则作为初始值，否则通过检测图像中的直线（LSD/Hough）并用平行线群集求消失点估计主点与焦距（构建K的初值），并检测径向/切向畸变（Brown–Conrady模型 k1,k2,k3,p1,p2）以供校正；内参与畸变可用OpenCV标定、或基于直线/消失点的自标定初始化，再用以最小化重投影误差的非线性优化（Levenberg–Marquardt/Ceres）精化并输出协方差估计或通过Bootstrap/Monte Carlo采样量化不确定性。与此同时执行语义分割与几何要素检测（利用预训练分割模型如 DeepLabv3/HRNet 或传统颜色/纹理分割）以标注地面、道路、地砖、轨道、水面、车辆与镜面区域；在语义掩码基础上检测并提取尺度锚候选：对地砖使用方形/网格检测（角点检测+Hough或连通域与正交性约束）拟合规则格网并用RANSAC拟合平面单应H；对轨道检测两条平行铁轨线段并对其像平行性与已知轨距生成尺度候选；对车辆采用模板匹配或检测器（YOLO/Mask R-CNN）并结合常见车辆尺寸做备用尺度锚；同时对可能的镜面（后视镜、水面）进行检测（基于高亮、局部对称性与反射纹理）并标注为需要特殊处理的区域。对每种候选尺度锚执行位置精度评估与一致性检验：用RANSAC剔除异常点、用单应H的内点比例和重投影误差判定可靠性，并计算尺度锚对由像素到世界尺度因子的影响与不确定度传播（对像素测量噪声、焦距与锚尺寸先验做敏感性分析）。最终输出包括：经畸变校正的影像或关键帧、估计的K = diag(fx,fy) with (cx,cy) 与畸变系数及其置信区间、每个候选尺度锚的位置与类型（地砖格、轨距、车辆等）与置信度分数、基于锚和内参解出的地面单应H及其不确定度估计、语义掩码和诊断日志（如内参来源、重投影残差统计、RANSAC内点比率）；若未检测到可信尺度锚则明确返回“仅相对尺度可用”并建议获取外部尺度信息。实现工具建议包括 OpenCV（畸变校正、特征、RANSAC、单应估计）、线检测与消失点算法（LSD、Hough、聚类交点）、深度语义分割模型（预训练网络）、非线性优化库（Ceres/LM）、以及用于不确定性评估的Monte Carlo或Bootstrap脚本；输入要求为原始图像/视频文件和（若有）任何可用的传感器元数据或尺度先验，输出必须以机器可读的格式记录参数、光栅化掩码和误差度量以便下游复用。",
    "子任务2（单幅图像的平面单应与垂直消失点几何测量）旨在用一幅静态图像在已知或可估相机内参与至少一个已知真实长度的平面尺度锚下，精确计算地面平面上任意两点之间的水平距离以及图中竖直方向的物体高度，并给出误差估计；其工作范围包括（1）输入：待测单幅图像（可含EXIF焦距/传感器信息）、像素坐标或语义掩码中标注的测量关键点（例如车头、路侧边界、塔体顶端/底端等）和至少一个平面尺度锚的真实长度L_ref（例如地砖边长或轨距）；（2）预处理：若存在畸变则先基于已知内参或通过直线自标定估计并用OpenCV undistort校正图像，必要时增强对比度以利于直线/角点检测；（3）地面平面单应求解：在语义掩码或角点检测（如Harris/FAST +角点聚类）结果上提取至少四对地面平面对应点，使用DLT结合RANSAC求解平面单应矩阵H（并输出内点比率与重投影残差），若无已知内参可用则把H分解为K[r1 r2 t]并通过消失点约束或EXIF信息估计K的初值；（4）尺度定标与逆映射：利用已知尺度锚计算由像素到地面平面真实坐标的尺度因子，将图像中任意地面像素逆变换为实际平面坐标并据此计算两点间欧氏距离；（5）竖直高度测量：在图像中检测多条对应世界竖直方向的直线（LSD或Hough +线段聚类），用这些直线交点在图像上鲁棒估计竖直消失点v_y（RANSAC聚类），在已知某参考垂直高度H_ref及其图像顶底像点(y_ref_top,y_ref_base)的条件下通过投影比/相似三角关系 H_target = H_ref * ((y_top - v_y)/(y_base - v_y)) / ((y_ref_top - v_y)/(y_ref_base - v_y)) 计算目标高度；（6）不确定度评估与一致性检测：对像素定位噪声、焦距和锚长度不确定性做雅可比矩阵线性化传播或用Monte Carlo采样（扰动像素点、f和L_ref）得到测量的置信区间，同时检验单应条件数、重投影误差和消失点估计方差以判定测量可靠性；（7）实现细节与工具建议：可用OpenCV实现特征/直线检测、findHomography（RANSAC）、undistort和重投影计算，使用SVD分解与最小二乘精化单应与消失点，必要时用Ceres/LM对H与K联合非线性优化以最小化重投影误差并输出协方差估计；（8）输出要求：对每一对测量点输出实际坐标、测距或高度值以及95%置信区间、重投影残差统计和内点比率，并以条件化语句明确列出关键假设（地面共面、目标竖直于地面、镜头可用针孔模型近似等）以便结果的可解释性与复现。",
    "子任务3（视频时序结构—运动恢复与速度估计）旨在利用单目视频序列在时间域内恢复相机相对位姿与场景三维结构并据此估算相机与场景中刚体的速度，输出包括随时间的相机位姿轨迹（相机中心在三维空间的位置，若提供尺度锚则为公制坐标）、三维稀疏点云、各时刻的速度向量及其不确定度估计；其输入为原始视频文件（或按帧提取的图像序列）、帧率信息、（可选）相机内参初值或标定结果以及（可选）尺度先验或外部遥测（IMU/GNSS/已知物距），工作范围限定为单目视觉测量与基于视觉的尺度定标融合。实现步骤为：1) 预处理——按帧提取与去畸变（若内参可用），并按需做基础去噪与曝光一致化；2) 特征建立与跟踪——在每帧检测局部不变特征（如 SIFT/ORB）并用描述子匹配或稠密/稀疏光流（KLT/TV-L1）建立跨帧对应，过滤重复与不可靠点；3) 两帧几何估计与筛选——采用八点法/五点法联合 RANSAC 求解基础矩阵/本质矩阵并剔除外点；4) 相对位姿恢复与三角化——由本质矩阵分解得到相对旋转 R 和方向性平移 t，使用多视角三角化为初始稀疏三维点云；5) 时域优化（滑动窗口 Bundle Adjustment）——在滑动时间窗口内同时优化若干帧的相机位姿与三维点以最小化重投影误差，优化中可加入尺度约束项（来自已知距离、地面平面单应或外部传感器）以恢复绝对尺度，使用鲁棒损失函数（Huber/Tukey）和非线性求解器（如 Ceres/g2o）；6) 速度计算与平滑——由相邻关键帧或优化后相机中心轨迹差分获得瞬时速度，或对特定三维点轨迹求导得到物体速度，并使用卡尔曼滤波或鲁棒平滑器对速度序列降噪与融合外部速率测量；7) 异常情形处理——对动态场景或多刚体运动进行运动分割以隔离静态背景用于位姿估计，对滚动快门和运动模糊采用对应模型（逐行时间校正或局部时间偏移参数化）并在优化中联合估计；8) 不确定性量化——通过优化后Hessian逆近似估计参数协方差或以蒙特卡洛像素扰动/内参扰动重复优化得到速度与位姿的置信区间；9) 输出与诊断——导出时间序列位姿、稀疏点云、速度数值及其置信区间、重投影残差统计与内点比率以供验证。建议采用的工具与算法组件包括 OpenCV（帧处理、特征检测/匹配、光流、基本矩阵求解）、Ceres/g2o（非线性优化与滑动窗口 BA）、可选的 SfM 软件（COLMAP）用于初始稀疏重建，以及标准匹配器（FLANN/BF）、描述子（SIFT/ORB）和滤波器（Kalman/TS）。",
    "子任务4（稠密重建与无人机航拍测量与验证融合）旨在从无人机影像序列生成可度量的三维表征并用其计算道路长度与宽度、各建筑物与树木高度、占地面积以及无人机飞行高度与速度，并对结果进行度量不确定性评估与交叉验证；其工作范围包括：输入——原始影像或视频（按帧抽取的影像序列）、帧率与时间戳及任何可用的影像元数据/遥测（EXIF焦距、GPS/高度/航向/IMU）；预处理——按合适间隔抽取关键帧、进行相机畸变校正与颜色一致化、剔除模糊帧并记录每帧的时间戳；稠密重建流程——用结构自运动(SfM)工具（例如COLMAP/VisualSFM）进行特征检测、匹配与多视几何求解以恢复相机内外参与稀疏点云，随后用多视深度估计/多视立体(MVS)方法（例如OpenMVS、PMVS或PatchMatch）生成稠密点云并通过法线估计与滤波（统计离群点剔除与体素下采样）清理点云；尺度与地理配准——若存在GPS/遥测则直接用于尺度和地理位姿定标，否则通过图像中已知尺寸的尺度锚（道路宽度、车辆或地面标识）或地面控制点在稀疏点云上执行尺度因子拟合与刚体变换以获得公制坐标系；地面建模与要素提取——用RANSAC拟合地面/路面平面并生成数字地面模型(DTM)与数字表面模型(DSM)（从稠密点云栅格化得到），用语义分割或基于点云的聚类（例如用预训练的DeepLab/Mask R-CNN对影像进行语义分割，或用点云法线与高度特征分割建筑、树木、道路）提取道路边界、建筑轮廓与树冠；几何量化——在地面平面坐标系上通过投影和多边形几何计算道路中心线长度、道路宽度统计（沿中心线测量多点截面距离）、各建筑物占地多边形及其投影面积，建筑与树木高度由DSM与DTM的高度差（或点云在竖直方向的最大值减地面值）计算，所有测量均在定标尺度下以米为单位输出；无人机飞行高度与速度——通过求解每个关键帧的相机中心到拟合地面平面的垂直距离得到瞬时飞行高度，速度通过关键帧相机中心位置关于时间的差分或直接利用遥测速度数据计算并用平滑滤波（卡尔曼或低通滤波）降低噪声；误差估计与验证——利用重投影残差与BA后位姿协方差估计测量不确定性，采用Monte Carlo像素扰动或尺度锚扰动评估对最终几何量的敏感性，并用多源交叉验证（如用道路宽度与车辆尺寸互检或用已知地物检测结果比较遥测）识别系统性偏差；输出工件——经清理的稠密点云（PLY/LAZ）、DSM/DTM栅格、正射影像（GeoTIFF）、建筑/道路/树木的矢量多边形与测量表（含95%置信区间）、相机位姿时间序列与飞行速度剖面、处理日志与质量指标（点云密度、重投影误差、内点比率）；建议工具链包括COLMAP或相应SfM软件、OpenMVS/PMVS或PatchMatch MVS、OpenCV（预处理）、Ceres/g2o（可选的非线性优化）、PCL/PDAL用于点云处理、GDAL/OGR或Shapely用于栅格/矢量操作，以及深度学习语义分割模型用于要素提取；在没有遥测的情形下，明确要求至少一个可靠的尺度锚或地面控制点以输出公制测量并在报告中给出基于该锚的不确定性评估。"
  ]
}