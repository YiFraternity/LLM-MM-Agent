{
  "tasks": [],
  "problem_str": "问题背景：\n视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。\n\n目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。\n\n下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据$X \\in \\mathbb{R}^{w \\times h \\times t}$，其中$w, h$代表视频帧的长、宽，$t$代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即$X = \\{x_1, x_2, \\dots, x_t\\}$，其中$x_i \\in \\mathbb{R}^{w \\times h} (i = 1, 2, \\dots, t)$为一张长宽分别为$w, h$的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0, 1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红）、G（绿）、B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片\\section*{构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在 Matlab 环境下，视频的读取、播放及相应基本操作程序见附件 1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。}\n\n题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。\n\n问题要求：\n请你们查阅相关资料和数据，结合视频数据特点，回答下列问题：\n\n\\textbf{问题 1：} 对一个不包含动态背景、摄像头稳定拍摄时间大约 5 秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图 1 的应用效果。（附件 2 提供了一些符合此类特征的监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{image1.png}\n    \\includegraphics[width=0.45\\textwidth]{image2.png}\n    \\caption{左图：原视频帧；右图：分离出的前景目标}\n    \\label{fig:1}\n\\end{figure}\n\n\\textbf{问题 2：} 对包含动态背景信息的监控视频（如图 2 所示），设计有效的前景目标提取方案。（附件 2 中提供了一些符合此类特征的典型监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.24\\textwidth]{image3.png}\n    \\includegraphics[width=0.24\\textwidth]{image4.png}\n    \\includegraphics[width=0.24\\textwidth]{image5.png}\n    \\includegraphics[width=0.24\\textwidth]{image6.png}\n    \\caption{几种典型的动态视频背景：树叶摇动，水波动，喷泉变化，窗帘晃动}\n    \\label{fig:2}\n\\end{figure}\n\n\\textbf{问题 3：} 在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件 2 中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从\\begin{itemize}\n    \\item 问题4：在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。\n    \\item 问题5：如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从 \\url{http://cvlab.epfl.ch/research/surv/multi-people-tracking} 下载）。\n\\end{itemize}\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\textwidth]{image.png}\n    \\caption{在室内同一时间从不同角度拍摄同一地点获得的视频帧}\n    \\label{fig:3}\n\\end{figure}\n\n\\begin{itemize}\n    \\item 问题6：利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证）\n\\end{itemize}\n\n\\textbf{注：} 强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。\nAddendum: \n参考文献：\n[1] Andrews Sobral & Antoine Vacavant, A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos, Computer Vision and Image Understanding, Volume 122, May 2014, Pages 4-21\n[2] B. Lee and M. Hedley, “Background estimation for video surveillance,” IVCNZ02, pp. 315–320, 2002.\n[3] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture models for real-time tracking,” in Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., vol. 2. IEEE, 1999.\n[4] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?” Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011.\n[5] D. Meng and F. De la Torre, “Robust matrix factorization with unknown noise,” in IEEE International Conference on Computer Vision, 2013, pp. 1337–1344.\n[6] Q. Zhao, D. Meng, Z. Xu,W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 55–63.\n[7] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 11, pp. 2233–2246, 2012.\n[8] M. Babaee, D. T. Dinh, and G. Rigoll, “A deep convolutional neural network for background subtraction,” arXiv preprint arXiv: 1702.01731, 2017.\n\nDataset Path:\n['avi2img.m', 'avi2mat.m', 'img2avi.m', 'readme.txt', 'run_vedio.m', '不带晃动-动态背景', '不带晃动-静态背景', '有晃动', 'campus', 'curtain', 'escalator', 'fountain', 'hall', 'lobby']\n\nData Description:\n该数据集由若干用于视频处理的 MATLAB 脚本和多个监控视频子集组成，脚本部分包括用于将 AVI 视频逐帧读出并保存为灰度 JPEG 的 avi2img.m、将一系列单帧图像拉伸为列向量并保存为 MAT 矩阵的 avi2mat.m、将按序 JPEG 图像写回为 AVI 视频的 img2avi.m、用于读取并按帧播放视频的 run_vedio.m 以及包含脚本说明的 readme.txt，脚本中常见的数据对象与变量有 VideoReader/VideoWriter 对象、帧计数与帧数组（如 vidFrames、mov）、单帧图像与灰度图（frame、gray_frame）、拉伸后组成列向量的矩阵 XX 及其尺寸信息 siz、以及用作循环索引的 k 等；视频数据按场景与背景特性组织，包括“不带晃动-静态背景”（如 smoke、pedestrian、office、airport、hall 等子文件夹）、“不带晃动-动态背景”（如 waterSurface，用于考察水面等动态背景下的前景分离）、“有晃动”（包含 cars7、cars6、people2、people1 等子文件夹以测试不同类型目标的提取）以及若干独立场景数据集如 campus、curtain、escalator、fountain、hall、lobby 等，这些场景通常以固定摄像头拍摄、时长约 5 秒，并配有同名或相关的 MAT 文件作为元数据或标注以辅助分析；总体上该数据集适用于研究与验证前景目标提取、背景建模和视频帧处理流水线（包括帧提取、灰度化、向量化存储、重构视频和播放）的算法与实现。",
  "problem": {
    "background": "视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。\n\n目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。\n\n下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据$X \\in \\mathbb{R}^{w \\times h \\times t}$，其中$w, h$代表视频帧的长、宽，$t$代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即$X = \\{x_1, x_2, \\dots, x_t\\}$，其中$x_i \\in \\mathbb{R}^{w \\times h} (i = 1, 2, \\dots, t)$为一张长宽分别为$w, h$的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0, 1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红）、G（绿）、B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片\\section*{构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在 Matlab 环境下，视频的读取、播放及相应基本操作程序见附件 1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。}\n\n题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。",
    "problem_requirement": "请你们查阅相关资料和数据，结合视频数据特点，回答下列问题：\n\n\\textbf{问题 1：} 对一个不包含动态背景、摄像头稳定拍摄时间大约 5 秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图 1 的应用效果。（附件 2 提供了一些符合此类特征的监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{image1.png}\n    \\includegraphics[width=0.45\\textwidth]{image2.png}\n    \\caption{左图：原视频帧；右图：分离出的前景目标}\n    \\label{fig:1}\n\\end{figure}\n\n\\textbf{问题 2：} 对包含动态背景信息的监控视频（如图 2 所示），设计有效的前景目标提取方案。（附件 2 中提供了一些符合此类特征的典型监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.24\\textwidth]{image3.png}\n    \\includegraphics[width=0.24\\textwidth]{image4.png}\n    \\includegraphics[width=0.24\\textwidth]{image5.png}\n    \\includegraphics[width=0.24\\textwidth]{image6.png}\n    \\caption{几种典型的动态视频背景：树叶摇动，水波动，喷泉变化，窗帘晃动}\n    \\label{fig:2}\n\\end{figure}\n\n\\textbf{问题 3：} 在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件 2 中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从\\begin{itemize}\n    \\item 问题4：在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。\n    \\item 问题5：如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从 \\url{http://cvlab.epfl.ch/research/surv/multi-people-tracking} 下载）。\n\\end{itemize}\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\textwidth]{image.png}\n    \\caption{在室内同一时间从不同角度拍摄同一地点获得的视频帧}\n    \\label{fig:3}\n\\end{figure}\n\n\\begin{itemize}\n    \\item 问题6：利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证）\n\\end{itemize}\n\n\\textbf{注：} 强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。",
    "dataset_path": [
      "avi2img.m",
      "avi2mat.m",
      "img2avi.m",
      "readme.txt",
      "run_vedio.m",
      "不带晃动-动态背景",
      "不带晃动-静态背景",
      "有晃动",
      "campus",
      "curtain",
      "escalator",
      "fountain",
      "hall",
      "lobby"
    ],
    "dataset_description": {
      "avi2img": "该文件 'avi2img.m' 的用途是将视频文件 'campus5.avi' 转换为一系列灰度图像，并保存为 JPEG 格式的图片文件。具体步骤包括读取视频文件、逐帧处理视频帧、将彩色帧转换为灰度帧、显示每一帧，并将每一帧保存为单独的图片文件。",
      "avi2mat": "该文件 'avi2mat.m' 是一个 MATLAB 脚本，用于将一系列单帧图片转换为向量并存储为 MATLAB mat 文件。具体来说，'avi2mat.m' 脚本读取指定文件夹中的所有 JPG 图片，将每张图片拉伸为一个列向量，并将所有列向量存储为一个矩阵。最后，该矩阵及其尺寸信息被保存为一个名为 'campus5' 的 mat 文件。",
      "img2avi": "该文件 'img2avi.m' 是一个 MATLAB 脚本，用于将一系列 JPEG 图片文件转换为一个 AVI 视频文件。该脚本首先定义了图片文件所在的目录，然后读取该目录下的所有 JPEG 文件，并将这些图片按顺序写入到一个 AVI 文件中，形成一个视频。",
      "readme": "readme.txt是一个文本文件，包含了用于视频处理的几个Matlab脚本的简要描述。这些脚本主要用于视频到图像帧的转换、图像帧到向量的转换、向量到视频的转换以及视频的播放。",
      "run_vedio": "run_vedio.m 是一个 MATLAB 脚本文件，用于读取并播放视频文件 'highway_gray.avi'。该脚本读取视频的所有帧，并创建一个 MATLAB 视频播放结构体，最后按照视频的帧速率重播视频。",
      "不带晃动-动态背景": "不带晃动-动态背景文件夹包含一个名为'waterSurface'的子文件夹，内含符合特定特征的监控视频数据。这些视频数据主要用于研究和测试在不同背景条件下（包括静态和动态背景）的前景目标（如人、车、动物等）提取技术。具体而言，'waterSurface'文件夹中的视频数据旨在探索在动态背景（例如水面波动）下的前景目标提取方法。这些视频时长约为5秒，摄像头稳定，不包含动态背景的视频可用于验证和优化静态背景下的前景目标提取模型。",
      "不带晃动-静态背景": "不带晃动-静态背景数据集包含多个子文件夹，每个子文件夹代表不同场景下的监控视频片段。具体包括：smoke（烟雾场景）、pedestrian（行人场景）、office（办公室场景）、airport（机场场景）、hall（大厅场景）。这些视频片段主要用于研究和测试监控视频中的前景目标提取技术，包括但不限于人、车、动物等。不带晃动-静态背景数据集中的视频片段时长约为5秒，摄像头稳定，背景相对静态或动态。",
      "有晃动": "有晃动文件夹包含四个子文件夹：cars7, cars6, people2, people1。这些子文件夹分别存储了不同类型的监控视频片段，旨在用于测试和验证前景目标（如车辆和行人）的提取算法。每个子文件夹中的视频具有不包含动态背景、摄像头稳定拍摄时间大约5秒的特点，适用于构建和测试提取前景目标的数学模型。",
      "campus": "campus文件夹包含两个文件：Campus.mat 和 Campus.avi。Campus.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Campus.mat 可能是与视频相关的元数据或标注文件，用于辅助视频分析任务，如前景目标提取。",
      "curtain": "curtain文件夹包含两个文件：Curtain.mat 和 Curtain.avi。Curtain.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Curtain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。curtain数据集适用于研究和实现提取视频中前景目标（如人、车、动物等）的数学模型和求解方法。",
      "escalator": "该文件夹包含一个名为'Escalator'的数据集，其中包括一个监控视频文件'escalator/Escalator.avi'和一个相关的MAT文件'escalator/Escalator.mat'。监控视频文件记录了在固定摄像头下拍摄的约5秒的电梯扶梯场景，背景相对稳定，无明显动态变化。MAT文件可能包含了视频的元数据、标注信息或其他辅助数据，用于支持视频分析任务，如前景目标（例如人、动物等）的提取。该数据集适用于研究和测试在静态背景条件下从监控视频中分离前景目标的技术。",
      "fountain": "文件夹fountain包含两个文件：Fountain.avi 和 Fountain.mat。Fountain.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄的场景，视频时长约为5秒。Fountain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。该数据集适用于研究和测试在稳定摄像头拍摄条件下提取前景目标（如人、车、动物等）的算法。",
      "hall": "该文件夹包含两个文件：hall.mat 和 hall.avi。hall.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄时间约为5秒的场景。hall.mat 是一个 MATLAB 数据文件，可能包含与 hall.avi 视频相关的元数据或标注信息。hall 适用于研究和测试在静态背景下的前景目标（如人、车、动物等）提取算法。",
      "lobby": "该文件夹包含两个文件：Lobby.mat 和 Lobby.avi。Lobby.mat 可能是一个 MATLAB 数据文件，用于存储相关数据或元数据。Lobby.avi 是一个监控视频文件，可能用于展示或测试监控视频中的前景目标提取技术。需要注意的是，文件名 'Lobyy.avi' 中存在拼写错误，可能是 'Lobby.avi' 的误写。lobby 文件夹包含这些文件。"
    },
    "variable_description": [
      {
        "file_name": "视频文件 'avi2img.m' 的路径和名称",
        "obj": "VideoReader 对象，用于读取和处理视频文件 'avi2img.m'",
        "numFrames": "视频文件 'avi2img.m' 中的总帧数",
        "frame": "从视频文件 'avi2img.m' 中读取的单帧图像",
        "gray_frame": "将读取的彩色帧转换为灰度帧后的图像",
        "k": "当前处理的视频文件 'avi2img.m' 的帧编号"
      },
      {
        "XX": "存储所有图片拉伸后的向量组成的矩阵，每一列代表一张图片的所有像素值。",
        "siz": "存储单张图片的尺寸信息，包括行数和列数。",
        "obj": "包含变量 'XX' 和 'siz' 的 MATLAB 对象，该对象被保存为 'avi2mat.m' 文件。"
      },
      {
        "DIR": "img2avi.m 中图片文件所在的目录路径",
        "file": "img2avi.m 中包含所有 JPEG 文件信息的结构体数组",
        "filenum": "img2avi.m 中 JPEG 文件的总数",
        "obj_gray": "img2avi.m 中用于写入视频的 VideoWriter 对象",
        "writerFrames": "img2avi.m 中视频的帧数",
        "fname": "img2avi.m 中当前处理的 JPEG 文件的完整路径",
        "frame": "img2avi.m 中当前处理的 JPEG 文件读取为图像矩阵",
        "k": "img2avi.m 中当前处理的 JPEG 文件的索引"
      },
      {},
      {
        "video": "VideoReader 对象，用于读取视频文件 'highway_gray.avi'",
        "vidFrames": "视频中所有帧的数据",
        "numFrames": "视频的总帧数",
        "mov": "一个包含所有视频帧的结构体数组，用于存储每一帧的图像数据",
        "hf": "创建的图像窗口句柄",
        "k": "循环变量，用于遍历视频帧",
        "video.Width": "视频的宽度",
        "video.Height": "视频的高度",
        "video.FrameRate": "视频的帧速率"
      },
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {}
    ],
    "addendum": "参考文献：\n[1] Andrews Sobral & Antoine Vacavant, A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos, Computer Vision and Image Understanding, Volume 122, May 2014, Pages 4-21\n[2] B. Lee and M. Hedley, “Background estimation for video surveillance,” IVCNZ02, pp. 315–320, 2002.\n[3] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture models for real-time tracking,” in Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., vol. 2. IEEE, 1999.\n[4] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?” Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011.\n[5] D. Meng and F. De la Torre, “Robust matrix factorization with unknown noise,” in IEEE International Conference on Computer Vision, 2013, pp. 1337–1344.\n[6] Q. Zhao, D. Meng, Z. Xu,W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 55–63.\n[7] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 11, pp. 2233–2246, 2012.\n[8] M. Babaee, D. T. Dinh, and G. Rigoll, “A deep convolutional neural network for background subtraction,” arXiv preprint arXiv: 1702.01731, 2017.\n",
    "data_summary": "Dataset Path:\n['avi2img.m', 'avi2mat.m', 'img2avi.m', 'readme.txt', 'run_vedio.m', '不带晃动-动态背景', '不带晃动-静态背景', '有晃动', 'campus', 'curtain', 'escalator', 'fountain', 'hall', 'lobby']\n\nData Description:\n该数据集由若干用于视频处理的 MATLAB 脚本和多个监控视频子集组成，脚本部分包括用于将 AVI 视频逐帧读出并保存为灰度 JPEG 的 avi2img.m、将一系列单帧图像拉伸为列向量并保存为 MAT 矩阵的 avi2mat.m、将按序 JPEG 图像写回为 AVI 视频的 img2avi.m、用于读取并按帧播放视频的 run_vedio.m 以及包含脚本说明的 readme.txt，脚本中常见的数据对象与变量有 VideoReader/VideoWriter 对象、帧计数与帧数组（如 vidFrames、mov）、单帧图像与灰度图（frame、gray_frame）、拉伸后组成列向量的矩阵 XX 及其尺寸信息 siz、以及用作循环索引的 k 等；视频数据按场景与背景特性组织，包括“不带晃动-静态背景”（如 smoke、pedestrian、office、airport、hall 等子文件夹）、“不带晃动-动态背景”（如 waterSurface，用于考察水面等动态背景下的前景分离）、“有晃动”（包含 cars7、cars6、people2、people1 等子文件夹以测试不同类型目标的提取）以及若干独立场景数据集如 campus、curtain、escalator、fountain、hall、lobby 等，这些场景通常以固定摄像头拍摄、时长约 5 秒，并配有同名或相关的 MAT 文件作为元数据或标注以辅助分析；总体上该数据集适用于研究与验证前景目标提取、背景建模和视频帧处理流水线（包括帧提取、灰度化、向量化存储、重构视频和播放）的算法与实现。",
    "data_description": {
      "avi2img": "该文件 'avi2img.m' 的用途是将视频文件 'campus5.avi' 转换为一系列灰度图像，并保存为 JPEG 格式的图片文件。具体步骤包括读取视频文件、逐帧处理视频帧、将彩色帧转换为灰度帧、显示每一帧，并将每一帧保存为单独的图片文件。",
      "avi2mat": "该文件 'avi2mat.m' 是一个 MATLAB 脚本，用于将一系列单帧图片转换为向量并存储为 MATLAB mat 文件。具体来说，'avi2mat.m' 脚本读取指定文件夹中的所有 JPG 图片，将每张图片拉伸为一个列向量，并将所有列向量存储为一个矩阵。最后，该矩阵及其尺寸信息被保存为一个名为 'campus5' 的 mat 文件。",
      "img2avi": "该文件 'img2avi.m' 是一个 MATLAB 脚本，用于将一系列 JPEG 图片文件转换为一个 AVI 视频文件。该脚本首先定义了图片文件所在的目录，然后读取该目录下的所有 JPEG 文件，并将这些图片按顺序写入到一个 AVI 文件中，形成一个视频。",
      "readme": "readme.txt是一个文本文件，包含了用于视频处理的几个Matlab脚本的简要描述。这些脚本主要用于视频到图像帧的转换、图像帧到向量的转换、向量到视频的转换以及视频的播放。",
      "run_vedio": "run_vedio.m 是一个 MATLAB 脚本文件，用于读取并播放视频文件 'highway_gray.avi'。该脚本读取视频的所有帧，并创建一个 MATLAB 视频播放结构体，最后按照视频的帧速率重播视频。",
      "不带晃动-动态背景": "不带晃动-动态背景文件夹包含一个名为'waterSurface'的子文件夹，内含符合特定特征的监控视频数据。这些视频数据主要用于研究和测试在不同背景条件下（包括静态和动态背景）的前景目标（如人、车、动物等）提取技术。具体而言，'waterSurface'文件夹中的视频数据旨在探索在动态背景（例如水面波动）下的前景目标提取方法。这些视频时长约为5秒，摄像头稳定，不包含动态背景的视频可用于验证和优化静态背景下的前景目标提取模型。",
      "不带晃动-静态背景": "不带晃动-静态背景数据集包含多个子文件夹，每个子文件夹代表不同场景下的监控视频片段。具体包括：smoke（烟雾场景）、pedestrian（行人场景）、office（办公室场景）、airport（机场场景）、hall（大厅场景）。这些视频片段主要用于研究和测试监控视频中的前景目标提取技术，包括但不限于人、车、动物等。不带晃动-静态背景数据集中的视频片段时长约为5秒，摄像头稳定，背景相对静态或动态。",
      "有晃动": "有晃动文件夹包含四个子文件夹：cars7, cars6, people2, people1。这些子文件夹分别存储了不同类型的监控视频片段，旨在用于测试和验证前景目标（如车辆和行人）的提取算法。每个子文件夹中的视频具有不包含动态背景、摄像头稳定拍摄时间大约5秒的特点，适用于构建和测试提取前景目标的数学模型。",
      "campus": "campus文件夹包含两个文件：Campus.mat 和 Campus.avi。Campus.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Campus.mat 可能是与视频相关的元数据或标注文件，用于辅助视频分析任务，如前景目标提取。",
      "curtain": "curtain文件夹包含两个文件：Curtain.mat 和 Curtain.avi。Curtain.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Curtain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。curtain数据集适用于研究和实现提取视频中前景目标（如人、车、动物等）的数学模型和求解方法。",
      "escalator": "该文件夹包含一个名为'Escalator'的数据集，其中包括一个监控视频文件'escalator/Escalator.avi'和一个相关的MAT文件'escalator/Escalator.mat'。监控视频文件记录了在固定摄像头下拍摄的约5秒的电梯扶梯场景，背景相对稳定，无明显动态变化。MAT文件可能包含了视频的元数据、标注信息或其他辅助数据，用于支持视频分析任务，如前景目标（例如人、动物等）的提取。该数据集适用于研究和测试在静态背景条件下从监控视频中分离前景目标的技术。",
      "fountain": "文件夹fountain包含两个文件：Fountain.avi 和 Fountain.mat。Fountain.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄的场景，视频时长约为5秒。Fountain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。该数据集适用于研究和测试在稳定摄像头拍摄条件下提取前景目标（如人、车、动物等）的算法。",
      "hall": "该文件夹包含两个文件：hall.mat 和 hall.avi。hall.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄时间约为5秒的场景。hall.mat 是一个 MATLAB 数据文件，可能包含与 hall.avi 视频相关的元数据或标注信息。hall 适用于研究和测试在静态背景下的前景目标（如人、车、动物等）提取算法。",
      "lobby": "该文件夹包含两个文件：Lobby.mat 和 Lobby.avi。Lobby.mat 可能是一个 MATLAB 数据文件，用于存储相关数据或元数据。Lobby.avi 是一个监控视频文件，可能用于展示或测试监控视频中的前景目标提取技术。需要注意的是，文件名 'Lobyy.avi' 中存在拼写错误，可能是 'Lobby.avi' 的误写。lobby 文件夹包含这些文件。"
    },
    "problem_str": "问题背景：\n视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。\n\n目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。\n\n下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据$X \\in \\mathbb{R}^{w \\times h \\times t}$，其中$w, h$代表视频帧的长、宽，$t$代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即$X = \\{x_1, x_2, \\dots, x_t\\}$，其中$x_i \\in \\mathbb{R}^{w \\times h} (i = 1, 2, \\dots, t)$为一张长宽分别为$w, h$的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0, 1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红）、G（绿）、B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片\\section*{构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在 Matlab 环境下，视频的读取、播放及相应基本操作程序见附件 1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。}\n\n题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。\n\n问题要求：\n请你们查阅相关资料和数据，结合视频数据特点，回答下列问题：\n\n\\textbf{问题 1：} 对一个不包含动态背景、摄像头稳定拍摄时间大约 5 秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图 1 的应用效果。（附件 2 提供了一些符合此类特征的监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{image1.png}\n    \\includegraphics[width=0.45\\textwidth]{image2.png}\n    \\caption{左图：原视频帧；右图：分离出的前景目标}\n    \\label{fig:1}\n\\end{figure}\n\n\\textbf{问题 2：} 对包含动态背景信息的监控视频（如图 2 所示），设计有效的前景目标提取方案。（附件 2 中提供了一些符合此类特征的典型监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.24\\textwidth]{image3.png}\n    \\includegraphics[width=0.24\\textwidth]{image4.png}\n    \\includegraphics[width=0.24\\textwidth]{image5.png}\n    \\includegraphics[width=0.24\\textwidth]{image6.png}\n    \\caption{几种典型的动态视频背景：树叶摇动，水波动，喷泉变化，窗帘晃动}\n    \\label{fig:2}\n\\end{figure}\n\n\\textbf{问题 3：} 在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件 2 中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从\\begin{itemize}\n    \\item 问题4：在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。\n    \\item 问题5：如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从 \\url{http://cvlab.epfl.ch/research/surv/multi-people-tracking} 下载）。\n\\end{itemize}\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\textwidth]{image.png}\n    \\caption{在室内同一时间从不同角度拍摄同一地点获得的视频帧}\n    \\label{fig:3}\n\\end{figure}\n\n\\begin{itemize}\n    \\item 问题6：利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证）\n\\end{itemize}\n\n\\textbf{注：} 强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。\nAddendum: \n参考文献：\n[1] Andrews Sobral & Antoine Vacavant, A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos, Computer Vision and Image Understanding, Volume 122, May 2014, Pages 4-21\n[2] B. Lee and M. Hedley, “Background estimation for video surveillance,” IVCNZ02, pp. 315–320, 2002.\n[3] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture models for real-time tracking,” in Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., vol. 2. IEEE, 1999.\n[4] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?” Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011.\n[5] D. Meng and F. De la Torre, “Robust matrix factorization with unknown noise,” in IEEE International Conference on Computer Vision, 2013, pp. 1337–1344.\n[6] Q. Zhao, D. Meng, Z. Xu,W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 55–63.\n[7] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 11, pp. 2233–2246, 2012.\n[8] M. Babaee, D. T. Dinh, and G. Rigoll, “A deep convolutional neural network for background subtraction,” arXiv preprint arXiv: 1702.01731, 2017.\n\nDataset Path:\n['avi2img.m', 'avi2mat.m', 'img2avi.m', 'readme.txt', 'run_vedio.m', '不带晃动-动态背景', '不带晃动-静态背景', '有晃动', 'campus', 'curtain', 'escalator', 'fountain', 'hall', 'lobby']\n\nData Description:\n该数据集由若干用于视频处理的 MATLAB 脚本和多个监控视频子集组成，脚本部分包括用于将 AVI 视频逐帧读出并保存为灰度 JPEG 的 avi2img.m、将一系列单帧图像拉伸为列向量并保存为 MAT 矩阵的 avi2mat.m、将按序 JPEG 图像写回为 AVI 视频的 img2avi.m、用于读取并按帧播放视频的 run_vedio.m 以及包含脚本说明的 readme.txt，脚本中常见的数据对象与变量有 VideoReader/VideoWriter 对象、帧计数与帧数组（如 vidFrames、mov）、单帧图像与灰度图（frame、gray_frame）、拉伸后组成列向量的矩阵 XX 及其尺寸信息 siz、以及用作循环索引的 k 等；视频数据按场景与背景特性组织，包括“不带晃动-静态背景”（如 smoke、pedestrian、office、airport、hall 等子文件夹）、“不带晃动-动态背景”（如 waterSurface，用于考察水面等动态背景下的前景分离）、“有晃动”（包含 cars7、cars6、people2、people1 等子文件夹以测试不同类型目标的提取）以及若干独立场景数据集如 campus、curtain、escalator、fountain、hall、lobby 等，这些场景通常以固定摄像头拍摄、时长约 5 秒，并配有同名或相关的 MAT 文件作为元数据或标注以辅助分析；总体上该数据集适用于研究与验证前景目标提取、背景建模和视频帧处理流水线（包括帧提取、灰度化、向量化存储、重构视频和播放）的算法与实现。"
  },
  "problem_background": "视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。\n\n目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。\n\n下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据$X \\in \\mathbb{R}^{w \\times h \\times t}$，其中$w, h$代表视频帧的长、宽，$t$代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即$X = \\{x_1, x_2, \\dots, x_t\\}$，其中$x_i \\in \\mathbb{R}^{w \\times h} (i = 1, 2, \\dots, t)$为一张长宽分别为$w, h$的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0, 1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红）、G（绿）、B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片\\section*{构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在 Matlab 环境下，视频的读取、播放及相应基本操作程序见附件 1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。}\n\n题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。",
  "problem_requirement": "请你们查阅相关资料和数据，结合视频数据特点，回答下列问题：\n\n\\textbf{问题 1：} 对一个不包含动态背景、摄像头稳定拍摄时间大约 5 秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图 1 的应用效果。（附件 2 提供了一些符合此类特征的监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{image1.png}\n    \\includegraphics[width=0.45\\textwidth]{image2.png}\n    \\caption{左图：原视频帧；右图：分离出的前景目标}\n    \\label{fig:1}\n\\end{figure}\n\n\\textbf{问题 2：} 对包含动态背景信息的监控视频（如图 2 所示），设计有效的前景目标提取方案。（附件 2 中提供了一些符合此类特征的典型监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.24\\textwidth]{image3.png}\n    \\includegraphics[width=0.24\\textwidth]{image4.png}\n    \\includegraphics[width=0.24\\textwidth]{image5.png}\n    \\includegraphics[width=0.24\\textwidth]{image6.png}\n    \\caption{几种典型的动态视频背景：树叶摇动，水波动，喷泉变化，窗帘晃动}\n    \\label{fig:2}\n\\end{figure}\n\n\\textbf{问题 3：} 在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件 2 中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从\\begin{itemize}\n    \\item 问题4：在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。\n    \\item 问题5：如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从 \\url{http://cvlab.epfl.ch/research/surv/multi-people-tracking} 下载）。\n\\end{itemize}\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\textwidth]{image.png}\n    \\caption{在室内同一时间从不同角度拍摄同一地点获得的视频帧}\n    \\label{fig:3}\n\\end{figure}\n\n\\begin{itemize}\n    \\item 问题6：利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证）\n\\end{itemize}\n\n\\textbf{注：} 强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。",
  "problem_analysis": "本建模任务的宏观目标是：在不同监控场景下，设计一套既有物理意义又具工程可行性的数学模型与求解策略，自动从视频序列中分离出“前景目标”（移动或新出现的物体）并为后续跟踪、识别或异常事件检测提供可靠输入。这个总体目标直接塑造了研究路径：我们既要刻画背景与前景在统计与结构上的差异性（以便数学上可分离），又要考虑算法的稳健性、实时性与可扩展性以适应海量监控视频的工程要求。因此一个合理的建模思路通常同时包含三个层次：观测建模（如何以代数或概率形式描述视频帧序列）、先验设计（对背景/前景的结构性假设，例如低秩、稀疏、平滑、连通等）、以及求解策略（静态批处理/在线增量、优化算法或学习方法、工程加速与后处理）。这些目标对选取范式（如基于矩阵分解的凸优化、基于概率模型的混合模型、基于深度学习的端到端分割）有直接影响：若侧重稳健理论可解释性和少监督环境，低秩+稀疏分解（Robust PCA, PCP）是天然首选；若强调动态背景与复杂光照，需引入时空正则化或混合高斯/深度网络；若面对摄像头抖动，模型必须包含配准变量或运动补偿环节。\n\n在正式建模前需要识别并审视若干显性与隐性假设及其影响。常见隐含假设包括：摄像头短期内固定或相对稳定（否则背景可通过简单低秩近似）；前景在每帧像素占比较小（稀疏性假设）；背景随时间变化缓慢或受限于低维子空间（低秩假设）；短时序列内光照变化不剧烈；噪声为轻尾或可建模的独立项。这些假设直接决定了可行模型的有效性：若背景并不低秩（例如场景含周期性波动的大量动态细节），则纯RPCA会把背景结构误判为前景；若前景占比较大或持续占据同一位置（如长期停放车辆），稀疏性假设失效，分解亦不可靠。相反，放宽假设（例如允许背景为“稀疏+低秩+稠密”混合噪声）会增加模型复杂度与计算负担，但可提高鲁棒性。\n\n在组件关系与相互依赖上，视频建模本质上是“空间—时间—统计”三方面的耦合问题。空间上像素之间存在强烈相关性（局部连通性、边缘与形状连续性），时间上帧间存在高度相关的慢变背景与相对快速的前景运动，统计上噪声与异常事件决定模型的鲁棒性需求。不同组成部分之间可能出现张力：例如要求模型在时间上快速响应以捕捉短时移动（需要高时间分辨率与在线更新），又要在空间上保证前景分割连贯（需要空间正则化或大范围上下文），这两者在计算复杂度和参数选择上存在矛盾；再如对灵活性强的深度方法与可解释性强的凸优化方法之间的取舍亦属类似张力。解决这些矛盾常依赖于多阶段流水线：先用快速粗略方法（差分、运动检测）筛出候选帧/区域，再用结构化优化或学习方法精细分离与抑制误检。或者在一个联合模型中引入可分解模块（配准、低秩背景建模、稀疏前景、时空平滑），并设计交替优化策略以平衡各项。\n\n针对不同场景的具体模型示例及其相互关系如下。对“静态摄像机、静态背景、短时间”情况，经典且有效的数学表述是矩阵分解模型：将每帧向量化后构成数据矩阵 D，假设 D = L + S + N，其中 L 为低秩矩阵（代表背景的空间-时间相关结构），S 为稀疏矩阵（前景在像素-帧上的稀疏出现），N 为小幅噪声。相应的优化问题可写为 min_{L,S} ||L||_* + λ||S||_1 + (μ/2)||D-L-S||_F^2 或等价约束形式，这就是PCP/Robust PCA 框架。求解方法包括奇异值阈值法、交替方向乘子法（ADMM）、加速的近端算法及增量SVD实现；在实际工程中需注意对参数 λ 的选择（可基于噪声估计或交叉验证），并加入空间后处理（形态学开闭、连通域筛选）以消除噪点并恢复连贯目标。\n\n当背景带有周期性或局部动态（如树叶、水波、喷泉）时，单纯低秩假设往往不足。此时需要扩展模型：一类方法是将背景建模为低秩+稀疏的更细致分块（例如将背景分解为基底子空间加上周期性分量或纹理子空间），或者采用概率混合模型（per-pixel Gaussian mixture models, MOG）来允许每个像素在若干常见值之间切换；另一类做法使用带时空正则化的稀疏分解，如在 S 项加入 L2,1 或组稀疏促使前景在空间上连贯，或在 L 项中允许局部时间变换（子空间动态更新）来解释可重复的背景运动。算法上可采用在线子空间跟踪（GRASTA, OR-PCA, ReProCS）或引入周期性基函数/字典学习以适配动态纹理。对于强周期性背景，频谱分析或时域滤波（去除固定频率成分）也可作为预处理。\n\n摄像头抖动或全局运动情形需要先做全局配准或在分解中引入变换变量：经典R A S L（Robust Alignment by Sparse and Low-rank）将每帧图像视为经未知仿射变换 τ_i 的对齐图像，求解 min_{L,S,τ} ||L||_* + λ||S||_1 s.t. D∘τ = L+S。这类问题非凸但可通过交替迭代（先固定变换估计对齐，再分解，交替更新）求解；简化工程实践常采用直接估计帧间的全局运动（基于特征匹配或光流/相位相关）得到单应/仿射变换进行逆变换后再用静态相机方法处理。若抖动非全局（云台错误）或含透视变化，则需更精细的局部配准或基于光流的背景补偿。\n\n在多视角（同一场景不同角度）情形，可利用视角间的几何约束与前景一致性提升检测。模型可以扩展为多视图联合低秩分解或张量RPCA：把多摄像头数据按帧对齐或按时刻堆叠为高阶张量，利用背景在多视角下共享低维结构而前景在空间位置及投影上具有稀疏/结构化差异；也可基于几何校准建立像素到三维地面平面的映射，然后在地面平面上聚合多视角检测以提高鲁棒性。多视角的挑战包括同步误差、视角遮挡与不同摄像头的辐射不一致（色彩/亮度差异），需要在模型中加入校准/亮度归一化步骤与遮挡建模。\n\n前景分离之后的异常事件检测任务通常基于由前景得到的目标级或群体级特征：个体轨迹（位移、速度、加速度）、群体密度与速度场（流场）、方向分布熵、速度场的局部发散/旋度、轨迹聚类与突变检测、周期性能量（跳舞等）或高频能量激增（爆炸、建筑倒塌）。统计上可以构造基于历史正常行为的概率模型（如高斯混合模型、HMM、动态因子模型）或学习式模型（LSTM、1D/2D卷积时序网络）做异常检测。设计要点在于选择能区分异常的低维描述并兼顾对环境变化的鲁棒性；例如，人群惊慌通常表现为速度与方向分布的突变及密度快速变薄，而有组织列队则表现为速度/方向的低熵与周期性结构。\n\n模型设计与选择面临若干不确定性与风险：噪声模型错配、训练数据偏差、参数敏感性、实时性与内存限制、遮挡与小尺度目标的漏检、阴影与反射导致的误检、长期背景变化（季节、建筑改造）导致模型漂移、以及隐私/伦理问题。为了缓解这些风险，应采用迭代式建模流程：初期以简单可解释模型（如RPCA+形态学）快速建立基线并做错误诊断，针对典型失败模式引入有针对性的扩展（光照补偿、时空正则、变换变量、字典学习或深度模型），并在模型中保留可调超参数与诊断指标用于在线校准。此外，采用混合策略（将传统模型与深度学习结合，例如用深度网络学习前景先验或用RPCA的分解结果作为自监督标签）可以兼顾泛化与精度。\n\n在算法实现层面要兼顾精度与工程约束：批处理方法（核范数最小化）适合离线分析或短段高质量处理，在线/增量方法（子空间跟踪、随机优化）适合实时监控；在大分辨率或长时序下应采用帧采样、局部窗口、并行SVD/GPU加速与稀疏矩阵存储以减小开销。评估应使用一套多维指标（精确率/召回率/F1、IoU、帧率、内存使用）并在多类视频（静态/动态背景、抖动、多视角）上进行系统测试。\n\n最后强调模型构建的开放性：开始用尽可能少的假设建立基础框架，基于数据驱动地识别失败模式并逐步引入复杂性（更精确的噪声模型、变换变量、空间结构先验或学习组件）。在模型迭代过程中应以可解释性与可诊断性为指导，通过可视化残差、成分图和轨迹统计明确导致误差的原因，从而有针对性地改进。总体而言，分离前景目标是一个多尺度、多模块耦合的问题，理想方案是模块化、可扩展并能结合经典优化理论与现代学习方法，在工程上兼顾性能、鲁棒性与实时性。",
  "modeling_solution": "总体思路与目标概述：本方案给出一个统一且模块化的数学建模框架，用以从不同类型的监控视频中自动分离前景目标，并能扩展以处理动态背景、摄像头抖动（或仿射变换）、多视角数据和基于前景的异常事件检测。设计基于“低秩背景 + 稀疏前景 + 结构化/周期性背景分量 + 噪声 + 变换变量”的分解思想，结合优化与在线子空间跟踪、图像配准与时空正则化、以及后续的目标跟踪/统计特征抽取与异常判定。该框架在理论上继承并扩展了Robust PCA/PCP、RASL、字典学习与子空间跟踪等方法，在工程实现上允许分批（离线）或在线（实时）运行，并通过有效数值算子（奇异值阈值、软阈值、TV走査、随机SVD）与并行化策略保证可用性。\n\n主要假设与变量定义：假设短时段内（例如约5秒）的摄像头拍摄场景总体稳定（若存在抖动则可近似为每帧小幅仿射/刚性变换），背景的空间—时间结构可由低维子空间近似（即背景矩阵近似低秩），前景目标在像素域内稀疏出现且在空间上具有连通/平滑性质，动态背景（如树叶、水波）可表示为可预测或可稀疏表示的周期/纹理分量，观测噪声为小幅高斯或复合轻尾噪声。以向量化表示，令 x_i ∈ R^n 表示第 i 帧的灰度像素列向量（n = w·h），将 t 帧按列堆叠得到数据矩阵 D ∈ R^{n×t}。对于存在全局帧变换（摄像头抖动或偏移），引入每帧的仿射或仿射参数 τ_i（集合记作 τ），定义经 τ_i 变换后的帧为 x_i ◦ τ_i（反向采样/插值得到对齐像素列）。目标是估计背景基底矩阵 L（低秩）、前景稀疏矩阵 S、动态纹理/周期分量 T（可选）、小幅噪声 E 与变换参数 τ，使得对于每帧对齐后的数据成立近似分解关系 D ◦ τ = L + S + T + E，或若无抖动则为 D = L + S + T + E。本方案中L反映背景长期稳定成分，S反映前景目标稀疏像素，T用于捕获持续但非低秩的动态背景成分（例如水面波动），E为密集小幅噪声。\n\n优化模型与约束：给出以下泛化优化目标函数以联合估计各分量与可能的帧变换：\nmin_{L,S,T,τ} ||L||_* + λ_1 ||S||_1 + λ_2 R_space(S) + λ_3 Φ_T(T) + (μ/2)||D◦τ − L − S − T||_F^2,\n其中 ||L||_* 为矩阵核范数（鼓励低秩背景），||S||_1 为逐元素L1范数（鼓励稀疏前景），R_space(S) 为前景的空间结构正则项（例如各帧上的总变分TV或L_{2,1}以鼓励时空连贯），Φ_T(T) 为对动态背景分量的正则/先验（可选，包括字典稀疏表征 ||A||_1 在字典B上，或频谱稀疏性/低秩时序基表示），μ 为数据拟合权重。若处理摄像机抖动或帧偏移问题，则在约束中同时优化 τ。对于多视角情形，可以把每个摄像头k的观测D_k视为具有各自背景 L_k 与前景 S_k，但共享某些跨视角约束（例如在空间投影到公共地面平面后同一行人对应位置的一致性），可通过耦合项 ||P(L_1, ..., L_K) − L_consensus||_* 或张量核范数来建模视角间关联。\n\n对模型各项的具体解释与可选形式：R_space(S) 可以选择帧内全变分 TV(S(:,i)) 的和或时空总变分，以保证前景像素簇在空间上连通、边界清晰，也可采用图切分先验。在Φ_T可以有若干实现路径：若动态背景为局部重复纹理，可采用基于字典的稀疏表示，即 T = B·α，促使α稀疏并对B进行预学习或在线更新；若动态背景对应周期性分量可在时间轴上做低秩/频域分解并将该频域分量纳入T。对于噪声模型若为高斯可将拟合项改为 ||·||_F^2，若噪声为密集大幅异常（复合噪声），可在目标中加入附加鲁棒项或用分布式噪声模型分解为稀疏+高斯两部分。\n\n求解策略与数值方法：整体问题非凸但具有分解结构，采用交替最小化与变换线性化的策略。核心外循环按下述步骤迭代直到收敛或达到迭代上限：第1步（对齐/估计τ）：若存在抖动，保持当前 L,S,T 固定，估计每帧 τ_i。对于小变换可线性化灰度图像在变换参数处的雅可比，采用增量式Gauss–Newton或通过相位相关/FFT实现全局平移估计，或用特征匹配（SIFT/ORB）再估仿射矩阵。推荐的实现是将每帧与当前估计的背景基底重构 L(:,i) 做配准，通过求解最小二乘问题 argmin_{δτ_i} ||x_i ◦ (τ_i + δτ_i) − (L(:,i)+S(:,i)+T(:,i))||_2^2 近似得到更新。第2步（更新L）：固定其它项，更新低秩矩阵L 等价于求解带核范数正则的最小二乘问题，使用奇异值阈值（SVT）或增广拉格朗日（ALM/ADMM）子问题：L ← SVT_{1/μ}(D◦τ − S − T + (1/μ)Y)（Y为拉格朗日乘子），实际实现中用截断/随机化SVD减少成本（随机SVD、PROPACK或增量SVD）。第3步（更新S）：固定L,T，求解带L1和空间正则项的稀疏问题，可采用分解为逐元素软阈值与TV近端算子交替的形式，或用ADMM分裂S问题使得一部分为逐元素阈值（软阈值）另一部分为TV近端（用Chambolle算法求投影）。第4步（更新T）：根据所选Φ_T形式，用基于字典稀疏编码（Lasso）或在频域阈值化的解法求解；若选择时间上低秩表示，可用核范数近端算子类似L的更新。第5步（更新乘子与步长）：若用ADMM或ALM则更新乘子并调整步长。上述步骤交替进行直到收敛。对于实时应用，可把该批量流程改为在线/增量版本：采用OR-PCA、GRASTA或ReProCS等在线子空间跟踪算法对背景L递增更新，同时用稀疏回归/逐帧阈值检测S，并用光流或光学掩模完成短时跟踪与形态学平滑。在线方法中，配准步骤可用快速相位相关法或金字塔光流近似来实现每帧对齐。\n\n数值实现细节与加速：主计算瓶颈在核范数子问题中的奇异值分解（SVD），为降低成本应使用截断SVD或随机化SVD，仅保留前r个奇异向量（r可自适应通过硬阈值确定）；在高分辨率或长序列中可分块处理（时间滑动窗口），对每个时间窗口执行分解并以滑动窗口的子空间结果作为下一窗口的初值。并行化方面，帧配准、逐帧稀疏阈值化与TV近端都可并行化在多核/GPU上实现。参数选择上，核范数与L1权重可采用经验公式与调整策略：例如在标准PCP中常用 λ = 1/√(max(n,t)) 为S项权重的初始选取；实际系统可基于估计噪声标准差σ与经验权重做缩放并通过小规模验证自动调参。对T项的正则选择应依据动态背景强度与频谱特点调节。对于形态学后处理采用开闭运算、小连通域滤除以剔除噪点，利用连通域大小筛除小目标误检或小阴影。\n\n摄像头抖动专门处理方案：若抖动可由全局仿射变换近似，用RASL类方法将变换参数 τ 与L,S联合优化（上述交替方案即为一种实现）。若抖动较复杂（局部景深变化或非刚体运动），建议先使用稳健的帧间配准（基于相位相关的全局位移估计结合金字塔多尺度），对变换参数只保守估计全局分量，然后在局部用稀疏光流补偿背景运动。另一种有效方案是先从短时间窗口内选出代表性静止帧（或通过运动置信度筛选）构建参考背景模板，再用模板对其他帧做鲁棒配准与残差分解。\n\n动态背景的专门建模：对于树叶、水面等周期或随机动态背景，可采用混合策略：对每个像素使用Mixture of Gaussians（MOG）或像素级的自适应模型来识别反复出现的值（视为背景子状态）并将不可重复/异常像素交给稀疏前景处理；另一策略是字典学习，把动态纹理用若干基元表示（在线学习或预训练），T = B·α，求解时更新α（稀疏系数）而保持B相对稳定或缓慢更新。频域处理也是有效手段：对每个像素/小块在时间轴上做FFT，滤除主频带（对应周期性背景）后在残差上做稀疏分解以检测移动前景。若动态背景呈强局地结构（例如喷泉区域），建议在空间上对场景分区，针对不同分区选择不同模型（有些分区采用低秩+稀疏，有些使用MOG）。\n\n多视角（多摄像头）联合处理：假若多个摄像头拍摄近同一地点并时间同步，可先对相机间做几何校准（或估计基本矩阵/单应），将帧投影到公共地面平面或鸟瞰视角，使前景在投影平面上的出现位置具有一致性。数学上可以扩展为耦合分解问题：对每个摄像头k有 D_k ◦ τ_k = L_k + S_k + T_k + E_k，加入跨视角一致性约束如 ||Proj_k(S_k) − Proj_j(S_j)||_F^2（仅在可视交叠区域），或者在投影后共享同一稀疏三维占用图，通过稀疏三维体素表示前景并在多视角观测中进行联合稀疏恢复。若多视角未校准，则可采用联合低秩张量分解，把卷积堆栈成三维/四维张量并使用张量范数或核范数松弛求解，从而利用视角间的统计相关性提升对遮挡和误检的鲁棒性。实现时需注意时间同步误差与不同摄像头曝光/色彩差异，采用亮度归一化与同步补偿措施。\n\n前景后处理与目标跟踪：得到S后应对其逐帧进行形态学处理、连通域分析以得到候选目标。进一步通过卡尔曼滤波或匈牙利算法对跨帧目标进行数据关联并产生轨迹。轨迹信息用于特征提取：速度、加速度、方向分布、轨迹曲率、群体密度与速度场等。若需要物体分类（人/车/动物），可以在前景候选框上运行轻量级分类器（HOG+SVM或小型CNN）。\n\n异常事件检测策略：利用从前景与轨迹得到的时空特征构建异常检测模块。基准方法是用历史“正常”数据估计特征的概率模型（例如多变量高斯、GMM或核密度估计），当观测到特征在概率空间显著偏离（如速度分布突然扩散、局部发散度高速增大代表惊慌外逃、密度短时升高代表聚集、方向熵低且速度周期性表示列队/舞蹈）则触发异常警报。对时序模式的捕捉可用滑动窗口的统计测试（CUSUM、KL-divergence）或时序学习模型（LSTM、1D-CNN）做判别；对周期性行为可用频谱分析或自相关函数检测显著峰值。爆炸或建筑倒塌等极端事件通常伴随前景像素数/运动能量在极短时间内的剧增，设计基于能量阈值与短期二阶统计变化检测器即可快速识别。为了提高鲁棒性，结合视觉证据与多模态（如声音若可用）或多视角一致性会明显降低误报。\n\n验证、参数敏感性与性能评价：建议使用数据集划分为训练/验证/测试三部分，在验证集上自动或半自动调参。使用评价指标包括像素级的精确率、召回率、F1分数与IoU，以及帧级检出率、误报率和系统实时性（帧/秒）与内存占用。敏感性分析通过在关键超参数（λ_1, λ_2, μ, 截断秩r等）上做一维/二维扫描并观测性能曲线，分析模型对噪声水平、前景占比、背景动态强度与变换幅度的鲁棒性。经验上，λ_1 的初值可设为 1/√(max(n,t)) 并按噪声等级上下调整；TV正则权重由目标边缘清晰度与噪点水平决定。数值稳定性问题可通过正规化、步长自适应与早停策略缓解。\n\n计算资源与复杂度估计：批量核范数优化中每次SVD为主开销，其复杂度约为 O(n·t·r)（截断SVD）或 O(min{n^2 t, nt^2}) 对于全SVD。采用随机SVD、并行SVD以及滑动窗口分解能大幅降低负担。在线子空间方法的单帧复杂度通常为O(n r) 并适合在GPU/多核CPU上实现，能达到实时或近实时性能（取决于分辨率与r大小）。推荐在工程部署中结合帧下采样、区域兴趣裁切（ROI）与多线程流水线（配准、分解、后处理并行）以保证帧率。\n\n实际流程概括（可作为实现蓝图）：先用avi2img/avi2mat读入并灰度化视频帧，对必要时做亮度归一化与小范围去噪滤波；若存在明显抖动，用快速相位相关或特征匹配估计粗配准并进行逆变换得到初步对齐帧；对短时间窗口执行低秩+稀疏分解（联合T项如需）用ADMM/ALM迭代求解，内部用随机截断SVD与TV近端更新S；输出每帧前景掩模后做形态学与连通域处理产出候选目标；对候选目标做跨帧数据关联生成轨迹并提取时空特征；基于轨迹和密度/速度场统计检测异常事件并触发告警。对多摄像头情形，先做几何校准与投影或并行独立分解后做跨视角一致性融合。\n\n模型扩展与未来改进方向：为提高适应性，可把上述范式与深度学习结合，一方面利用无监督/自监督的卷积自编码器或生成对抗网络学习更复杂的背景先验，另一方面用深度网络对前景的空间连通性与形状进行修正与分类。可以把Φ_T 的字典B通过在线字典学习自适应学习，以更准确刻画动态纹理。引入不确定性量化（Bayesian RPCA变体或贝叶斯字典学习）可为异常检测提供置信度。长期部署时应考虑背景漂移—定期或自适应地重训练背景子空间或采用带遗忘因子的在线更新以防止模型过时。对于大规模、多站点监控系统，应设计分布式/边缘计算版本，使每台摄像机或边缘节点执行轻量级在线分解并把高层特征或异常报警发送至中心服务器做全局融合与决策。\n\n总结：本方案在数学和工程上以低秩+稀疏为核心，辅以带变换变量的对齐、动态背景字典/频谱建模、空间/时域正则化、以及在线子空间跟踪与并行计算实现，形成一套通用且可扩展的前景分离与异常检测体系。该模型既包含可解析的准则（核范数与L1范数的凸近似保证了解的可解释性和一定的鲁棒性），又保留了面向现实应用时必须的灵活性（处理抖动、动态背景与多视角的模块化扩展），并提供了具体求解方法、实现建议及评估手段，便于在给定数据集（附件中的静态、动态及抖动场景）上验证与迭代改进。",
  "task_descriptions": [
    "子任务1（建模与假设准备）——目标是把一段短时监控视频预处理并用统一、可参数化的代数模型与先验精确定义为供后续求解器使用的输入与初值：输入数据为按时间顺序的帧序列{frame_i}_{i=1}^t（建议以avi2img/avi2mat或等效工具读取），每帧先转为灰度图并标准化到[0,1]（除以255），可选地对整序列做亮度归一化、伽马校正或弱高斯去噪；若场景中只需关注局部区域，提供或自动生成感兴趣区(ROI)掩码以裁剪空间维度以降低计算量。将每帧按列向量化 x_i ∈ R^n (n = w·h) 并按时间堆叠成数据矩阵 D = [x_1, …, x_t] ∈ R^{n×t}；若摄像机存在短时仿射抖动或帧间小幅位移，统一引入每帧的变换参数集合 τ = {τ_i}（τ_i 表示仿射/平移/尺度等小变换），并用符号 D◦τ 表示对 D 中各列按 τ_i 做逆变换/重采样得到的对齐矩阵。在此基础上明确代数分解假设与先验：假设存在低秩背景矩阵 L（表示长期稳定的空间—时间基底）、稀疏前景矩阵 S（表示在像素—时间平面上稀疏出现的移动物体）、可选的动态背景/纹理分量 T（用于捕捉周期性或局部持续动态，如树叶、水波，可用字典稀疏或时间低秩先验表示），以及小幅密集噪声 E，使得在对齐后数据满足近似分解关系 D◦τ ≈ L + S + T + E。明确各分量的先验形式以便后续建模：对背景L采用秩约束或核范数松弛以鼓励低维子空间；对前景S采用逐元素稀疏先验（L1）并规定可选的空间结构先验形式（如每帧总变分TV或帧间组稀疏L_{2,1}）以反映前景的空间连通性；对动态纹理T给出可选先验路径（预训练或在线学习的字典表示 T = Bα 且α稀疏，或基于时间频谱的带通/频域稀疏模型，或在时间域上亦采用低秩表示）；对噪声E假定为小方差高斯扰动，必要时允许包含密集轻尾噪声成分的更复杂模型。规定用于检查模型假设的诊断量：计算D的奇异值谱以判断低秩假设的合理性（明显前几个奇异值后快速衰减支持低秩），估计每帧非零像素比例以验证前景稀疏性，并在存在显著动态背景时分析像素时间序列的周期谱以决定是否启用T分量或采用像素级MOG替代。明确需要由此子任务输出的内容：预处理后的矩阵D（或D◦τ的初始近似），初始变换参数τ（可设为单位变换或由快速相位相关估计得到的粗配准），若采用字典方法则给出初始字典B或频谱过滤器参数，以及一套默认/建议的超参数初值（例如S项初始权重可取 λ ≈ 1/√(max(n,t))，并给出μ等数据拟合尺度的经验标度说明），同时输出诊断报告（奇异值衰减图、前景稀疏度统计、像素时间频谱摘要）用于决定是否需调整模型形式或预处理策略。该子任务的范围仅限于数据准备、变量定义、先验选择与假设自检，并产生可被后续求解模块直接读取的标准化输入文件（矩阵、掩码、初值与超参数集合）与诊断指标，不涉及具体的求解算法或分解实现细节。",
    "子任务2（求解器设计与数值实现）的目标是从预处理后得到的灰度化、向量化并按帧堆叠的数据矩阵 D（及可选的初始帧变换参数 τ、区域掩码和字典初值）中，稳健且高效地联合求解低秩背景矩阵 L、稀疏前景矩阵 S、可选的动态背景分量 T 和可选的逐帧对齐变换 τ，并输出每帧的前景掩模与背景重构；为此本子任务限定为数值算法设计、实现细节与工程加速策略（不含后续跟踪或事件识别）。 具体步骤与方法如下：1）问题分裂与框架：采用交替最小化/增广拉格朗日（ADMM/ALM）框架，将目标函数分解为可分离的子问题——L 子问题为带核范数的最小二乘，S 子问题为带 L1 与空间先验（如TV或L2,1）的稀疏回归，T 子问题依据先验为字典稀疏或时间低秩子问题，τ 子问题为小幅仿射/平移参数的配准更新；2）L 的数值求解：用奇异值阈值（SVT）近端算子解决核范数子问题，采用截断/随机化 SVD（例如 PROPACK、randomized SVD 或 MATLAB svds/pythonic randomized_svd）以只计算显著奇异值并显著降低复杂度，支持自适应秩截断与基于阈值的保留策略；3）S 的数值求解：将逐元素软阈值（逐元素 L1 近端）与空间正则（总变分 TV）通过 ADMM 分裂为两个子步骤，分别用逐元素软阈值闭式解和 TV 近端算子（如 Chambolle 算法或 FISTA）求解，必要时对每帧并行执行以提升吞吐；4）T 的数值求解：若采用字典稀疏表示则将其转为标准 Lasso 问题，使用坐标下降、FISTA 或现成稀疏编码库求解并允许字典 B 的缓慢在线更新；若采用时间低秩表示则以核范数近端解法与 L 更新类似处理；5）τ 的数值求解：对于小幅全局变换，采用对灰度重构误差关于 τ 的线性化并用增量 Gauss–Newton 最小二乘更新，或在预处理阶段用相位相关/金字塔相位相关或基于特征匹配（ORB/SIFT + RANSAC）做快速粗配准；在 ADMM 迭代中交替固定其余变量更新 τ 并用线性化雅可比提高收敛；6）迭代控制与收敛判定：每次外循环按顺序更新 τ（若存在）、L、S、T，然后更新拉格朗日乘子与步长，采用相对残差阈值与原始/对偶残差（ADMM 标准）以及最大迭代次数作为停止条件，并支持早停与温启动（warm start）；7）在线与批处理两条实现路径：批处理采用上述全局 ADMM/ALM 方法和时间滑窗（sliding window）策略处理长序列；实时需求下提供在线子空间跟踪算法实现备选（如 OR-PCA、GRASTA、ReProCS），这些方法在每帧以 O(n·r) 复杂度递增更新背景子空间并用快速稀疏回归估计 S 和 T；8）数值稳定性与参数建议：对核范数与稀疏权重提供经验初值（例如 λ_S ≈ 1/√(max(n,t)) 并按噪声尺度 σ 调整），对 ADMM 步长与惩罚参数采用自适应增量更新规则以避免震荡，必要时对数据加小幅 Tikhonov 正则以改善病态问题；9）工程加速：对计算瓶颈（SVD、稀疏编码、TV 近端）采用截断/随机化 SVD、并行化实现（逐帧/分块并行）、GPU 加速和多线程 I/O，结合 ROI 裁剪与帧下采样以控制每帧成本；10）复杂度与资源预算：在说明文档中明确给出各子问题的理论复杂度（截断 SVD 主导，近似为 O(n·t·r) 或单次 O(n·r) 在线），并提供内存、CPU/GPU 需求估算和可切换的精度/速度参数（r、滑窗长度、SVD 截断阈）；11）软件接口与输出格式：定义清晰的 API（输入：D、可选 τ0、掩码、字典 B、超参数；输出：L、S、T、τ、每帧二值前景掩模、迭代日志与诊断指标如残差与秩曲线），并建议以 MATLAB/Python（NumPy/SciPy）为首选实现环境，辅以调用高效线性代数库（LAPACK/ARPACK/CUDA cuSOLVER）。 此子任务的交付物应包括可复现的算法实现（批处理与在线版本）、充分注释的代码或伪代码、默认超参数建议、数值稳定性与性能调优说明、复杂度/资源估算以及用于单段视频处理的运行接口与诊断输出，所有内容应足以使工程人员在给定 D 与初值的情况下直接运行并获得 L、S、T、τ 与前景掩模。",
    "子任务3（复杂场景专用模块：动态背景、摄像机抖动与多视角融合）—— 范围与目标：本子任务独立负责在有显著局部/周期性动态背景、摄像机短时抖动或存在多路近同步/非同步视角时，提供一组模块化、可互换且能与主分解器对接的预处理与联合建模方法，目标是生成对后续低秩/稀疏分解更友好的输入（包括局部动态掩码、配准后帧或多视角一致性约束），并在必要时直接输出经补偿的前景候选掩模或多视角稀疏三维占用的先验。输入与先验信息：单路或多路视频帧序列（灰度化并标准化到[0,1]），可选的相机内外参/重叠区域信息与时间戳、初始ROI掩码；关键可调超参数包括时间滑窗长度、字典原子数/稀疏度阈值、像素级MOG分量数、配准模型类型（平移/仿射/单应）与配准鲁棒阈值。实施步骤与方法：1) 动态背景识别与分区：对输入视频做基于短时谱分析（帧内/像素时间序列的FFT能谱）或像素级统计（方差/自相关）检测出具有强周期成分或高频随机运动的空间块；对不同块采用不同策略（静态块用低秩假设，动态纹理块进入后续专用模型）；2) 像素级/块级背景模型选择：对普通动态但重复出现的像素使用像素级自适应模型（Mixture of Gaussians, MOG）以识别可重复背景模式；对具有结构性纹理（如水面、树叶）采用字典学习（离线或在线字典B）或时间频域滤波（带通/陷波）来表示动态背景 T，使得 T = Bα 或通过频域门限去除主要频率后得到残差；字典学习可用 SPAMS 或 FISTA/Lasso 实现并支持缓慢在线更新；3) 摄像机抖动估计与补偿：先用快速全局方法（相位相关在金字塔上估计全局平移/缩放；ORB/SIFT 特征配对 + RANSAC 估计仿射/单应）做粗配准，随后在局部用稠密光流或基于图像雅可比的增量 Gauss–Newton 优化细化变换参数 τ_i（线性化灰度重建误差并在 ADMM 外循环中交替更新 τ 与其它分量）；若抖动可由全局仿射近似，则采用 RASL 风格的联合最优化（交替更新变换与低秩/稀疏分量）；对较复杂的局部非刚性抖动，可分块估计局部仿射并用平滑场正则化连接相邻块的变换场。4) 动态背景补偿与局部模型融合：在滑动时间窗口内，对被识别为动态纹理的块用字典稀疏编码或频域滤波得到背景重构 T 并将其从原始帧中剔除；同时对静态/轻微变动区域应用低秩分解或在线子空间跟踪（GRASTA/OR-PCA）以得到背景估计；对同一区域若有多模型输出，采用置信加权或基于重构误差的选择规则融合结果。5) 多视角融合策略（若存在多路视频）：先尽可能做几何校准（若有相机参数）或估计互视单应/基础矩阵并对重叠区域进行亮度归一化与时间对齐（若不同步则做时间延迟估计）；将各视角投影到公用地面平面或鸟瞰视图后，采用耦合约束将各视角的背景/前景分解耦合（例如在投影平面上对齐后的 S_k 通过最小二乘或稀疏三维体素表示共同恢复：求解使得投影一致的多视角稀疏重建问题），或采用张量/RPCA 扩展在视角维度上共享低秩背景基底以提高遮挡鲁棒性；实现上可选用体素稀疏恢复（multi-view voxel carving + L1 优化）或在每视角分别分解后基于投影一致性做后验融合。6) 算法接口与迭代策略：各模块应以滑动窗口为工作单元，输出（或更新）局部动态掩码、配准变换 τ、背景纹理字典/系数、以及经补偿后的帧或多视角一致性约束项；模块间通过迭代（配准→分解→补偿→再配准）精化结果，采用截断/随机化 SVD、并行稀疏编码与 GPU 加速以降低延时。工具与实现要点：建议使用 OpenCV（配准、光流、特征匹配）、VLFeat/ORB/SIFT、SPAMS 或 scikit-learn（字典学习、Lasso）、PROPACK/ARPACK 或 randomized_svd（截断 SVD）、ADMM/FISTA 实现优化子问题，并在需要时结合 CUDA/cuBLAS 做并行加速；为在线场景准备 OR-PCA/GRASTA 的实现以保证实时性。输出规格：为主分解器提供（1）每帧/每块的动态背景掩码与补偿后的帧序列，或直接给出剔除动态纹理后的矩阵 D'；（2）每帧估计的全局或分块变换参数 τ；（3）若多视角则输出投影到公共平面的多视角一致性约束或稀疏三维占用先验；（4）模块运行时的置信度指标与诊断信息（重构误差谱、字典稀疏系数分布、配准残差）。限制与假定：本模块假定短时窗口内动态背景的统计/频谱特征相对稳定且摄像机抖动可由小幅仿射/局部仿射近似描述；若输入不满足这些假设应触发回退策略（仅使用像素级 MOG 或人工ROI 指定）。",
    "子任务4（后处理、目标跟踪、事件特征提取与异常检测、验证与部署）旨在以逐帧前景掩模和候选目标为唯一输入，输出稳定的目标轨迹、结构化时空特征、事件判定与报警日志，并提供评估指标与部署建议。具体包含以下步骤与技术要点：1) 掩模后处理与候选框生成——对每帧前景掩模做二值化、形态学开闭、连通域分析以去噪并生成边界框/质心与像素面积；过滤小于面积阈值（默认占帧面积的0.001）或非连通目标；2) 数据关联与轨迹管理——对连续帧候选框以匈牙利算法或贪心IOU匹配进行关联，匹配代价可用1−IOU或结合匈牙利的外观距离；在关联中用卡尔曼滤波（常用恒速模型）进行状态预测与平滑，设置跟踪丢失容忍帧数N_miss（建议3–10帧）与最短成轨长度N_min（建议5帧）以剔除伪轨；3) 轨迹与目标级特征提取——为每条轨迹按时间步计算像素位移、速度（像素/秒，结合帧率）、加速度、方向角、曲率、轨迹长度与占用面积时间序列；在无真实尺度时对速度归一化（除以帧对角线长度）以便阈值通用；4) 群体与流场特征——在空间网格或ROI上计算每帧的目标密度（单位面积目标数或像素覆盖率）、局部平均速度场（由轨迹或稠密光流估算）、速度场散度与旋度、方向熵与速度方差，用于描述聚集/散开与秩序性；光流可用Farneback或轻量级CNN（PWC-Net）实现；5) 时序统计与频谱特征——对轨迹或局部速度时间序列做滑动窗口统计（均值、方差、跳变率）、CUSUM/滑动Z-score检测突变，并用FFT或自相关检测周期性（舞蹈、列队等）；6) 异常判别策略——提供三类可选方法：规则阈值（如短时内密度急增、局部速度散度大于阈值触发）、统计学习（基于历史正常样本的GMM、Mahalanobis距离、One-Class SVM）与时序深度模型（LSTM自编码器或1D-CNN监测重构误差）；融合策略可将多方法的置信度按加权投票或逻辑回归整合，输出事件类型、时间窗、相关轨迹ID与置信度；7) 报警后处理与稳健化——对报警做时间抑制（debounce）与空间融合以减少误报，提供阈值自适应机制（基于最近窗口的背景统计）并产生日志与可视化（关键帧、轨迹叠加、热力图）；8) 性能评估与参数调优——在标注集上按像素/目标/事件层面计算精确率、召回率、F1、IoU、事件检测延迟与误报率，进行超参数敏感性分析（IOU阈值、N_miss、窗口长度、告警阈值），并用ROC/PR曲线与混淆矩阵指导阈值选择；9) 部署建议——区分离线批量与实时在线两种模式：实时采用轻量跟踪（SORT/卡尔曼+IOU）、低维特征与简单阈值或轻量神经网络，限制每帧处理时间以满足帧率；离线可用更复杂的光流与LSTM模型；提供输出格式规范（轨迹表：ID,时间戳, bbox,速度等；事件表：类型,开始/结束帧,相关IDs,置信度）与API 接口建议；10) 推荐工具——OpenCV（形态学、连通域、光流、匈牙利）、NumPy/SciPy、scikit-learn、filterpy（卡尔曼）、PyTorch/TensorFlow（LSTM/自编码器）、以及现成跟踪库（SORT/DeepSORT）用于扩展外观关联。该子任务应交付可复现的处理代码或模块、参数默认值与调优指南、评估报告与部署说明，确保在不依赖其它预处理细节的情况下能直接接收前景掩模与输出可靠的轨迹与事件报警。"
  ]
}