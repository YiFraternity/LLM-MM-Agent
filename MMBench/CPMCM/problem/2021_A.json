{
  "background": "计算机视觉、相控阵雷达、声呐、射电天文、无线通信等领域的信号通常呈现为矩阵的形式，这一系列的矩阵间通常在某些维度存在一定的关联性，因此数学上可用相关矩阵组表示。例如，视频信号中的单帧图像可视为一个矩阵，连续的多帧图像组成了相关矩阵组，而相邻图像帧或图像帧内像素间的关联性则反映在矩阵间的相关性上。随着成像传感器数量/雷达阵列/通信阵列的持续扩大，常规处理算法对计算和存储的需求成倍增长，从而对处理器件或算法的实现成本和功耗提出了巨大的挑战。因此，充分挖掘矩阵间关联性，以实现低复杂度的计算和存储，具有十分重要的价值和意义。",
  "problem_requirement": "给定一组复数矩阵 $H = \\{H_{j,k}\\}$，$H_{j,k} \\in \\mathbb{C}^{M \\times N}, j = 1, \\ldots, J, k = 1, \\ldots, K$。其中，矩阵之间以及同一矩阵的元素之间有一定的相关性，包括：相同 $j$ 下标、不同 $k$ 下标的矩阵间存在一定的关联，即 $\\{H_{j,1}, H_{j,2}, H_{j,3}, \\ldots, H_{j,K}\\}$ 间存在关联\\footnote{在本问题中，仅考虑同一行块内部的 $K$ 个矩阵间的相关性，不考虑矩阵组 $H$ 中属于不同行块的矩阵（即，不同 $j$ 下标的矩阵）间的相关性。}；且矩阵\n\n\\[\nH_{j,k} = \\begin{bmatrix}\n h_{1,1}^{(j,k)} & h_{1,2}^{(j,k)} & h_{1,3}^{(j,k)} & \\cdots & h_{1,N}^{(j,k)} \\\n h_{2,1}^{(j,k)} & h_{2,2}^{(j,k)} & h_{2,3}^{(j,k)} & \\cdots & h_{2,N}^{(j,k)} \\\n \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\n h_{M,1}^{(j,k)} & h_{M,2}^{(j,k)} & h_{M,3}^{(j,k)} & \\cdots & h_{M,N}^{(j,k)}\n\\end{bmatrix}\n\\]\n\n的各个元素间 $\\{h_{m,n}^{(j,k)}\\}, m = 1, \\ldots, M, n = 1, \\ldots, N$，也存在关联。\n\n定义矩阵组 $H = \\{H_{j,k}\\}$ 上的一组数学运算，其中间结果 $V = \\{V_{j,k}\\}$ 由如下的公式给出：\n\n\\[\nV_{j,k} = svd\\big(H_{j,k}\\big), \\text{or } H_{j,k} = U_{j,k} S_{j,k} \\widetilde{V}_{j,k}^H, V_{j,k} = \\widetilde{V}_{j,k}^H(:,1:L)\n\\]\n\n\\[\nj = 1, \\ldots, J; \\, k = 1, \\ldots, K\n\\]其中，\\(svd(\\cdot)\\)为矩阵的奇异值分解（即，SVD 分解）中求解右奇异向量的过程，其简要说明可参考附录一；\\(V_{j,k}\\)是由\\(H_{j,k}\\)的前\\(L\\)个右奇异向量构成的矩阵，\\(L\\)个之后的右奇异向量可以忽略，维度为\\(N \\times L\\)。\n\n进一步，为得到最终输出结果\\(W = \\{W_{j,k}\\}\\)，先将不同\\(j\\)下标、相同\\(k\\)下标的\\(V_{j,k}\\)进行横向的拼接，得到维度为\\(N \\times LJ\\)的\\(V_k = [V_{1,k} \\quad \\cdots \\quad V_{j,k} \\quad \\cdots \\quad V_{J,k}]\\)，然后根据如下公式获取\\(W_k\\)：\n\\[\nW_k = V_k (V_k^H V_k + \\sigma^2 I)^{-1}\n\\]\n其中，\\(\\sigma^2\\)为固定常数；\\(W_k\\)维度同\\(V_k\\)；\\(I\\)为单位矩阵，维度为\\(LJ \\times LJ\\)。\n\n最后，将各\\(W_k\\)按如下的公式进行拆解：\n\\[\nW_k = [W_{1,k}, \\ldots, W_{j,k}, \\ldots, W_{J,k}]\n\\]\n其中，\\(W_{j,k}\\)是\\(W_k\\)中顺序排列的子矩阵，维度为\\(N \\times L\\)。上述各流程亦可参考附录二中的图示说明。\n\n为了降低计算和储存的复杂度，分析相关矩阵组的关联性，通过数学建模对输出结果\\(W\\)进行估计，建模过程表示为：\n\\[\n\\widehat{W} = f(H)\n\\]\n其中\\(\\widehat{W}\\)即为对输出结果\\(W\\)的建模估计。这一建模过程又可以拆分为2个步骤：\n\\[\n\\widehat{V} = f_1(H), \\quad \\widehat{W} = f_2(\\widehat{V})\n\\]\n其中\\(f_1(\\cdot)\\)表示从输入矩阵组\\(H\\)到中间结果\\(V\\)的建模过程，\\(\\widehat{V}\\)表示中间结果\\(V\\)的建模估计，\\(f_2(\\cdot)\\)表示从中间结果\\(V\\)到最终结果\\(W\\)的建模过程，\\(\\widehat{W}\\)表示最终结果\\(W\\)的建模估计。定义\\(W\\)的建模估计精度为：\n\\[\n\\rho_{l,j,k}(W) = \\frac{\\|\\widehat{W}_{l,j,k}^H W_{l,j,k}\\|_2}{\\|\\widehat{W}_{l,j,k}\\|_2 \\|W_{l,j,k}\\|_2}, l = 1, \\ldots, L\n\\]\n其中，\\(\\|\\cdot\\|_2\\)表示矢量的欧几里得范数（也即2范数，对于列矢量\\(a\\)，\\(\\|a\\|_2 = \\sqrt{a^H a}\\)）；\\(W_{l,j,k}\\)表示\\(W_{j,k}\\)的第\\(l\\)列。上式中，\\(\\widehat{W}_{l,j,k}^H W_{l,j,k}\\)为复数标量，此处取其欧几里得范数即获取其模值。\n\n为了降低计算和储存的复杂度，分析相关矩阵组的关联性，通过数学建模对输出结果\\(W\\)进行估计，建模过程表示为：\n\\[\n\\widehat{W} = f(H)\n\\]\n其中\\(\\widehat{W}\\)即为对输出结果\\(W\\)的建模估计。这一建模过程又可以拆分为2个步骤：\n\\[\n\\widehat{V} = f_1(H), \\quad \\widehat{W} = f_2(\\widehat{V})\n\\]\n其中\\(f_1(\\cdot)\\)表示从输入矩阵组\\(H\\)到中间结果\\(V\\)的建模过程，\\(\\widehat{V}\\)表示中间结果\\(V\\)的建模估计，\\(f_2(\\cdot)\\)表示从中间结果\\(V\\)到最终结果\\(W\\)的建模过程，\\(\\widehat{W}\\)表示最终结果\\(W\\)的建模估计。定义\\(W\\)的建模估计精度为：\n\\[\n\\rho_{l,j,k}(W) = \\frac{\\|\\widehat{W}_{l,j,k}^H W_{l,j,k}\\|_2}{\\|\\widehat{W}_{l,j,k}\\|_2 \\|W_{l,j,k}\\|_2}, l = 1, \\ldots, L\n\\]\n其中，\\(\\|\\cdot\\|_2\\)表示矢量的欧几里得范数（也即2范数，对于列矢量\\(a\\)，\\(\\|a\\|_2 = \\sqrt{a^H a}\\)）；\\(W_{l,j,k}\\)表示\\(W_{j,k}\\)的第\\(l\\)列。上式中，\\(\\widehat{W}_{l,j,k}^H W_{l,j,k}\\)为复数标量，此处取其欧几里得范数即获取其模值。\n\n如果使用以上方法，当矩阵组 \\(H = \\{H_{j,k}\\}\\) 的维度，或者，矩阵组内各个矩阵 \\(H_{j,k}\\) 的维度继续提升时，整个系统将承受愈发巨大的计算负担。为此，需要通过恰当的建模方法，使得在近似获得输出结果的同时明显地降低计算复杂度。\n\n在本题目中，利用相关矩阵组的关联性降低计算复杂度可以从如下基础方向（或你认为其他更合适的方向）中的一个或者多个方向切入完成建模题目：\n\n1) 利用矩阵组 \\(H\\) 内部各个矩阵间的关联性，减少前述一组数学运算的整体计算复杂度。例如，矩阵组 \\(H\\) 中包括存在关联性的 5 个矩阵 \\(\\{H_{j,1}, H_{j,2}, H_{j,3}, H_{j,4}, H_{j,5}\\}\\)，部分情况下可以仅针对 \\(H_{j,1}, H_{j,3}, H_{j,5}\\) 进行相应的运算过程并获取 \\(\\widehat{W}_{j,1}, \\widehat{W}_{j,3}, \\widehat{W}_{j,5}\\)，然后通过恰当的插值操作获取 \\(\\widehat{W}_{j,2}\\) 和 \\(\\widehat{W}_{j,4}\\)，使得 \\(\\rho_{l,j,k}(W)\\) 均满足前述建模估计精度的需求。\n\n2) 利用矩阵 \\(H_{j,k}\\) 内部各个矩阵元素间的关联性，降低奇异值分解过程、矩阵求逆过程的计算复杂度。关于奇异值分解的低计算复杂度实现，方法不做限定。例如，可以参考文献 [5] 中提出的随机奇异值分解 (Randomized SVD) 方法，其简要实现过程可以参考网页 [6]，部分摘录于附录五。\n\n3) 针对计算流程进行合理的构造和转化，避免执行相对复杂的矩阵运算步骤。例如，矩阵求逆的计算复杂度较高，而本问题的最终需求为 \\(W_k = V_k (V_k^H V_k + \\sigma^2 I)^{-1}\\)，如果将该步骤转化为 \\((V_k^H V_k + \\sigma^2 I) W_k^H = V_k^H\\) 形式来求解 \\(W_k\\)，则潜在地可以降低整体计算流程的计算复杂度。4) 请注意，在完成本问题时，推荐根据上述表格给出更细化的计算复杂度评估。例如，统计建模过程中复数乘法的使用次数、复数加法的使用次数等，然后分别与复数乘法的计算复杂度（可以为 14）及复数加法的计算复杂度（可以为 2）相乘，累加后得到总体计算复杂度。\n\n存储复杂度定义为矩阵组 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 占用的存储空间的大小，以比特为单位计算。对于复数矩阵中单个复数元素，其实部和虚部均采用 32 比特单精度浮点表示。因此，整个矩阵组 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 占用的存储空间分别为 \\(64MNJK\\) 比特和 \\(64NLJK\\) 比特。\n\n为了节省存储开销，考虑对 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 分别进行压缩。独立设计 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 的压缩函数 \\(P_1(\\cdot)\\) 和 \\(P_2(\\cdot)\\)，对压缩后的数据 \\(P_1(\\boldsymbol{H})\\) 和 \\(P_2(\\boldsymbol{W})\\) 进行存储。压缩函数的设计请主要考虑挖掘并利用矩阵内部或矩阵间的关联性，或者，矩阵表达的稀疏性；思路可参考但不限于图像的变换域压缩算法或视频的帧间压缩算法。压缩后的每个元素仍然以 32bit 单精度浮点数存储，不考虑位宽的压缩。\n\n\\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 以压缩的形式存储在存储器中。在进行处理之前，需要从存储器中读出 \\(P_1(\\boldsymbol{H})\\) 和 \\(P_2(\\boldsymbol{W})\\) 进行解压缩处理：\n\\[\n\\widehat{\\boldsymbol{H}} = G_1\\big(P_1(\\boldsymbol{H})\\big), \\ \\widehat{\\boldsymbol{W}} = G_2\\big(P_2(\\boldsymbol{W})\\big)\n\\]\n其中，\\(G_1(\\cdot)\\) 和 \\(G_2(\\cdot)\\) 分别表示矩阵组 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 的解压缩函数。经过压缩和解压缩之后得到的 \\(\\widehat{\\boldsymbol{H}}\\) 和 \\(\\widehat{\\boldsymbol{W}}\\) 与原始的 \\(\\boldsymbol{H}\\) 和 \\(\\boldsymbol{W}\\) 存在误差，定义为\n\\[\nerr_H = 10 * \\log_{10} \\frac{E\\left\\{\\|\\widehat{\\boldsymbol{H}}_{j,k} - \\boldsymbol{H}_{j,k}\\|_F^2\\right\\}}{E\\left\\{\\|\\boldsymbol{H}_{j,k}\\|_F^2\\right\\}}, \\ err_W = 10 * \\log_{10} \\frac{E\\left\\{\\|\\widehat{\\boldsymbol{W}}_{j,k} - \\boldsymbol{W}_{j,k}\\|_F^2\\right\\}}{E\\left\\{\\|\\boldsymbol{W}_{j,k}\\|_F^2\\right\\}}\n\\]\n其中，\\(\\|\\cdot\\|_F\\) 表示矩阵的 Frobenius 范数；\\(E\\{\\cdot\\}\\) 表示求期望运算，即在所提供矩阵组的所有矩阵求平均。注意：标准输出矩阵组 \\(\\boldsymbol{W}\\) 是 0 相位，即其中矩阵 \\(\\boldsymbol{W}_{j,k}\\) 的每个列向量的首个元素是 0 相位复数（实数）。若建模得到的 \\(\\widehat{\\boldsymbol{W}}_{j,k}\\) 带有随机初始相位，可增加一步相位拉齐处理，将 \\(\\widehat{\\boldsymbol{W}}_{j,k}\\) 拉齐到与 \\(\\boldsymbol{W}_{j,k}\\) 相同的 0 相位，然后再计算误差。\n\n综上所述，相关矩阵组的整体处理流程如下图所示。\n\n\\begin{tikzpicture}[node distance=2cm, auto, thick, main/.style = {draw, rectangle, minimum size=2cm}]\n    \\node[main] (input) {$\\boldsymbol{H} = \\{\\boldsymbol{H}_{j,k}\\}$};\n    \\node[main, right of=input] (compress1) {存储单元};\n    \\node[main, right of=compress1] (decompress1) {计算单元};\n    \\node[main, right of=decompress1] (compress2) {存储单元};\n    \\node[main, right of=compress2] (decompress2) {$\\widehat{\\boldsymbol{W}} = \\{\\widehat{\\boldsymbol{W}}_{j,k}\\}$};\n    \n    \\draw[->] (input) -- node[above] {$P_1(\\cdot)$} (compress1);\n    \\draw[->] (compress1) -- node[above] {$G_1(\\cdot)$} (decompress1);\n    \\draw[->] (decompress1) -- node[above] {$P_2(\\cdot)$} (compress2);\n    \\draw[->] (compress2) -- node[above] {$G_2(\\cdot)$} (decompress2);\n    \n    \\node[above of=compress1, node distance=1cm] {压缩};\n    \\node[above of=decompress1, node distance=1cm] {解压缩};\n    \\node[above of=compress2, node distance=1cm] {压缩};\n    \\node[above of=decompress2, node distance=1cm] {解压缩};\n    \n    \\node[below of=decompress1, node distance=1cm] {$\\widehat{\\boldsymbol{W}} = f(\\boldsymbol{H})$};\n\\end{tikzpicture}\n\n输入矩阵组 $\\mathbf{H}$、标准中间矩阵组 $\\mathbf{V}$ 和标准输出矩阵组 $\\mathbf{W}$ 的数据及其维度如下，数据采用十进制格式：\n\n\\begin{itemize}\n    \\item 第一组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第二组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第三组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第四组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第五组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第六组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n\\end{itemize}\n\n附件中提供 .mat 及 .csv 文件格式的数据，按需使用其中的一种文件格式即可。\n\n请基于以上提供的数据，采用适当的方法，解决以下相关矩阵组的低复杂度计算和存储建模问题。注意，提交结果及论文需要完成以下问题 1、问题 2 中的至少一题，同时完成两题将适当加分。问题 3 为开放式问题，不作为必选，但鼓励尝试，有新意的算法模型设计将得到加分。\n\n在完成以下问题时，仅需考虑各个问题本身申明的建模需求，不需要考虑其他问题产生的建模需求。例如，在完成问题 3 时，不需要额外考虑问题 1 中 $\\rho_{\\min}(V)$ 的建模估计精度需求。",
  "dataset_path": [
    "Data1_H.csv",
    "Data1_H.mat",
    "Data1_V.csv",
    "Data1_V.mat",
    "Data1_W.csv",
    "Data1_W.mat",
    "Data2_H.csv",
    "Data2_H.mat",
    "Data2_V.csv",
    "Data2_V.mat",
    "Data2_W.csv",
    "Data2_W.mat",
    "Data3_H.csv",
    "Data3_H.mat",
    "Data3_V.csv",
    "Data3_V.mat",
    "Data3_W.csv",
    "Data3_W.mat",
    "Data4_H.csv",
    "Data4_H.mat",
    "Data4_V.csv",
    "Data4_V.mat",
    "Data4_W.csv",
    "Data4_W.mat",
    "Data5_H.csv",
    "Data5_H.mat",
    "Data5_V.csv",
    "Data5_V.mat",
    "Data5_W.csv",
    "Data5_W.mat",
    "Data6_H.csv",
    "Data6_H.mat",
    "Data6_V.csv",
    "Data6_V.mat",
    "Data6_W.csv",
    "Data6_W.mat",
    "Readme.txt",
    "附录.docx"
  ],
  "dataset_description": "输入矩阵组 $\\mathbf{H}$、标准中间矩阵组 $\\mathbf{V}$ 和标准输出矩阵组 $\\mathbf{W}$ 的数据及其维度如下，数据采用十进制格式：\n\n\\begin{itemize}\n    \\item 第一组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第二组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第三组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第四组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第五组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n    \\item 第六组：$M = 4, N = 64, L = 2, J = 4, K = 384, \\sigma^2 = 0.01$，详细数据见附件；\n\\end{itemize}\n\n附件中提供 .mat 及 .csv 文件格式的数据，按需使用其中的一种文件格式即可。",
  "variable_description": [
    {
      "M": "矩阵的行数"
    },
    {
      "N": "矩阵的列数"
    },
    {
      "L": "奇异值分解中保留的右奇异向量的数量"
    },
    {
      "J": "矩阵组的行数"
    },
    {
      "K": "矩阵组的列数"
    },
    {
      "\\sigma^2": "固定常数"
    }
  ],
  "addendum": "如果使用以上方法，当矩阵组 $H = \\{H_{j,k}\\}$ 的维度，或者，矩阵组内各个矩阵 $H_{j,k}$ 的维度继续提升时，整个系统将承受愈发巨大的计算负担。为此，需要通过恰当的建模方法，使得在近似获得输出结果的同时明显地降低计算复杂度。\n\n在本题目中，利用相关矩阵组的关联性降低计算复杂度可以从如下基础方向（或你认为其他更合适的方向）中的一个或者多个方向切入完成建模题目：\n\n1) 利用矩阵组 $H$ 内部各个矩阵间的关联性，减少前述一组数学运算的整体计算复杂度。例如，矩阵组 $H$ 中包括存在关联性的 5 个矩阵 $\\{H_{j,1}, H_{j,2}, H_{j,3}, H_{j,4}, H_{j,5}\\}$，部分情况下可以仅针对 $H_{j,1}, H_{j,3}, H_{j,5}$ 进行相应的运算过程并获取 $\\widehat{W}_{j,1}, \\widehat{W}_{j,3}, \\widehat{W}_{j,5}$，然后通过恰当的插值操作获取 $\\widehat{W}_{j,2}$ 和 $\\widehat{W}_{j,4}$，使得 $\\rho_{l,j,k}(W)$ 均满足前述建模估计精度的需求。\n\n2) 利用矩阵 $H_{j,k}$ 内部各个矩阵元素间的关联性，降低奇异值分解过程、矩阵求逆过程的计算复杂度。关于奇异值分解的低计算复杂度实现，方法不做限定。例如，可以参考文献 [5] 中提出的随机奇异值分解 (Randomized SVD) 方法，其简要实现过程可以参考网页 [6]，部分摘录于附录五。\n\n3) 针对计算流程进行合理的构造和转化，避免执行相对复杂的矩阵运算步骤。例如，矩阵求逆的计算复杂度较高，而本问题的最终需求为 $W_k = V_k (V_k^H V_k + \\sigma^2 I)^{-1}$，如果将该步骤转化为 $(V_k^H V_k + \\sigma^2 I) W_k^H = V_k^H$ 形式来求解 $W_k$，则潜在地可以降低整体计算流程的计算复杂度。4) 请注意，在完成本问题时，推荐根据上述表格给出更细化的计算复杂度评估。例如，统计建模过程中复数乘法的使用次数、复数加法的使用次数等，然后分别与复数乘法的计算复杂度（可以为 14）及复数加法的计算复杂度（可以为 2）相乘，累加后得到总体计算复杂度。\n\n存储复杂度定义为矩阵组 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 占用的存储空间的大小，以比特为单位计算。对于复数矩阵中单个复数元素，其实部和虚部均采用 32 比特单精度浮点表示。因此，整个矩阵组 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 占用的存储空间分别为 $64MNJK$ 比特和 $64NLJK$ 比特。\n\n为了节省存储开销，考虑对 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 分别进行压缩。独立设计 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 的压缩函数 $P_1(\\cdot)$ 和 $P_2(\\cdot)$，对压缩后的数据 $P_1(\\boldsymbol{H})$ 和 $P_2(\\boldsymbol{W})$ 进行存储。压缩函数的设计请主要考虑挖掘并利用矩阵内部或矩阵间的关联性，或者，矩阵表达的稀疏性；思路可参考但不限于图像的变换域压缩算法或视频的帧间压缩算法。压缩后的每个元素仍然以 32bit 单精度浮点数存储，不考虑位宽的压缩。\n\n$\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 以压缩的形式存储在存储器中。在进行处理之前，需要从存储器中读出 $P_1(\\boldsymbol{H})$ 和 $P_2(\\boldsymbol{W})$ 进行解压缩处理：\n\\[\n\\widehat{\\boldsymbol{H}} = G_1\\big(P_1(\\boldsymbol{H})\\big), \\ \\widehat{\\boldsymbol{W}} = G_2\\big(P_2(\\boldsymbol{W})\\big)\n\\]\n其中，$G_1(\\cdot)$ 和 $G_2(\\cdot)$ 分别表示矩阵组 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 的解压缩函数。经过压缩和解压缩之后得到的 $\\widehat{\\boldsymbol{H}}$ 和 $\\widehat{\\boldsymbol{W}}$ 与原始的 $\\boldsymbol{H}$ 和 $\\boldsymbol{W}$ 存在误差，定义为\n\\[\nerr_H = 10 * \\log_{10} \\frac{E\\left\\{\\|\\widehat{\\boldsymbol{H}}_{j,k} - \\boldsymbol{H}_{j,k}\\|_F^2\\right\\}}{E\\left\\{\\|\\boldsymbol{H}_{j,k}\\|_F^2\\right\\}}, \\ err_W = 10 * \\log_{10} \\frac{E\\left\\{\\|\\widehat{\\boldsymbol{W}}_{j,k} - \\boldsymbol{W}_{j,k}\\|_F^2\\right\\}}{E\\left\\{\\|\\boldsymbol{W}_{j,k}\\|_F^2\\right\\}}\n\\]\n其中，$\\|\\cdot\\|_F$ 表示矩阵的 Frobenius 范数；$E\\{\\cdot\\}$ 表示求期望运算，即在所提供矩阵组的所有矩阵求平均。注意：标准输出矩阵组 $\\boldsymbol{W}$ 是 0 相位，即其中矩阵 $\\boldsymbol{W}_{j,k}$ 的每个列向量的首个元素是 0 相位复数（实数）。若建模得到的 $\\widehat{\\boldsymbol{W}}_{j,k}$ 带有随机初始相位，可增加一步相位拉齐处理，将 $\\widehat{\\boldsymbol{W}}_{j,k}$ 拉齐到与 $\\boldsymbol{W}_{j,k}$ 相同的 0 相位，然后再计算误差。\n\n综上所述，相关矩阵组的整体处理流程如下图所示。\n\n\\begin{tikzpicture}[node distance=2cm, auto, thick, main/.style = {draw, rectangle, minimum size=2cm}]\n    \\node[main] (input) {$\\boldsymbol{H} = \\{\\boldsymbol{H}_{j,k}\\}$};\n    \\node[main, right of=input] (compress1) {存储单元};\n    \\node[main, right of=compress1] (decompress1) {计算单元};\n    \\node[main, right of=decompress1] (compress2) {存储单元};\n    \\node[main, right of=compress2] (decompress2) {$\\widehat{\\boldsymbol{W}} = \\{\\widehat{\\boldsymbol{W}}_{j,k}\\}$};\n    \n    \\draw[->] (input) -- node[above] {$P_1(\\cdot)$} (compress1);\n    \\draw[->] (compress1) -- node[above] {$G_1(\\cdot)$} (decompress1);\n    \\draw[->] (decompress1) -- node[above] {$P_2(\\cdot)$} (compress2);\n    \\draw[->] (compress2) -- node[above] {$G_2(\\cdot)$} (decompress2);\n    \n    \\node[above of=compress1, node distance=1cm] {压缩};\n    \\node[above of=decompress1, node distance=1cm] {解压缩};\n    \\node[above of=compress2, node distance=1cm] {压缩};\n    \\node[above of=decompress2, node distance=1cm] {解压缩};\n    \n    \\node[below of=decompress1, node distance=1cm] {$\\widehat{\\boldsymbol{W}} = f(\\boldsymbol{H})$};\n\\end{tikzpicture}\n\n请基于以上提供的数据，采用适当的方法，解决以下相关矩阵组的低复杂度计算和存储建模问题。注意，提交结果及论文需要完成以下问题 1、问题 2 中的至少一题，同时完成两题将适当加分。问题 3 为开放式问题，不作为必选，但鼓励尝试，有新意的算法模型设计将得到加分。\n\n在完成以下问题时，仅需考虑各个问题本身申明的建模需求，不需要考虑其他问题产生的建模需求。例如，在完成问题 3 时，不需要额外考虑问题 1 中 $\\rho_{\\min}(V)$ 的建模估计精度需求。"
}