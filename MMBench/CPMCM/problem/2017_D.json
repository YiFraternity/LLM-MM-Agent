{
  "background": "视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。\n\n目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。\n\n下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据$X \\in \\mathbb{R}^{w \\times h \\times t}$，其中$w, h$代表视频帧的长、宽，$t$代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即$X = \\{x_1, x_2, \\dots, x_t\\}$，其中$x_i \\in \\mathbb{R}^{w \\times h} (i = 1, 2, \\dots, t)$为一张长宽分别为$w, h$的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0, 1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红）、G（绿）、B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片\\section*{构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在 Matlab 环境下，视频的读取、播放及相应基本操作程序见附件 1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。}\n\n题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。",
  "problem_requirement": "请你们查阅相关资料和数据，结合视频数据特点，回答下列问题：\n\n\\textbf{问题 1：} 对一个不包含动态背景、摄像头稳定拍摄时间大约 5 秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图 1 的应用效果。（附件 2 提供了一些符合此类特征的监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{image1.png}\n    \\includegraphics[width=0.45\\textwidth]{image2.png}\n    \\caption{左图：原视频帧；右图：分离出的前景目标}\n    \\label{fig:1}\n\\end{figure}\n\n\\textbf{问题 2：} 对包含动态背景信息的监控视频（如图 2 所示），设计有效的前景目标提取方案。（附件 2 中提供了一些符合此类特征的典型监控视频）\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=0.24\\textwidth]{image3.png}\n    \\includegraphics[width=0.24\\textwidth]{image4.png}\n    \\includegraphics[width=0.24\\textwidth]{image5.png}\n    \\includegraphics[width=0.24\\textwidth]{image6.png}\n    \\caption{几种典型的动态视频背景：树叶摇动，水波动，喷泉变化，窗帘晃动}\n    \\label{fig:2}\n\\end{figure}\n\n\\textbf{问题 3：} 在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件 2 中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从\\begin{itemize}\n    \\item 问题4：在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。\n    \\item 问题5：如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从 \\url{http://cvlab.epfl.ch/research/surv/multi-people-tracking} 下载）。\n\\end{itemize}\n\n\\begin{figure}[h]\n    \\centering\n    \\includegraphics[width=\\textwidth]{image.png}\n    \\caption{在室内同一时间从不同角度拍摄同一地点获得的视频帧}\n    \\label{fig:3}\n\\end{figure}\n\n\\begin{itemize}\n    \\item 问题6：利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证）\n\\end{itemize}\n\n\\textbf{注：} 强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。",
  "dataset_path": [
    "avi2img.m",
    "avi2mat.m",
    "img2avi.m",
    "readme.txt",
    "run_vedio.m",
    "不带晃动-动态背景",
    "不带晃动-静态背景",
    "有晃动",
    "campus",
    "curtain",
    "escalator",
    "fountain",
    "hall",
    "lobby"
  ],
  "dataset_description": "该文件 'avi2img.m' 的用途是将视频文件 'campus5.avi' 转换为一系列灰度图像，并保存为 JPEG 格式的图片文件。具体步骤包括读取视频文件、逐帧处理视频帧、将彩色帧转换为灰度帧、显示每一帧，并将每一帧保存为单独的图片文件。\n该文件 'avi2mat.m' 是一个 MATLAB 脚本，用于将一系列单帧图片转换为向量并存储为 MATLAB mat 文件。具体来说，'avi2mat.m' 脚本读取指定文件夹中的所有 JPG 图片，将每张图片拉伸为一个列向量，并将所有列向量存储为一个矩阵。最后，该矩阵及其尺寸信息被保存为一个名为 'campus5' 的 mat 文件。\n该文件 'img2avi.m' 是一个 MATLAB 脚本，用于将一系列 JPEG 图片文件转换为一个 AVI 视频文件。该脚本首先定义了图片文件所在的目录，然后读取该目录下的所有 JPEG 文件，并将这些图片按顺序写入到一个 AVI 文件中，形成一个视频。\nreadme.txt是一个文本文件，包含了用于视频处理的几个Matlab脚本的简要描述。这些脚本主要用于视频到图像帧的转换、图像帧到向量的转换、向量到视频的转换以及视频的播放。\nrun_vedio.m 是一个 MATLAB 脚本文件，用于读取并播放视频文件 'highway_gray.avi'。该脚本读取视频的所有帧，并创建一个 MATLAB 视频播放结构体，最后按照视频的帧速率重播视频。\n不带晃动-动态背景文件夹包含一个名为'waterSurface'的子文件夹，内含符合特定特征的监控视频数据。这些视频数据主要用于研究和测试在不同背景条件下（包括静态和动态背景）的前景目标（如人、车、动物等）提取技术。具体而言，'waterSurface'文件夹中的视频数据旨在探索在动态背景（例如水面波动）下的前景目标提取方法。这些视频时长约为5秒，摄像头稳定，不包含动态背景的视频可用于验证和优化静态背景下的前景目标提取模型。\n不带晃动-静态背景数据集包含多个子文件夹，每个子文件夹代表不同场景下的监控视频片段。具体包括：smoke（烟雾场景）、pedestrian（行人场景）、office（办公室场景）、airport（机场场景）、hall（大厅场景）。这些视频片段主要用于研究和测试监控视频中的前景目标提取技术，包括但不限于人、车、动物等。不带晃动-静态背景数据集中的视频片段时长约为5秒，摄像头稳定，背景相对静态或动态。\n有晃动文件夹包含四个子文件夹：cars7, cars6, people2, people1。这些子文件夹分别存储了不同类型的监控视频片段，旨在用于测试和验证前景目标（如车辆和行人）的提取算法。每个子文件夹中的视频具有不包含动态背景、摄像头稳定拍摄时间大约5秒的特点，适用于构建和测试提取前景目标的数学模型。\ncampus文件夹包含两个文件：Campus.mat 和 Campus.avi。Campus.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Campus.mat 可能是与视频相关的元数据或标注文件，用于辅助视频分析任务，如前景目标提取。\ncurtain文件夹包含两个文件：Curtain.mat 和 Curtain.avi。Curtain.avi 是一个监控视频文件，展示了摄像头稳定拍摄的场景，持续时间约为5秒，不包含动态背景。Curtain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。curtain数据集适用于研究和实现提取视频中前景目标（如人、车、动物等）的数学模型和求解方法。\n该文件夹包含一个名为'Escalator'的数据集，其中包括一个监控视频文件'escalator/Escalator.avi'和一个相关的MAT文件'escalator/Escalator.mat'。监控视频文件记录了在固定摄像头下拍摄的约5秒的电梯扶梯场景，背景相对稳定，无明显动态变化。MAT文件可能包含了视频的元数据、标注信息或其他辅助数据，用于支持视频分析任务，如前景目标（例如人、动物等）的提取。该数据集适用于研究和测试在静态背景条件下从监控视频中分离前景目标的技术。\n文件夹fountain包含两个文件：Fountain.avi 和 Fountain.mat。Fountain.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄的场景，视频时长约为5秒。Fountain.mat 是一个与视频相关的MAT文件，可能包含视频的元数据或处理后的数据。该数据集适用于研究和测试在稳定摄像头拍摄条件下提取前景目标（如人、车、动物等）的算法。\n该文件夹包含两个文件：hall.mat 和 hall.avi。hall.avi 是一个监控视频文件，展示了一个不包含动态背景、摄像头稳定拍摄时间约为5秒的场景。hall.mat 是一个 MATLAB 数据文件，可能包含与 hall.avi 视频相关的元数据或标注信息。hall 适用于研究和测试在静态背景下的前景目标（如人、车、动物等）提取算法。\n该文件夹包含两个文件：Lobby.mat 和 Lobby.avi。Lobby.mat 可能是一个 MATLAB 数据文件，用于存储相关数据或元数据。Lobby.avi 是一个监控视频文件，可能用于展示或测试监控视频中的前景目标提取技术。需要注意的是，文件名 'Lobyy.avi' 中存在拼写错误，可能是 'Lobby.avi' 的误写。lobby 文件夹包含这些文件。",
  "variable_description": [
    {
      "file_name": "视频文件 'avi2img.m' 的路径和名称",
      "obj": "VideoReader 对象，用于读取和处理视频文件 'avi2img.m'",
      "numFrames": "视频文件 'avi2img.m' 中的总帧数",
      "frame": "从视频文件 'avi2img.m' 中读取的单帧图像",
      "gray_frame": "将读取的彩色帧转换为灰度帧后的图像",
      "k": "当前处理的视频文件 'avi2img.m' 的帧编号"
    },
    {
      "XX": "存储所有图片拉伸后的向量组成的矩阵，每一列代表一张图片的所有像素值。",
      "siz": "存储单张图片的尺寸信息，包括行数和列数。",
      "obj": "包含变量 'XX' 和 'siz' 的 MATLAB 对象，该对象被保存为 'avi2mat.m' 文件。"
    },
    {
      "DIR": "img2avi.m 中图片文件所在的目录路径",
      "file": "img2avi.m 中包含所有 JPEG 文件信息的结构体数组",
      "filenum": "img2avi.m 中 JPEG 文件的总数",
      "obj_gray": "img2avi.m 中用于写入视频的 VideoWriter 对象",
      "writerFrames": "img2avi.m 中视频的帧数",
      "fname": "img2avi.m 中当前处理的 JPEG 文件的完整路径",
      "frame": "img2avi.m 中当前处理的 JPEG 文件读取为图像矩阵",
      "k": "img2avi.m 中当前处理的 JPEG 文件的索引"
    },
    {},
    {
      "video": "VideoReader 对象，用于读取视频文件 'highway_gray.avi'",
      "vidFrames": "视频中所有帧的数据",
      "numFrames": "视频的总帧数",
      "mov": "一个包含所有视频帧的结构体数组，用于存储每一帧的图像数据",
      "hf": "创建的图像窗口句柄",
      "k": "循环变量，用于遍历视频帧",
      "video.Width": "视频的宽度",
      "video.Height": "视频的高度",
      "video.FrameRate": "视频的帧速率"
    },
    {},
    {},
    {},
    {},
    {},
    {},
    {},
    {},
    {}
  ],
  "addendum": "参考文献：\n[1] Andrews Sobral & Antoine Vacavant, A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos, Computer Vision and Image Understanding, Volume 122, May 2014, Pages 4-21\n[2] B. Lee and M. Hedley, “Background estimation for video surveillance,” IVCNZ02, pp. 315–320, 2002.\n[3] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture models for real-time tracking,” in Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., vol. 2. IEEE, 1999.\n[4] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?” Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011.\n[5] D. Meng and F. De la Torre, “Robust matrix factorization with unknown noise,” in IEEE International Conference on Computer Vision, 2013, pp. 1337–1344.\n[6] Q. Zhao, D. Meng, Z. Xu,W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 55–63.\n[7] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 11, pp. 2233–2246, 2012.\n[8] M. Babaee, D. T. Dinh, and G. Rigoll, “A deep convolutional neural network for background subtraction,” arXiv preprint arXiv: 1702.01731, 2017.\n"
}